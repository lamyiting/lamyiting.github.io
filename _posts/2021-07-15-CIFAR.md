```python
import numpy as np
import pandas as pd 
import matplotlib.pyplot as plt
import seaborn as sns
pd.set_option('display.max_columns', None)
```


```python
from tensorflow.keras.models import Sequential, Model, save_model, load_model
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout
from tensorflow.keras.callbacks import EarlyStopping
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.regularizers import l2
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.applications import VGG16, ResNet50V2
import matplotlib.image as mpimg
import cv2
import tensorflow as tf
```

# Image Classification - CIFAR 100

File was 'unzipped' using 7-zip, then it is unpickled using the below code.


```python
# Code to unpickle is provided by Cifar website.
def unpickle(file):
    import pickle
    with open(file, 'rb') as fo:
        dict = pickle.load(fo, encoding='bytes')
    return dict
```


```python
train = unpickle('data/cifar-100-python/train')
test = unpickle('data/cifar-100-python/test')
meta = unpickle('data/cifar-100-python/meta')
```

# Exploratory Data Analysis


https://www.cs.toronto.edu/~kriz/cifar.html

## Train Set

This data is from the above link.
- 20 superclasses
-
- 100 classes in total
- 500 images in each class (compared to 100 images per class in test set)
- 2500 images in each superclass
- Total training images = 500 x 100 = 50,000 images

File is in a dictionary format, and there are 5 sections:
- image `filenames`
- image `batch labels `
- image `coarse labels` - The superclass to which the image belongs to, and there are 20 superclasses.
- image `fine labels` - The class which the image belongs to. These are sub-classes of superclass, and there are 100 classes in total.
- image `data` - 32 x 32 pixel with 3 RGB values. Came in flattened data 50,000 images x 3,072 values / image

#### Unflattening data

The images came as flattened data with shape of (50000, 3072).  Each image is 32 x 32, therefore, the total is 1,024 pixels.  Each row has 3,072 values, with the first 1,024 representing the `R` value, next 1,024 being the `G` values and the last 1,025 being the `B` values.

To view each image, we need to convert the data to a shape of (32, 32, 3).


```python
Train_flat_data = pd.DataFrame(train[b'data'])

# Check shape 
Train_flat_data.shape
```




    (50000, 3072)




```python
print('BEFORE unflattening data', '\n') 
print('data shape: ', Train_flat_data.shape)
```

    BEFORE unflattening data 
    
    data shape:  (50000, 3072)
    


```python
# Unflatten data
print('AFTER unflattening data', '\n')
Train_data = np.array(Train_flat_data, dtype=np.uint8).reshape((50000,32,32,3), order='F').transpose(0,2,1,3)
print('data shape: ', Train_data.shape)
print('image shape: ', Train_data[1].shape)
```

    AFTER unflattening data 
    
    data shape:  (50000, 32, 32, 3)
    image shape:  (32, 32, 3)
    

#### Meta data (aka labels)

Meta data file contains the names of each class and superclass. 


```python
Superclass_label = pd.DataFrame(meta[b'coarse_label_names']).rename(columns={0: 'Superclass_label'})
SL = Superclass_label['Superclass_label']
Superclass_label.head()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Superclass_label</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>b'aquatic_mammals'</td>
    </tr>
    <tr>
      <th>1</th>
      <td>b'fish'</td>
    </tr>
    <tr>
      <th>2</th>
      <td>b'flowers'</td>
    </tr>
    <tr>
      <th>3</th>
      <td>b'food_containers'</td>
    </tr>
    <tr>
      <th>4</th>
      <td>b'fruit_and_vegetables'</td>
    </tr>
  </tbody>
</table>
</div>




```python
Class_label = pd.DataFrame(meta[b'fine_label_names']).rename(columns={0: 'Class_label'})
CL = Class_label['Class_label']
Class_label.T
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>0</th>
      <th>1</th>
      <th>2</th>
      <th>3</th>
      <th>4</th>
      <th>5</th>
      <th>6</th>
      <th>7</th>
      <th>8</th>
      <th>9</th>
      <th>10</th>
      <th>11</th>
      <th>12</th>
      <th>13</th>
      <th>14</th>
      <th>15</th>
      <th>16</th>
      <th>17</th>
      <th>18</th>
      <th>19</th>
      <th>20</th>
      <th>21</th>
      <th>22</th>
      <th>23</th>
      <th>24</th>
      <th>25</th>
      <th>26</th>
      <th>27</th>
      <th>28</th>
      <th>29</th>
      <th>30</th>
      <th>31</th>
      <th>32</th>
      <th>33</th>
      <th>34</th>
      <th>35</th>
      <th>36</th>
      <th>37</th>
      <th>38</th>
      <th>39</th>
      <th>40</th>
      <th>41</th>
      <th>42</th>
      <th>43</th>
      <th>44</th>
      <th>45</th>
      <th>46</th>
      <th>47</th>
      <th>48</th>
      <th>49</th>
      <th>50</th>
      <th>51</th>
      <th>52</th>
      <th>53</th>
      <th>54</th>
      <th>55</th>
      <th>56</th>
      <th>57</th>
      <th>58</th>
      <th>59</th>
      <th>60</th>
      <th>61</th>
      <th>62</th>
      <th>63</th>
      <th>64</th>
      <th>65</th>
      <th>66</th>
      <th>67</th>
      <th>68</th>
      <th>69</th>
      <th>70</th>
      <th>71</th>
      <th>72</th>
      <th>73</th>
      <th>74</th>
      <th>75</th>
      <th>76</th>
      <th>77</th>
      <th>78</th>
      <th>79</th>
      <th>80</th>
      <th>81</th>
      <th>82</th>
      <th>83</th>
      <th>84</th>
      <th>85</th>
      <th>86</th>
      <th>87</th>
      <th>88</th>
      <th>89</th>
      <th>90</th>
      <th>91</th>
      <th>92</th>
      <th>93</th>
      <th>94</th>
      <th>95</th>
      <th>96</th>
      <th>97</th>
      <th>98</th>
      <th>99</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Class_label</th>
      <td>b'apple'</td>
      <td>b'aquarium_fish'</td>
      <td>b'baby'</td>
      <td>b'bear'</td>
      <td>b'beaver'</td>
      <td>b'bed'</td>
      <td>b'bee'</td>
      <td>b'beetle'</td>
      <td>b'bicycle'</td>
      <td>b'bottle'</td>
      <td>b'bowl'</td>
      <td>b'boy'</td>
      <td>b'bridge'</td>
      <td>b'bus'</td>
      <td>b'butterfly'</td>
      <td>b'camel'</td>
      <td>b'can'</td>
      <td>b'castle'</td>
      <td>b'caterpillar'</td>
      <td>b'cattle'</td>
      <td>b'chair'</td>
      <td>b'chimpanzee'</td>
      <td>b'clock'</td>
      <td>b'cloud'</td>
      <td>b'cockroach'</td>
      <td>b'couch'</td>
      <td>b'crab'</td>
      <td>b'crocodile'</td>
      <td>b'cup'</td>
      <td>b'dinosaur'</td>
      <td>b'dolphin'</td>
      <td>b'elephant'</td>
      <td>b'flatfish'</td>
      <td>b'forest'</td>
      <td>b'fox'</td>
      <td>b'girl'</td>
      <td>b'hamster'</td>
      <td>b'house'</td>
      <td>b'kangaroo'</td>
      <td>b'keyboard'</td>
      <td>b'lamp'</td>
      <td>b'lawn_mower'</td>
      <td>b'leopard'</td>
      <td>b'lion'</td>
      <td>b'lizard'</td>
      <td>b'lobster'</td>
      <td>b'man'</td>
      <td>b'maple_tree'</td>
      <td>b'motorcycle'</td>
      <td>b'mountain'</td>
      <td>b'mouse'</td>
      <td>b'mushroom'</td>
      <td>b'oak_tree'</td>
      <td>b'orange'</td>
      <td>b'orchid'</td>
      <td>b'otter'</td>
      <td>b'palm_tree'</td>
      <td>b'pear'</td>
      <td>b'pickup_truck'</td>
      <td>b'pine_tree'</td>
      <td>b'plain'</td>
      <td>b'plate'</td>
      <td>b'poppy'</td>
      <td>b'porcupine'</td>
      <td>b'possum'</td>
      <td>b'rabbit'</td>
      <td>b'raccoon'</td>
      <td>b'ray'</td>
      <td>b'road'</td>
      <td>b'rocket'</td>
      <td>b'rose'</td>
      <td>b'sea'</td>
      <td>b'seal'</td>
      <td>b'shark'</td>
      <td>b'shrew'</td>
      <td>b'skunk'</td>
      <td>b'skyscraper'</td>
      <td>b'snail'</td>
      <td>b'snake'</td>
      <td>b'spider'</td>
      <td>b'squirrel'</td>
      <td>b'streetcar'</td>
      <td>b'sunflower'</td>
      <td>b'sweet_pepper'</td>
      <td>b'table'</td>
      <td>b'tank'</td>
      <td>b'telephone'</td>
      <td>b'television'</td>
      <td>b'tiger'</td>
      <td>b'tractor'</td>
      <td>b'train'</td>
      <td>b'trout'</td>
      <td>b'tulip'</td>
      <td>b'turtle'</td>
      <td>b'wardrobe'</td>
      <td>b'whale'</td>
      <td>b'willow_tree'</td>
      <td>b'wolf'</td>
      <td>b'woman'</td>
      <td>b'worm'</td>
    </tr>
  </tbody>
</table>
</div>



#### Properties

**Filename**


```python
print('filename: ', len(train.get(b'filenames')))

import random
print(random.choice(train.get(b'filenames')))
```

    filename:  50000
    b'mako_shark_s_000431.png'
    

**Batch labels**


```python
print('Number of batch label: ', len(train.get(b'batch_label')))
print(train.get(b'batch_label'))
```

    Number of batch label:  21
    b'training batch 1 of 1'
    

**Fine labels**


```python
print('Number of fine labels: ', len(train.get(b'fine_labels')))
print('Unique values in fine labels (class): ', "\n", np.unique(np.array(train.get(b'fine_labels'))))

Train_fine = pd.DataFrame(train[b'fine_labels']).rename(columns={0: 'fine'})
Train_fine.head()
```

    Number of fine labels:  50000
    Unique values in fine labels (class):  
     [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
     24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
     48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
     72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95
     96 97 98 99]
    




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>fine</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>19</td>
    </tr>
    <tr>
      <th>1</th>
      <td>29</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>11</td>
    </tr>
    <tr>
      <th>4</th>
      <td>1</td>
    </tr>
  </tbody>
</table>
</div>




```python
# check for imbalance

pd.DataFrame(Train_fine.value_counts()).T
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead tr th {
        text-align: left;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr>
      <th>fine</th>
      <th>0</th>
      <th>63</th>
      <th>73</th>
      <th>72</th>
      <th>71</th>
      <th>70</th>
      <th>69</th>
      <th>68</th>
      <th>67</th>
      <th>66</th>
      <th>65</th>
      <th>64</th>
      <th>62</th>
      <th>1</th>
      <th>61</th>
      <th>60</th>
      <th>59</th>
      <th>58</th>
      <th>57</th>
      <th>56</th>
      <th>55</th>
      <th>54</th>
      <th>53</th>
      <th>52</th>
      <th>74</th>
      <th>75</th>
      <th>76</th>
      <th>77</th>
      <th>98</th>
      <th>97</th>
      <th>96</th>
      <th>95</th>
      <th>94</th>
      <th>93</th>
      <th>92</th>
      <th>91</th>
      <th>90</th>
      <th>89</th>
      <th>88</th>
      <th>87</th>
      <th>86</th>
      <th>85</th>
      <th>84</th>
      <th>83</th>
      <th>82</th>
      <th>81</th>
      <th>80</th>
      <th>79</th>
      <th>78</th>
      <th>51</th>
      <th>50</th>
      <th>49</th>
      <th>24</th>
      <th>22</th>
      <th>21</th>
      <th>20</th>
      <th>19</th>
      <th>18</th>
      <th>17</th>
      <th>16</th>
      <th>15</th>
      <th>14</th>
      <th>13</th>
      <th>12</th>
      <th>11</th>
      <th>10</th>
      <th>9</th>
      <th>8</th>
      <th>7</th>
      <th>6</th>
      <th>5</th>
      <th>4</th>
      <th>3</th>
      <th>2</th>
      <th>23</th>
      <th>25</th>
      <th>48</th>
      <th>26</th>
      <th>47</th>
      <th>46</th>
      <th>45</th>
      <th>44</th>
      <th>43</th>
      <th>42</th>
      <th>41</th>
      <th>40</th>
      <th>39</th>
      <th>38</th>
      <th>37</th>
      <th>36</th>
      <th>35</th>
      <th>34</th>
      <th>33</th>
      <th>32</th>
      <th>31</th>
      <th>30</th>
      <th>29</th>
      <th>28</th>
      <th>27</th>
      <th>99</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>500</td>
      <td>500</td>
      <td>500</td>
      <td>500</td>
      <td>500</td>
      <td>500</td>
      <td>500</td>
      <td>500</td>
      <td>500</td>
      <td>500</td>
      <td>500</td>
      <td>500</td>
      <td>500</td>
      <td>500</td>
      <td>500</td>
      <td>500</td>
      <td>500</td>
      <td>500</td>
      <td>500</td>
      <td>500</td>
      <td>500</td>
      <td>500</td>
      <td>500</td>
      <td>500</td>
      <td>500</td>
      <td>500</td>
      <td>500</td>
      <td>500</td>
      <td>500</td>
      <td>500</td>
      <td>500</td>
      <td>500</td>
      <td>500</td>
      <td>500</td>
      <td>500</td>
      <td>500</td>
      <td>500</td>
      <td>500</td>
      <td>500</td>
      <td>500</td>
      <td>500</td>
      <td>500</td>
      <td>500</td>
      <td>500</td>
      <td>500</td>
      <td>500</td>
      <td>500</td>
      <td>500</td>
      <td>500</td>
      <td>500</td>
      <td>500</td>
      <td>500</td>
      <td>500</td>
      <td>500</td>
      <td>500</td>
      <td>500</td>
      <td>500</td>
      <td>500</td>
      <td>500</td>
      <td>500</td>
      <td>500</td>
      <td>500</td>
      <td>500</td>
      <td>500</td>
      <td>500</td>
      <td>500</td>
      <td>500</td>
      <td>500</td>
      <td>500</td>
      <td>500</td>
      <td>500</td>
      <td>500</td>
      <td>500</td>
      <td>500</td>
      <td>500</td>
      <td>500</td>
      <td>500</td>
      <td>500</td>
      <td>500</td>
      <td>500</td>
      <td>500</td>
      <td>500</td>
      <td>500</td>
      <td>500</td>
      <td>500</td>
      <td>500</td>
      <td>500</td>
      <td>500</td>
      <td>500</td>
      <td>500</td>
      <td>500</td>
      <td>500</td>
      <td>500</td>
      <td>500</td>
      <td>500</td>
      <td>500</td>
      <td>500</td>
      <td>500</td>
      <td>500</td>
      <td>500</td>
    </tr>
  </tbody>
</table>
</div>



**Coarse Labels**


```python
print('Number of coarse labels: ', len(train.get(b'coarse_labels')))
print('Unique values in coarse labels (Superclass): ', "\n", np.unique(np.array(train.get(b'coarse_labels'))))

Train_coarse = pd.DataFrame(train[b'coarse_labels']).rename(columns={0: 'coarse'})
Train_coarse.head()
```

    Number of coarse labels:  50000
    Unique values in coarse labels (Superclass):  
     [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]
    




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>coarse</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>11</td>
    </tr>
    <tr>
      <th>1</th>
      <td>15</td>
    </tr>
    <tr>
      <th>2</th>
      <td>4</td>
    </tr>
    <tr>
      <th>3</th>
      <td>14</td>
    </tr>
    <tr>
      <th>4</th>
      <td>1</td>
    </tr>
  </tbody>
</table>
</div>




```python
# check for imbalance

pd.DataFrame(Train_coarse.value_counts()).T
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead tr th {
        text-align: left;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr>
      <th>coarse</th>
      <th>0</th>
      <th>1</th>
      <th>18</th>
      <th>17</th>
      <th>16</th>
      <th>15</th>
      <th>14</th>
      <th>13</th>
      <th>12</th>
      <th>11</th>
      <th>10</th>
      <th>9</th>
      <th>8</th>
      <th>7</th>
      <th>6</th>
      <th>5</th>
      <th>4</th>
      <th>3</th>
      <th>2</th>
      <th>19</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>2500</td>
      <td>2500</td>
      <td>2500</td>
      <td>2500</td>
      <td>2500</td>
      <td>2500</td>
      <td>2500</td>
      <td>2500</td>
      <td>2500</td>
      <td>2500</td>
      <td>2500</td>
      <td>2500</td>
      <td>2500</td>
      <td>2500</td>
      <td>2500</td>
      <td>2500</td>
      <td>2500</td>
      <td>2500</td>
      <td>2500</td>
      <td>2500</td>
    </tr>
  </tbody>
</table>
</div>



#### Duplicates & Null

The images came as flattened data with shape of (50000, 3072).  Each image is 32 x 32, therefore, the total is 1,024 pixels.  Each row has 3,072 values, with the first 1,024 representing the `R` value, next 1,024 being the `G` values and the last 1,025 being the `B` values.

To view each image, we need to convert the data to a shape of (32, 32, 3).


```python
# Check for duplicates
Train_flat_data.duplicated().sum()
```




    14




```python
# Look at what duplicated images look like

duplicated_image_index = Train_flat_data[Train_flat_data.duplicated(keep=False)].sort_values(by=[0,1,2,3,4]).index

for i in duplicated_image_index:
    images = train[b'data'].reshape((50000,32,32,3), order='F').transpose(0,2,1,3) 
    plt.figure(figsize=(3,3))
    plt.imshow(images[i])
    plt.title(f'index: {i}')

```

    <ipython-input-17-76331bbea16f>:7: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
      plt.figure(figsize=(3,3))
    


    
![png](image/output_34_1.png)
    



    
![png](image/output_34_2.png)
    



    
![png](image/output_34_3.png)
    



    
![png](image/output_34_4.png)
    



    
![png](image/output_34_5.png)
    



    
![png](image/output_34_6.png)
    



    
![png](image/output_34_7.png)
    



    
![png](image/output_34_8.png)
    



    
![png](image/output_34_9.png)
    



    
![png](image/output_34_10.png)
    



    
![png](image/output_34_11.png)
    



    
![png](image/output_34_12.png)
    



    
![png](image/output_34_13.png)
    



    
![png](image/output_34_14.png)
    



    
![png](image/output_34_15.png)
    



    
![png](image/output_34_16.png)
    



    
![png](image/output_34_17.png)
    



    
![png](image/output_34_18.png)
    



    
![png](image/output_34_19.png)
    



    
![png](image/output_34_20.png)
    



    
![png](image/output_34_21.png)
    



    
![png](image/output_34_22.png)
    



    
![png](image/output_34_23.png)
    



    
![png](image/output_34_24.png)
    



    
![png](image/output_34_25.png)
    



    
![png](image/output_34_26.png)
    



    
![png](image/output_34_27.png)
    



    
![png](image/output_34_28.png)
    


There are duplicated images, but not a lot. We will keep them as this will keep all the classes balance.


```python
# Check for null values

Train_flat_data.isna().sum().sum()
```




    0



#### Grayscaled


```python
def grayscale(color_dataset):
    '''
    This function converts all colour images in the dataset to grayscale.
    
    INPUT: flatten image dataset with a shape of (num_of_samples, height, width, RGB)
    OUTPUT: flatten image dataset with a shape of (num_of_samples, height, width) 
    
    '''
    # Input can be dataset of any shape
    shape = color_dataset.shape
    
    # Create a new variable to store images converted into grayscale
    grayscale_dataset = np.zeros((shape[0], int(shape[1]/3)))
    
    # loop through each line or image to convert RGB into luminosity 
    for idx in range(shape[0]):
        if idx % 1000 == 0:
            print(idx, end="\r")
        color_image = color_dataset.iloc[idx,:]
        new_image = np.zeros(1024)
        
        # Average formula from https://www.johndcook.com/blog/2009/08/24/algorithms-convert-color-grayscale/
        for i in range(1024):
            R = color_image[i]*0.21  
            G = color_image[i+1024]*0.72  
            B = color_image[i+2048]*0.07   

            new_image[i] = R+G+B
            
        
        # Append new image to grayscale dataset
        grayscale_dataset[idx] = new_image

    return grayscale_dataset
```


```python
# Convert color images to grayscale
Train_flat_data_gray = grayscale(Train_flat_data)
```

    49000


```python
# Check shape before unflatten
print('BEFORE unflattening data', '\n') 
print('data shape: ', Train_flat_data_gray.shape)

# Unflatten data
print('AFTER unflattening data', '\n')
Train_data_gray = np.array(Train_flat_data_gray, dtype=np.uint8).reshape((50000,32,32,1))
print('data shape: ', Train_data_gray.shape)
print('image shape: ', Train_data_gray[1].shape)
```

    BEFORE unflattening data 
    
    data shape:  (50000, 1024)
    AFTER unflattening data 
    
    data shape:  (50000, 32, 32, 1)
    image shape:  (32, 32, 1)
    


```python
# Print 5 random images from each superclass

Superclass_index = sorted(Train_coarse['coarse'].unique())

for s in Superclass_index:
    #create subplots
    plt.subplots(1,5, figsize=(10,10))
    print('superclass: ', s)
    print(Superclass_label.iloc[s]['Superclass_label'])
    
    for i in range(0,5):
        # find a random image of this superclass
        index = random.choice(Train_coarse.index[Train_coarse['coarse'] == s])

        # plot image
        image = Train_data_gray[index]
        plt.subplot(1,5,i+1) 
        plt.imshow(image, cmap='gray_r')
        
    plt.show()

```

    superclass:  0
    b'aquatic_mammals'
    


    
![png](output_41_1.png)
    


    superclass:  1
    b'fish'
    


    
![png](output_41_3.png)
    


    superclass:  2
    b'flowers'
    


    
![png](output_41_5.png)
    


    superclass:  3
    b'food_containers'
    


    
![png](output_41_7.png)
    


    superclass:  4
    b'fruit_and_vegetables'
    


    
![png](output_41_9.png)
    


    superclass:  5
    b'household_electrical_devices'
    


    
![png](output_41_11.png)
    


    superclass:  6
    b'household_furniture'
    


    
![png](output_41_13.png)
    


    superclass:  7
    b'insects'
    


    
![png](output_41_15.png)
    


    superclass:  8
    b'large_carnivores'
    


    
![png](output_41_17.png)
    


    superclass:  9
    b'large_man-made_outdoor_things'
    


    
![png](output_41_19.png)
    


    superclass:  10
    b'large_natural_outdoor_scenes'
    


    
![png](output_41_21.png)
    


    superclass:  11
    b'large_omnivores_and_herbivores'
    


    
![png](output_41_23.png)
    


    superclass:  12
    b'medium_mammals'
    


    
![png](output_41_25.png)
    


    superclass:  13
    b'non-insect_invertebrates'
    


    
![png](output_41_27.png)
    


    superclass:  14
    b'people'
    


    
![png](output_41_29.png)
    


    superclass:  15
    b'reptiles'
    


    
![png](output_41_31.png)
    


    superclass:  16
    b'small_mammals'
    


    
![png](output_41_33.png)
    


    superclass:  17
    b'trees'
    


    
![png](output_41_35.png)
    


    superclass:  18
    b'vehicles_1'
    


    
![png](output_41_37.png)
    


    superclass:  19
    b'vehicles_2'
    


    
![png](output_41_39.png)
    


## Test Set

Same as training data:
- 20 superclasses
- 100 classes in total
- 100 images in each class (compared to 500 per class in training set)
- 500 images in each superclass
- Total test images = 100 x 100 = 10,000 images

File is in a dictionary format, and there are 5 sections:
- image `filenames`
- image `batch labels `
- image `coarse labels` - The superclass to which the image belongs to, and there are 20 superclasses.
- image `fine labels` - The class which the image belongs to. These are sub-classes of superclass, and there are 100 classes in total.
- image `data` - 32 x 32 pixel with 3 RGB values. Came in flattened data 50,000 images x 3,072 values / image

#### Unflattening data


```python
Test_flat_data = pd.DataFrame(test[b'data'])
```


```python
print('BEFORE unflattening data', '\n') 
print('data shape: ', Test_flat_data.shape)
```

    BEFORE unflattening data 
    
    data shape:  (10000, 3072)
    


```python
# Unflatten data
print('AFTER unflattening data', '\n')
Test_data = np.array(Test_flat_data, dtype=np.uint8).reshape((10000,32,32,3), order='F').transpose(0,2,1,3)
print('data shape: ', Test_data.shape)
print('image shape: ', Test_data[1].shape)
```

    AFTER unflattening data 
    
    data shape:  (10000, 32, 32, 3)
    image shape:  (32, 32, 3)
    

#### Properties

**Filename**


```python
print('filename: ', len(test.get(b'filenames')))
```

    filename:  10000
    

**Batch labels**


```python
print('Number of batch label: ', len(test.get(b'batch_label')))
print(test.get(b'batch_label'))
```

    Number of batch label:  20
    b'testing batch 1 of 1'
    

**Fine labels**


```python
print('Number of fine labels: ', len(test.get(b'fine_labels')))
print('Unique values in fine labels (class): ', "\n", np.unique(np.array(test.get(b'fine_labels'))))

Test_fine = pd.DataFrame(test[b'fine_labels']).rename(columns={0: 'fine'})
Test_fine.head()
```

    Number of fine labels:  10000
    Unique values in fine labels (class):  
     [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
     24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
     48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
     72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95
     96 97 98 99]
    




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>fine</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>49</td>
    </tr>
    <tr>
      <th>1</th>
      <td>33</td>
    </tr>
    <tr>
      <th>2</th>
      <td>72</td>
    </tr>
    <tr>
      <th>3</th>
      <td>51</td>
    </tr>
    <tr>
      <th>4</th>
      <td>71</td>
    </tr>
  </tbody>
</table>
</div>




```python
# check for imbalance

pd.DataFrame(Test_fine.value_counts()).T
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead tr th {
        text-align: left;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr>
      <th>fine</th>
      <th>0</th>
      <th>63</th>
      <th>73</th>
      <th>72</th>
      <th>71</th>
      <th>70</th>
      <th>69</th>
      <th>68</th>
      <th>67</th>
      <th>66</th>
      <th>65</th>
      <th>64</th>
      <th>62</th>
      <th>1</th>
      <th>61</th>
      <th>60</th>
      <th>59</th>
      <th>58</th>
      <th>57</th>
      <th>56</th>
      <th>55</th>
      <th>54</th>
      <th>53</th>
      <th>52</th>
      <th>74</th>
      <th>75</th>
      <th>76</th>
      <th>77</th>
      <th>98</th>
      <th>97</th>
      <th>96</th>
      <th>95</th>
      <th>94</th>
      <th>93</th>
      <th>92</th>
      <th>91</th>
      <th>90</th>
      <th>89</th>
      <th>88</th>
      <th>87</th>
      <th>86</th>
      <th>85</th>
      <th>84</th>
      <th>83</th>
      <th>82</th>
      <th>81</th>
      <th>80</th>
      <th>79</th>
      <th>78</th>
      <th>51</th>
      <th>50</th>
      <th>49</th>
      <th>24</th>
      <th>22</th>
      <th>21</th>
      <th>20</th>
      <th>19</th>
      <th>18</th>
      <th>17</th>
      <th>16</th>
      <th>15</th>
      <th>14</th>
      <th>13</th>
      <th>12</th>
      <th>11</th>
      <th>10</th>
      <th>9</th>
      <th>8</th>
      <th>7</th>
      <th>6</th>
      <th>5</th>
      <th>4</th>
      <th>3</th>
      <th>2</th>
      <th>23</th>
      <th>25</th>
      <th>48</th>
      <th>26</th>
      <th>47</th>
      <th>46</th>
      <th>45</th>
      <th>44</th>
      <th>43</th>
      <th>42</th>
      <th>41</th>
      <th>40</th>
      <th>39</th>
      <th>38</th>
      <th>37</th>
      <th>36</th>
      <th>35</th>
      <th>34</th>
      <th>33</th>
      <th>32</th>
      <th>31</th>
      <th>30</th>
      <th>29</th>
      <th>28</th>
      <th>27</th>
      <th>99</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>100</td>
      <td>100</td>
      <td>100</td>
      <td>100</td>
      <td>100</td>
      <td>100</td>
      <td>100</td>
      <td>100</td>
      <td>100</td>
      <td>100</td>
      <td>100</td>
      <td>100</td>
      <td>100</td>
      <td>100</td>
      <td>100</td>
      <td>100</td>
      <td>100</td>
      <td>100</td>
      <td>100</td>
      <td>100</td>
      <td>100</td>
      <td>100</td>
      <td>100</td>
      <td>100</td>
      <td>100</td>
      <td>100</td>
      <td>100</td>
      <td>100</td>
      <td>100</td>
      <td>100</td>
      <td>100</td>
      <td>100</td>
      <td>100</td>
      <td>100</td>
      <td>100</td>
      <td>100</td>
      <td>100</td>
      <td>100</td>
      <td>100</td>
      <td>100</td>
      <td>100</td>
      <td>100</td>
      <td>100</td>
      <td>100</td>
      <td>100</td>
      <td>100</td>
      <td>100</td>
      <td>100</td>
      <td>100</td>
      <td>100</td>
      <td>100</td>
      <td>100</td>
      <td>100</td>
      <td>100</td>
      <td>100</td>
      <td>100</td>
      <td>100</td>
      <td>100</td>
      <td>100</td>
      <td>100</td>
      <td>100</td>
      <td>100</td>
      <td>100</td>
      <td>100</td>
      <td>100</td>
      <td>100</td>
      <td>100</td>
      <td>100</td>
      <td>100</td>
      <td>100</td>
      <td>100</td>
      <td>100</td>
      <td>100</td>
      <td>100</td>
      <td>100</td>
      <td>100</td>
      <td>100</td>
      <td>100</td>
      <td>100</td>
      <td>100</td>
      <td>100</td>
      <td>100</td>
      <td>100</td>
      <td>100</td>
      <td>100</td>
      <td>100</td>
      <td>100</td>
      <td>100</td>
      <td>100</td>
      <td>100</td>
      <td>100</td>
      <td>100</td>
      <td>100</td>
      <td>100</td>
      <td>100</td>
      <td>100</td>
      <td>100</td>
      <td>100</td>
      <td>100</td>
      <td>100</td>
    </tr>
  </tbody>
</table>
</div>



**Coarse Labels**


```python
print('Number of coarse labels: ', len(test.get(b'coarse_labels')))
print('Unique values in coarse labels (Superclass): ', "\n", np.unique(np.array(test.get(b'coarse_labels'))))

Test_coarse = pd.DataFrame(test[b'coarse_labels']).rename(columns={0: 'coarse'})
Test_coarse.head()
```

    Number of coarse labels:  10000
    Unique values in coarse labels (Superclass):  
     [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]
    




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>coarse</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>10</td>
    </tr>
    <tr>
      <th>1</th>
      <td>10</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>4</td>
    </tr>
    <tr>
      <th>4</th>
      <td>10</td>
    </tr>
  </tbody>
</table>
</div>




```python
# check for imbalance

pd.DataFrame(Test_coarse.value_counts()).T
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead tr th {
        text-align: left;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr>
      <th>coarse</th>
      <th>0</th>
      <th>1</th>
      <th>18</th>
      <th>17</th>
      <th>16</th>
      <th>15</th>
      <th>14</th>
      <th>13</th>
      <th>12</th>
      <th>11</th>
      <th>10</th>
      <th>9</th>
      <th>8</th>
      <th>7</th>
      <th>6</th>
      <th>5</th>
      <th>4</th>
      <th>3</th>
      <th>2</th>
      <th>19</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>500</td>
      <td>500</td>
      <td>500</td>
      <td>500</td>
      <td>500</td>
      <td>500</td>
      <td>500</td>
      <td>500</td>
      <td>500</td>
      <td>500</td>
      <td>500</td>
      <td>500</td>
      <td>500</td>
      <td>500</td>
      <td>500</td>
      <td>500</td>
      <td>500</td>
      <td>500</td>
      <td>500</td>
      <td>500</td>
    </tr>
  </tbody>
</table>
</div>



#### Grayscaled


```python
# Convert color images to grayscale
Test_flat_data_gray = grayscale(Test_flat_data)
```

    9000


```python
# Check shape before unflatten
print('BEFORE unflattening data', '\n') 
print('data shape: ', Test_flat_data_gray.shape)

# Unflatten data
print('AFTER unflattening data', '\n')
Test_data_gray = np.array(Test_flat_data_gray, dtype=np.uint8).reshape((10000,32,32,1))
print('data shape: ', Test_data_gray.shape)
print('image shape: ', Test_data_gray[1].shape)
```

    BEFORE unflattening data 
    
    data shape:  (10000, 1024)
    AFTER unflattening data 
    
    data shape:  (10000, 32, 32, 1)
    image shape:  (32, 32, 1)
    


```python
# Print 5 random images from each superclass

Superclass_index = sorted(Test_coarse['coarse'].unique())

for s in Superclass_index:
    #create subplots
    plt.subplots(1,5, figsize=(10,10))
    print('superclass: ', s)
    print(Superclass_label.iloc[s]['Superclass_label'])
    
    for i in range(0,5):
        # find a random image of this superclass
        index = random.choice(Test_coarse.index[Test_coarse['coarse'] == s])

        # plot image
        image = Test_data_gray[index]
        plt.subplot(1,5,i+1) 
        plt.imshow(image, cmap='gray_r')
        
    plt.show()

```

    superclass:  0
    b'aquatic_mammals'
    


    
![png](output_63_1.png)
    


    superclass:  1
    b'fish'
    


    
![png](output_63_3.png)
    


    superclass:  2
    b'flowers'
    


    
![png](output_63_5.png)
    


    superclass:  3
    b'food_containers'
    


    
![png](output_63_7.png)
    


    superclass:  4
    b'fruit_and_vegetables'
    


    
![png](output_63_9.png)
    


    superclass:  5
    b'household_electrical_devices'
    


    
![png](output_63_11.png)
    


    superclass:  6
    b'household_furniture'
    


    
![png](output_63_13.png)
    


    superclass:  7
    b'insects'
    


    
![png](output_63_15.png)
    


    superclass:  8
    b'large_carnivores'
    


    
![png](output_63_17.png)
    


    superclass:  9
    b'large_man-made_outdoor_things'
    


    
![png](output_63_19.png)
    


    superclass:  10
    b'large_natural_outdoor_scenes'
    


    
![png](output_63_21.png)
    


    superclass:  11
    b'large_omnivores_and_herbivores'
    


    
![png](output_63_23.png)
    


    superclass:  12
    b'medium_mammals'
    


    
![png](output_63_25.png)
    


    superclass:  13
    b'non-insect_invertebrates'
    


    
![png](output_63_27.png)
    


    superclass:  14
    b'people'
    


    
![png](output_63_29.png)
    


    superclass:  15
    b'reptiles'
    


    
![png](output_63_31.png)
    


    superclass:  16
    b'small_mammals'
    


    
![png](output_63_33.png)
    


    superclass:  17
    b'trees'
    


    
![png](output_63_35.png)
    


    superclass:  18
    b'vehicles_1'
    


    
![png](output_63_37.png)
    


    superclass:  19
    b'vehicles_2'
    


    
![png](output_63_39.png)
    


## Meta data (aka labels)

Meta data file contains the names of each class and superclass. 


```python
Superclass_label = pd.DataFrame(meta[b'coarse_label_names']).rename(columns={0: 'Superclass_label'})
SL = Superclass_label['Superclass_label']
Superclass_label
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Superclass_label</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>b'aquatic_mammals'</td>
    </tr>
    <tr>
      <th>1</th>
      <td>b'fish'</td>
    </tr>
    <tr>
      <th>2</th>
      <td>b'flowers'</td>
    </tr>
    <tr>
      <th>3</th>
      <td>b'food_containers'</td>
    </tr>
    <tr>
      <th>4</th>
      <td>b'fruit_and_vegetables'</td>
    </tr>
    <tr>
      <th>5</th>
      <td>b'household_electrical_devices'</td>
    </tr>
    <tr>
      <th>6</th>
      <td>b'household_furniture'</td>
    </tr>
    <tr>
      <th>7</th>
      <td>b'insects'</td>
    </tr>
    <tr>
      <th>8</th>
      <td>b'large_carnivores'</td>
    </tr>
    <tr>
      <th>9</th>
      <td>b'large_man-made_outdoor_things'</td>
    </tr>
    <tr>
      <th>10</th>
      <td>b'large_natural_outdoor_scenes'</td>
    </tr>
    <tr>
      <th>11</th>
      <td>b'large_omnivores_and_herbivores'</td>
    </tr>
    <tr>
      <th>12</th>
      <td>b'medium_mammals'</td>
    </tr>
    <tr>
      <th>13</th>
      <td>b'non-insect_invertebrates'</td>
    </tr>
    <tr>
      <th>14</th>
      <td>b'people'</td>
    </tr>
    <tr>
      <th>15</th>
      <td>b'reptiles'</td>
    </tr>
    <tr>
      <th>16</th>
      <td>b'small_mammals'</td>
    </tr>
    <tr>
      <th>17</th>
      <td>b'trees'</td>
    </tr>
    <tr>
      <th>18</th>
      <td>b'vehicles_1'</td>
    </tr>
    <tr>
      <th>19</th>
      <td>b'vehicles_2'</td>
    </tr>
  </tbody>
</table>
</div>




```python
Class_label = pd.DataFrame(meta[b'fine_label_names']).rename(columns={0: 'Class_label'})
CL = Class_label['Class_label']
Class_label.T
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>0</th>
      <th>1</th>
      <th>2</th>
      <th>3</th>
      <th>4</th>
      <th>5</th>
      <th>6</th>
      <th>7</th>
      <th>8</th>
      <th>9</th>
      <th>10</th>
      <th>11</th>
      <th>12</th>
      <th>13</th>
      <th>14</th>
      <th>15</th>
      <th>16</th>
      <th>17</th>
      <th>18</th>
      <th>19</th>
      <th>20</th>
      <th>21</th>
      <th>22</th>
      <th>23</th>
      <th>24</th>
      <th>25</th>
      <th>26</th>
      <th>27</th>
      <th>28</th>
      <th>29</th>
      <th>30</th>
      <th>31</th>
      <th>32</th>
      <th>33</th>
      <th>34</th>
      <th>35</th>
      <th>36</th>
      <th>37</th>
      <th>38</th>
      <th>39</th>
      <th>40</th>
      <th>41</th>
      <th>42</th>
      <th>43</th>
      <th>44</th>
      <th>45</th>
      <th>46</th>
      <th>47</th>
      <th>48</th>
      <th>49</th>
      <th>50</th>
      <th>51</th>
      <th>52</th>
      <th>53</th>
      <th>54</th>
      <th>55</th>
      <th>56</th>
      <th>57</th>
      <th>58</th>
      <th>59</th>
      <th>60</th>
      <th>61</th>
      <th>62</th>
      <th>63</th>
      <th>64</th>
      <th>65</th>
      <th>66</th>
      <th>67</th>
      <th>68</th>
      <th>69</th>
      <th>70</th>
      <th>71</th>
      <th>72</th>
      <th>73</th>
      <th>74</th>
      <th>75</th>
      <th>76</th>
      <th>77</th>
      <th>78</th>
      <th>79</th>
      <th>80</th>
      <th>81</th>
      <th>82</th>
      <th>83</th>
      <th>84</th>
      <th>85</th>
      <th>86</th>
      <th>87</th>
      <th>88</th>
      <th>89</th>
      <th>90</th>
      <th>91</th>
      <th>92</th>
      <th>93</th>
      <th>94</th>
      <th>95</th>
      <th>96</th>
      <th>97</th>
      <th>98</th>
      <th>99</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Class_label</th>
      <td>b'apple'</td>
      <td>b'aquarium_fish'</td>
      <td>b'baby'</td>
      <td>b'bear'</td>
      <td>b'beaver'</td>
      <td>b'bed'</td>
      <td>b'bee'</td>
      <td>b'beetle'</td>
      <td>b'bicycle'</td>
      <td>b'bottle'</td>
      <td>b'bowl'</td>
      <td>b'boy'</td>
      <td>b'bridge'</td>
      <td>b'bus'</td>
      <td>b'butterfly'</td>
      <td>b'camel'</td>
      <td>b'can'</td>
      <td>b'castle'</td>
      <td>b'caterpillar'</td>
      <td>b'cattle'</td>
      <td>b'chair'</td>
      <td>b'chimpanzee'</td>
      <td>b'clock'</td>
      <td>b'cloud'</td>
      <td>b'cockroach'</td>
      <td>b'couch'</td>
      <td>b'crab'</td>
      <td>b'crocodile'</td>
      <td>b'cup'</td>
      <td>b'dinosaur'</td>
      <td>b'dolphin'</td>
      <td>b'elephant'</td>
      <td>b'flatfish'</td>
      <td>b'forest'</td>
      <td>b'fox'</td>
      <td>b'girl'</td>
      <td>b'hamster'</td>
      <td>b'house'</td>
      <td>b'kangaroo'</td>
      <td>b'keyboard'</td>
      <td>b'lamp'</td>
      <td>b'lawn_mower'</td>
      <td>b'leopard'</td>
      <td>b'lion'</td>
      <td>b'lizard'</td>
      <td>b'lobster'</td>
      <td>b'man'</td>
      <td>b'maple_tree'</td>
      <td>b'motorcycle'</td>
      <td>b'mountain'</td>
      <td>b'mouse'</td>
      <td>b'mushroom'</td>
      <td>b'oak_tree'</td>
      <td>b'orange'</td>
      <td>b'orchid'</td>
      <td>b'otter'</td>
      <td>b'palm_tree'</td>
      <td>b'pear'</td>
      <td>b'pickup_truck'</td>
      <td>b'pine_tree'</td>
      <td>b'plain'</td>
      <td>b'plate'</td>
      <td>b'poppy'</td>
      <td>b'porcupine'</td>
      <td>b'possum'</td>
      <td>b'rabbit'</td>
      <td>b'raccoon'</td>
      <td>b'ray'</td>
      <td>b'road'</td>
      <td>b'rocket'</td>
      <td>b'rose'</td>
      <td>b'sea'</td>
      <td>b'seal'</td>
      <td>b'shark'</td>
      <td>b'shrew'</td>
      <td>b'skunk'</td>
      <td>b'skyscraper'</td>
      <td>b'snail'</td>
      <td>b'snake'</td>
      <td>b'spider'</td>
      <td>b'squirrel'</td>
      <td>b'streetcar'</td>
      <td>b'sunflower'</td>
      <td>b'sweet_pepper'</td>
      <td>b'table'</td>
      <td>b'tank'</td>
      <td>b'telephone'</td>
      <td>b'television'</td>
      <td>b'tiger'</td>
      <td>b'tractor'</td>
      <td>b'train'</td>
      <td>b'trout'</td>
      <td>b'tulip'</td>
      <td>b'turtle'</td>
      <td>b'wardrobe'</td>
      <td>b'whale'</td>
      <td>b'willow_tree'</td>
      <td>b'wolf'</td>
      <td>b'woman'</td>
      <td>b'worm'</td>
    </tr>
  </tbody>
</table>
</div>



**Type, Shape and Keys**


```python
print('Type: ', type(train))
print('Type: ', type(Train_data))
print('Shape: ', Train_data.shape)
print('Keys: ', train.keys())
```

    Type:  <class 'dict'>
    Type:  <class 'numpy.ndarray'>
    Shape:  (50000, 32, 32, 3)
    Keys:  dict_keys([b'filenames', b'batch_label', b'fine_labels', b'coarse_labels', b'data'])
    


```python
print('Type: ', type(test))
print('Type: ', type(Test_data))
print('Shape: ', Test_data.shape)
print('Keys: ', test.keys())
```

    Type:  <class 'dict'>
    Type:  <class 'numpy.ndarray'>
    Shape:  (10000, 32, 32, 3)
    Keys:  dict_keys([b'filenames', b'batch_label', b'fine_labels', b'coarse_labels', b'data'])
    

## Random images from each superclass


```python
# Print 5 random images from each superclass

Superclass_index = sorted(Train_coarse['coarse'].unique())

for s in Superclass_index:
    #create subplots
    plt.subplots(1,5, figsize=(10,10))
    print('superclass: ', s)
    print(Superclass_label.iloc[s]['Superclass_label'])
    
    for i in range(0,5):
        # find a random image of this superclass
        index = random.choice(Train_coarse.index[Train_coarse['coarse'] == s])

        # plot image
        image = Train_data[index]
        plt.subplot(1,5,i+1) 
        plt.imshow(image)
        
    plt.show()

```

    superclass:  0
    b'aquatic_mammals'
    


    
![png](output_72_1.png)
    


    superclass:  1
    b'fish'
    


    
![png](output_72_3.png)
    


    superclass:  2
    b'flowers'
    


    
![png](output_72_5.png)
    


    superclass:  3
    b'food_containers'
    


    
![png](output_72_7.png)
    


    superclass:  4
    b'fruit_and_vegetables'
    


    
![png](output_72_9.png)
    


    superclass:  5
    b'household_electrical_devices'
    


    
![png](output_72_11.png)
    


    superclass:  6
    b'household_furniture'
    


    
![png](output_72_13.png)
    


    superclass:  7
    b'insects'
    


    
![png](output_72_15.png)
    


    superclass:  8
    b'large_carnivores'
    


    
![png](output_72_17.png)
    


    superclass:  9
    b'large_man-made_outdoor_things'
    


    
![png](output_72_19.png)
    


    superclass:  10
    b'large_natural_outdoor_scenes'
    


    
![png](output_72_21.png)
    


    superclass:  11
    b'large_omnivores_and_herbivores'
    


    
![png](output_72_23.png)
    


    superclass:  12
    b'medium_mammals'
    


    
![png](output_72_25.png)
    


    superclass:  13
    b'non-insect_invertebrates'
    


    
![png](output_72_27.png)
    


    superclass:  14
    b'people'
    


    
![png](output_72_29.png)
    


    superclass:  15
    b'reptiles'
    


    
![png](output_72_31.png)
    


    superclass:  16
    b'small_mammals'
    


    
![png](output_72_33.png)
    


    superclass:  17
    b'trees'
    


    
![png](output_72_35.png)
    


    superclass:  18
    b'vehicles_1'
    


    
![png](output_72_37.png)
    


    superclass:  19
    b'vehicles_2'
    


    
![png](output_72_39.png)
    


## Average of RGB for each superclass


```python
# Create list of Superclass index
Superclass_index = sorted(Train_coarse['coarse'].unique())
plt.subplots(4,5, figsize=(12,12))

for s in Superclass_index:
    # Find all the rows in data table that pertains to each superclass
    index_list = Train_coarse.index[Train_coarse['coarse'] == s]
    
    # Take the average all of those rows 
    averageRGB = np.mean(Train_data[index_list], axis=0, dtype=np.int64) # this will give [32,3,3] shape
    
    # print name of superclass
    title = s, ' ', Superclass_label.iloc[s]['Superclass_label']
    
    # plot image
    plt.subplot(4,5,s+1)
    plt.imshow(averageRGB)
    plt.title(title)

plt.tight_layout()
plt.show()
    
```


    
![png](output_74_0.png)
    


## Average of RGB for 25 random classes


```python
# Create list of Superclass index
Class_index = sorted(Train_fine['fine'].unique())
plt.subplots(5,5, figsize=(9,9))

for i in range(25):
    # take a random number from class index
    c = random.choice(Class_index)
    
    # Find all the rows in data table that pertains to each superclass
    index_list = Train_fine.index[Train_fine['fine'] == c]
    
    # Take the average all of those rows 
    averageRGB = np.mean(Train_data[index_list], axis=0, dtype=np.int64) # this will give [32,3,3] shape
    
    # print name of superclass
    title = c, ' ', Class_label.iloc[c]['Class_label']
    
    # plot image
    plt.subplot(5,5,i+1)
    plt.imshow(averageRGB)
    plt.title(title)

plt.tight_layout()
plt.show()
    
```


    
![png](output_76_0.png)
    


# Classification Models - Superclass

## Color - Superclass

### Basic Models - Logistic Regression

We will try out the basic model and see how the accuracy scores are.


```python
# Set our X_train, y_train and X_test, y_test

X_train_flat = Train_flat_data
y_train = np.array(train[b'coarse_labels']) #set coarse/superclass as our classification target

X_test_flat = Test_flat_data
y_test = np.array(test[b'coarse_labels'])
```


```python
from sklearn.linear_model import LogisticRegression

LR = LogisticRegression(random_state=1, n_jobs=-1)
LR.fit(X_train_flat, y_train)
print('Train score: ', LR.score(X_train_flat, y_train))
print('Test score: ', LR.score(X_test_flat, y_test))
```

    Train score:  0.29046
    Test score:  0.2597
    


```python
from sklearn.metrics import confusion_matrix
import seaborn as sns
# Make classifications based on the test features, and assign the classifications to a variable
LR_y_pred = LR.predict(X_test_flat)

# Build the confusion matrix as a dataframe
confusion_df = pd.DataFrame(confusion_matrix(y_test, LR_y_pred))
confusion_df.index = [f'Actually {i}' for i in Superclass_label['Superclass_label']]
confusion_df.columns = [f'Predicted {i}' for i in Superclass_label['Superclass_label']]


plt.figure(figsize = (12,12))
sns.heatmap(confusion_df,
            annot=True,
            cbar=False,
            cmap="rocket_r",
            linewidths=0.5
           )
plt.title('Confusion Matrix',size = 25,y=1.01)
plt.xlabel("Predicted Label", size = 20)
plt.ylabel("True Label", size = 20)
plt.show()
```


    
![png](output_83_0.png)
    


### Self-Constructed CNN

##### Set up train and test sets


```python
# Set our X_train, y_train and X_test, y_test

X_train = Train_data
y_train = Train_coarse #set coarse/superclass as our classification target

X_test = Test_data
y_test = Test_coarse
```


```python
print(f'X_train range: {X_train.min()}-{X_train.max()}')
print(f'X_train range: {X_test.min()}-{X_test.max()}')
```

    X_train range: 0-255
    X_train range: 0-255
    


```python
# Scale the X values to between 0 to 1
X_train = X_train.astype('float32')
X_test = X_test.astype('float32')
X_train /= 255
X_test /= 255
print(f'X_train range: {X_train.min()}-{X_train.max()}')
```

    X_train range: 0.0-1.0
    


```python
X_train.shape, y_train.shape, X_test.shape, y_test.shape
```




    ((50000, 32, 32, 3), (50000, 1), (10000, 32, 32, 3), (10000, 1))




```python
    #=========================================================================================
    # ACCURACY ON TEST SCORE
    #=========================================================================================
    
    def test_loss_score(model):

        # Evaluate the model's performance on the test data
        score = model.evaluate(X_test, y_test, verbose=3)

        print('Test loss:', score[0])
        print('Test accuracy:', score[1])
        print('\n', '\n')
    
    #=========================================================================================
     # TRAINING/VALIDATION ACCURACY AND LOSS
    #=========================================================================================
    
    def accuracy_loss_plots(model):
        # Set up two subplots
        plt.subplots(1, 2, figsize=(18, 6))

        # Plot accuracies
        plt.subplot(1, 2, 1)
        plt.plot(model.history['accuracy'], label='Train', marker='.')
        plt.plot(model.history['val_accuracy'], label='Validation', marker='.')
        plt.title('Accuracies Across Epochs')
        plt.xlabel('Epoch')
        plt.ylabel('Accuracy')
        plt.legend()

        # Plot losses
        plt.subplot(1, 2, 2)
        plt.plot(model.history['loss'], label='Train', marker='.')
        plt.plot(model.history['val_loss'], label='Validation', marker='.')
        plt.title('Losses Across Epochs')
        plt.xlabel('Epoch')
        plt.ylabel('Loss')
        plt.legend()

        # This ensures the subplots do not overlap
        plt.tight_layout()

        # Show the subplots
        plt.show()

    #=========================================================================================
    # CONFUSION MATRIX
    #=========================================================================================
   
    from sklearn.metrics import confusion_matrix
    def confusion(model):
        # Calculate the predicted labels for each test image.
        predict_probas = model.predict(X_test)
        y_predict = np.argmax(predict_probas, axis=1)

        # Create the confusion matrix using sklearn 
        conf_mat = confusion_matrix(y_test, y_predict)

        # Since we have many images, it is helpful to show our 
        # results as fractions of the total number of images 
        # for each class.
        normalized_conf_mat = conf_mat / conf_mat.sum(axis=1)

        normalized_conf_mat = pd.DataFrame(normalized_conf_mat, columns=SL).set_index(SL)

        plt.figure(figsize = (12,12))
        sns.heatmap(normalized_conf_mat,
                    annot=True,
                    cbar=False,
                    cmap="rocket_r",
                    linewidths=1
                   )
        plt.title('Confusion Matrix',size = 25,y=1.01)
        plt.xlabel("Predicted Label", size = 20)
        plt.ylabel("True Label", size = 20)
        plt.show()
        
ES = EarlyStopping(monitor='val_accuracy', patience=5, mode='auto', min_delta=0.0001, verbose=1)

```

##### CNN 1 - Model 1


```python
CNN_model = Sequential()

# Create simple CNN model architecture with Pooling for dimensionality reduction 
# and Dropout to reduce overfitting
CNN_model.add(Conv2D(32, kernel_size=(3, 3), activation = 'relu', input_shape = (32,32,3)))
CNN_model.add(MaxPooling2D(pool_size=(2, 2)))
CNN_model.add(Dropout(0.2))

CNN_model.add(Conv2D(64, kernel_size=(3, 3), activation = 'relu'))
CNN_model.add(MaxPooling2D(pool_size=(2, 2)))
CNN_model.add(Dropout(0.2))

CNN_model.add(Conv2D(256, kernel_size=(3, 3), activation = 'relu'))
CNN_model.add(MaxPooling2D(pool_size=(2, 2)))
CNN_model.add(Dropout(0.2))

# Flatten the output of our convolutional layers
CNN_model.add(Flatten())

# Add dense layers
CNN_model.add(Dense(256, activation= 'relu'))
CNN_model.add(Dense(64, activation= 'relu'))
CNN_model.add(Dense(32, activation= 'relu'))
CNN_model.add(Dense(len(np.unique(y_train)), activation='softmax'))

# Print out a summary of the network
CNN_model.summary()

# Compile the model with the desired loss function, optimizer, and metric(s) to track
CNN_model.compile(loss = 'sparse_categorical_crossentropy', 
                  optimizer = 'Adam',
                  metrics = ['accuracy'])

# Fit the model on the training data, defining desired batch_size & number of epochs,
# running validation after each batch
CNN1 = CNN_model.fit(X_train, y_train,
              batch_size = 128,
              epochs = 50,
              verbose = 1,
              validation_split = 0.2)



test_loss_score(CNN_model)
accuracy_loss_plots(CNN1)
confusion(CNN_model)
```

    Model: "sequential_11"
    _________________________________________________________________
    Layer (type)                 Output Shape              Param #   
    =================================================================
    conv2d_33 (Conv2D)           (None, 30, 30, 32)        896       
    _________________________________________________________________
    max_pooling2d_33 (MaxPooling (None, 15, 15, 32)        0         
    _________________________________________________________________
    dropout_33 (Dropout)         (None, 15, 15, 32)        0         
    _________________________________________________________________
    conv2d_34 (Conv2D)           (None, 13, 13, 64)        18496     
    _________________________________________________________________
    max_pooling2d_34 (MaxPooling (None, 6, 6, 64)          0         
    _________________________________________________________________
    dropout_34 (Dropout)         (None, 6, 6, 64)          0         
    _________________________________________________________________
    conv2d_35 (Conv2D)           (None, 4, 4, 256)         147712    
    _________________________________________________________________
    max_pooling2d_35 (MaxPooling (None, 2, 2, 256)         0         
    _________________________________________________________________
    dropout_35 (Dropout)         (None, 2, 2, 256)         0         
    _________________________________________________________________
    flatten_11 (Flatten)         (None, 1024)              0         
    _________________________________________________________________
    dense_44 (Dense)             (None, 256)               262400    
    _________________________________________________________________
    dense_45 (Dense)             (None, 64)                16448     
    _________________________________________________________________
    dense_46 (Dense)             (None, 32)                2080      
    _________________________________________________________________
    dense_47 (Dense)             (None, 20)                660       
    =================================================================
    Total params: 448,692
    Trainable params: 448,692
    Non-trainable params: 0
    _________________________________________________________________
    Epoch 1/50
    313/313 [==============================] - 21s 66ms/step - loss: 2.7316 - accuracy: 0.1368 - val_loss: 2.5351 - val_accuracy: 0.2182
    Epoch 2/50
    313/313 [==============================] - 22s 70ms/step - loss: 2.4384 - accuracy: 0.2428 - val_loss: 2.3380 - val_accuracy: 0.2770
    Epoch 3/50
    313/313 [==============================] - 22s 70ms/step - loss: 2.2461 - accuracy: 0.3020 - val_loss: 2.1590 - val_accuracy: 0.3355
    Epoch 4/50
    313/313 [==============================] - 22s 70ms/step - loss: 2.1065 - accuracy: 0.3438 - val_loss: 2.0770 - val_accuracy: 0.3557
    Epoch 5/50
    313/313 [==============================] - 22s 69ms/step - loss: 2.0078 - accuracy: 0.3758 - val_loss: 1.9794 - val_accuracy: 0.3908
    Epoch 6/50
    313/313 [==============================] - 22s 70ms/step - loss: 1.9254 - accuracy: 0.4001 - val_loss: 1.9102 - val_accuracy: 0.4135
    Epoch 7/50
    313/313 [==============================] - 22s 70ms/step - loss: 1.8571 - accuracy: 0.4222 - val_loss: 1.8474 - val_accuracy: 0.4250
    Epoch 8/50
    313/313 [==============================] - 22s 70ms/step - loss: 1.7909 - accuracy: 0.4402 - val_loss: 1.8370 - val_accuracy: 0.4315
    Epoch 9/50
    313/313 [==============================] - 22s 69ms/step - loss: 1.7295 - accuracy: 0.4593 - val_loss: 1.7435 - val_accuracy: 0.4558
    Epoch 10/50
    313/313 [==============================] - 22s 69ms/step - loss: 1.6822 - accuracy: 0.4735 - val_loss: 1.7465 - val_accuracy: 0.4608
    Epoch 11/50
    313/313 [==============================] - 21s 69ms/step - loss: 1.6338 - accuracy: 0.4878 - val_loss: 1.7024 - val_accuracy: 0.4728
    Epoch 12/50
    313/313 [==============================] - 22s 69ms/step - loss: 1.5884 - accuracy: 0.5005 - val_loss: 1.6598 - val_accuracy: 0.4843
    Epoch 13/50
    313/313 [==============================] - 22s 70ms/step - loss: 1.5411 - accuracy: 0.5134 - val_loss: 1.6768 - val_accuracy: 0.4845
    Epoch 14/50
    313/313 [==============================] - 22s 69ms/step - loss: 1.5100 - accuracy: 0.5256 - val_loss: 1.6187 - val_accuracy: 0.4953
    Epoch 15/50
    313/313 [==============================] - 22s 70ms/step - loss: 1.4679 - accuracy: 0.5374 - val_loss: 1.6158 - val_accuracy: 0.5041
    Epoch 16/50
    313/313 [==============================] - 22s 69ms/step - loss: 1.4326 - accuracy: 0.5499 - val_loss: 1.5939 - val_accuracy: 0.5071
    Epoch 17/50
    313/313 [==============================] - 22s 70ms/step - loss: 1.4012 - accuracy: 0.5581 - val_loss: 1.6441 - val_accuracy: 0.5009
    Epoch 18/50
    313/313 [==============================] - 22s 71ms/step - loss: 1.3677 - accuracy: 0.5653 - val_loss: 1.5830 - val_accuracy: 0.5175
    Epoch 19/50
    313/313 [==============================] - 22s 69ms/step - loss: 1.3427 - accuracy: 0.5743 - val_loss: 1.5717 - val_accuracy: 0.5206
    Epoch 20/50
    313/313 [==============================] - 22s 70ms/step - loss: 1.3113 - accuracy: 0.5836 - val_loss: 1.5942 - val_accuracy: 0.5140
    Epoch 21/50
    313/313 [==============================] - 22s 69ms/step - loss: 1.2767 - accuracy: 0.5951 - val_loss: 1.5798 - val_accuracy: 0.5166
    Epoch 22/50
    313/313 [==============================] - 22s 72ms/step - loss: 1.2576 - accuracy: 0.5986 - val_loss: 1.5663 - val_accuracy: 0.5210
    Epoch 23/50
    313/313 [==============================] - 22s 71ms/step - loss: 1.2293 - accuracy: 0.6070 - val_loss: 1.5606 - val_accuracy: 0.5240
    Epoch 24/50
    313/313 [==============================] - 22s 70ms/step - loss: 1.2082 - accuracy: 0.6130 - val_loss: 1.5815 - val_accuracy: 0.5225
    Epoch 25/50
    313/313 [==============================] - 22s 70ms/step - loss: 1.1771 - accuracy: 0.6225 - val_loss: 1.5908 - val_accuracy: 0.5230
    Epoch 26/50
    313/313 [==============================] - 22s 70ms/step - loss: 1.1661 - accuracy: 0.6265 - val_loss: 1.5729 - val_accuracy: 0.5262
    Epoch 27/50
    313/313 [==============================] - 22s 70ms/step - loss: 1.1528 - accuracy: 0.6288 - val_loss: 1.5813 - val_accuracy: 0.5221
    Epoch 28/50
    313/313 [==============================] - 21s 69ms/step - loss: 1.1240 - accuracy: 0.6384 - val_loss: 1.6116 - val_accuracy: 0.5213
    Epoch 29/50
    313/313 [==============================] - 22s 70ms/step - loss: 1.1066 - accuracy: 0.6429 - val_loss: 1.5827 - val_accuracy: 0.5300
    Epoch 30/50
    313/313 [==============================] - 22s 70ms/step - loss: 1.0936 - accuracy: 0.6485 - val_loss: 1.6120 - val_accuracy: 0.5223
    Epoch 31/50
    313/313 [==============================] - 22s 71ms/step - loss: 1.0609 - accuracy: 0.6566 - val_loss: 1.6025 - val_accuracy: 0.5264
    Epoch 32/50
    313/313 [==============================] - 22s 69ms/step - loss: 1.0564 - accuracy: 0.6600 - val_loss: 1.5952 - val_accuracy: 0.5299
    Epoch 33/50
    313/313 [==============================] - 22s 71ms/step - loss: 1.0399 - accuracy: 0.6654 - val_loss: 1.6133 - val_accuracy: 0.5235
    Epoch 34/50
    313/313 [==============================] - 22s 69ms/step - loss: 1.0184 - accuracy: 0.6686 - val_loss: 1.6009 - val_accuracy: 0.5321
    Epoch 35/50
    313/313 [==============================] - 24s 76ms/step - loss: 1.0067 - accuracy: 0.6759 - val_loss: 1.6637 - val_accuracy: 0.5228
    Epoch 36/50
    313/313 [==============================] - 24s 77ms/step - loss: 0.9950 - accuracy: 0.6779 - val_loss: 1.6483 - val_accuracy: 0.5256
    Epoch 37/50
    313/313 [==============================] - 22s 71ms/step - loss: 0.9773 - accuracy: 0.6823 - val_loss: 1.6169 - val_accuracy: 0.5324
    Epoch 38/50
    313/313 [==============================] - 22s 70ms/step - loss: 0.9618 - accuracy: 0.6867 - val_loss: 1.6631 - val_accuracy: 0.5331
    Epoch 39/50
    313/313 [==============================] - 22s 69ms/step - loss: 0.9499 - accuracy: 0.6895 - val_loss: 1.6556 - val_accuracy: 0.5271
    Epoch 40/50
    313/313 [==============================] - 22s 69ms/step - loss: 0.9368 - accuracy: 0.6955 - val_loss: 1.7012 - val_accuracy: 0.5240
    Epoch 41/50
    313/313 [==============================] - 22s 69ms/step - loss: 0.9222 - accuracy: 0.6981 - val_loss: 1.7016 - val_accuracy: 0.5193
    Epoch 42/50
    313/313 [==============================] - 21s 68ms/step - loss: 0.9185 - accuracy: 0.6996 - val_loss: 1.6803 - val_accuracy: 0.5267
    Epoch 43/50
    313/313 [==============================] - 22s 70ms/step - loss: 0.9128 - accuracy: 0.7010 - val_loss: 1.6657 - val_accuracy: 0.5241
    Epoch 44/50
    313/313 [==============================] - 22s 71ms/step - loss: 0.8866 - accuracy: 0.7096 - val_loss: 1.6885 - val_accuracy: 0.5288
    Epoch 45/50
    313/313 [==============================] - 21s 68ms/step - loss: 0.8752 - accuracy: 0.7144 - val_loss: 1.7137 - val_accuracy: 0.5259
    Epoch 46/50
    313/313 [==============================] - 23s 73ms/step - loss: 0.8737 - accuracy: 0.7140 - val_loss: 1.6806 - val_accuracy: 0.5310
    Epoch 47/50
    313/313 [==============================] - 23s 72ms/step - loss: 0.8623 - accuracy: 0.7175 - val_loss: 1.6829 - val_accuracy: 0.5282
    Epoch 48/50
    313/313 [==============================] - 22s 70ms/step - loss: 0.8539 - accuracy: 0.7202 - val_loss: 1.6897 - val_accuracy: 0.5238
    Epoch 49/50
    313/313 [==============================] - 22s 70ms/step - loss: 0.8476 - accuracy: 0.7210 - val_loss: 1.6847 - val_accuracy: 0.5288
    Epoch 50/50
    313/313 [==============================] - 22s 70ms/step - loss: 0.8370 - accuracy: 0.7249 - val_loss: 1.7292 - val_accuracy: 0.5228
    Test loss: 1.6694965362548828
    Test accuracy: 0.5331000089645386
    
     
    
    


    
![png](output_92_1.png)
    



    
![png](output_92_2.png)
    


##### CNN 1 - Model 2


```python
CNN_model2 = Sequential()

# Create simple CNN model architecture with Pooling for dimensionality reduction 
# and Dropout to reduce overfitting
CNN_model2.add(Conv2D(32, kernel_size=(3, 3), activation = 'relu', input_shape = (32,32,3)))
CNN_model2.add(MaxPooling2D(pool_size=(2, 2)))
CNN_model2.add(Dropout(0.1))

CNN_model2.add(Conv2D(64, kernel_size=(3, 3), activation = 'relu'))
CNN_model2.add(MaxPooling2D(pool_size=(2, 2)))
CNN_model2.add(Dropout(0.2))

CNN_model2.add(Conv2D(256, kernel_size=(3, 3), activation = 'relu'))
CNN_model2.add(MaxPooling2D(pool_size=(2, 2)))
CNN_model2.add(Dropout(0.4))

# Flatten the output of our convolutional layers
CNN_model2.add(Flatten())

# Add dense layers
CNN_model2.add(Dense(256, activation= 'relu'))
CNN_model2.add(Dense(64, activation= 'relu'))
CNN_model2.add(Dense(32, activation= 'relu'))
CNN_model2.add(Dense(len(np.unique(y_train)), activation='softmax'))

# Print out a summary of the network
CNN_model2.summary()

# Compile the model with the desired loss function, optimizer, and metric(s) to track
CNN_model2.compile(loss = 'sparse_categorical_crossentropy', 
                  optimizer = 'Adam',
                  metrics = ['accuracy'])

# Fit the model on the training data, defining desired batch_size & number of epochs,
# running validation after each batch
CNN2 = CNN_model2.fit(X_train, y_train,
              batch_size = 128,
              epochs = 50,
              verbose = 1,
              validation_split = 0.2)



test_loss_score(CNN_model2)
accuracy_loss_plots(CNN2)
confusion(CNN_model2)
```

    Model: "sequential_15"
    _________________________________________________________________
    Layer (type)                 Output Shape              Param #   
    =================================================================
    conv2d_49 (Conv2D)           (None, 30, 30, 32)        896       
    _________________________________________________________________
    max_pooling2d_45 (MaxPooling (None, 15, 15, 32)        0         
    _________________________________________________________________
    dropout_45 (Dropout)         (None, 15, 15, 32)        0         
    _________________________________________________________________
    conv2d_50 (Conv2D)           (None, 13, 13, 64)        18496     
    _________________________________________________________________
    max_pooling2d_46 (MaxPooling (None, 6, 6, 64)          0         
    _________________________________________________________________
    dropout_46 (Dropout)         (None, 6, 6, 64)          0         
    _________________________________________________________________
    conv2d_51 (Conv2D)           (None, 4, 4, 256)         147712    
    _________________________________________________________________
    max_pooling2d_47 (MaxPooling (None, 2, 2, 256)         0         
    _________________________________________________________________
    dropout_47 (Dropout)         (None, 2, 2, 256)         0         
    _________________________________________________________________
    flatten_14 (Flatten)         (None, 1024)              0         
    _________________________________________________________________
    dense_53 (Dense)             (None, 256)               262400    
    _________________________________________________________________
    dense_54 (Dense)             (None, 64)                16448     
    _________________________________________________________________
    dense_55 (Dense)             (None, 32)                2080      
    _________________________________________________________________
    dense_56 (Dense)             (None, 20)                660       
    =================================================================
    Total params: 448,692
    Trainable params: 448,692
    Non-trainable params: 0
    _________________________________________________________________
    Epoch 1/50
    313/313 [==============================] - 22s 70ms/step - loss: 2.7370 - accuracy: 0.1399 - val_loss: 2.5526 - val_accuracy: 0.2190
    Epoch 2/50
    313/313 [==============================] - 21s 68ms/step - loss: 2.4255 - accuracy: 0.2437 - val_loss: 2.3472 - val_accuracy: 0.2748
    Epoch 3/50
    313/313 [==============================] - 21s 68ms/step - loss: 2.2397 - accuracy: 0.3024 - val_loss: 2.1116 - val_accuracy: 0.3437
    Epoch 4/50
    313/313 [==============================] - 21s 68ms/step - loss: 2.1015 - accuracy: 0.3446 - val_loss: 1.9880 - val_accuracy: 0.3844
    Epoch 5/50
    313/313 [==============================] - 22s 71ms/step - loss: 2.0034 - accuracy: 0.3782 - val_loss: 1.9250 - val_accuracy: 0.4007
    Epoch 6/50
    313/313 [==============================] - 22s 70ms/step - loss: 1.9177 - accuracy: 0.4018 - val_loss: 1.8706 - val_accuracy: 0.4216
    Epoch 7/50
    313/313 [==============================] - 21s 69ms/step - loss: 1.8428 - accuracy: 0.4229 - val_loss: 1.7874 - val_accuracy: 0.4480
    Epoch 8/50
    313/313 [==============================] - 21s 68ms/step - loss: 1.7921 - accuracy: 0.4401 - val_loss: 1.8152 - val_accuracy: 0.4342
    Epoch 9/50
    313/313 [==============================] - 22s 71ms/step - loss: 1.7323 - accuracy: 0.4570 - val_loss: 1.7135 - val_accuracy: 0.4631
    Epoch 10/50
    313/313 [==============================] - 22s 71ms/step - loss: 1.6901 - accuracy: 0.4700 - val_loss: 1.6751 - val_accuracy: 0.4758
    Epoch 11/50
    313/313 [==============================] - 23s 73ms/step - loss: 1.6492 - accuracy: 0.4824 - val_loss: 1.6465 - val_accuracy: 0.4853
    Epoch 12/50
    313/313 [==============================] - 22s 71ms/step - loss: 1.6037 - accuracy: 0.4942 - val_loss: 1.6102 - val_accuracy: 0.4982
    Epoch 13/50
    313/313 [==============================] - 22s 71ms/step - loss: 1.5690 - accuracy: 0.5043 - val_loss: 1.5899 - val_accuracy: 0.5056
    Epoch 14/50
    313/313 [==============================] - 22s 71ms/step - loss: 1.5305 - accuracy: 0.5175 - val_loss: 1.5662 - val_accuracy: 0.5084
    Epoch 15/50
    313/313 [==============================] - 23s 73ms/step - loss: 1.5067 - accuracy: 0.5221 - val_loss: 1.5526 - val_accuracy: 0.5164
    Epoch 16/50
    313/313 [==============================] - 22s 71ms/step - loss: 1.4781 - accuracy: 0.5337 - val_loss: 1.5494 - val_accuracy: 0.5194
    Epoch 17/50
    313/313 [==============================] - 22s 71ms/step - loss: 1.4469 - accuracy: 0.5429 - val_loss: 1.5596 - val_accuracy: 0.5138
    Epoch 18/50
    313/313 [==============================] - 22s 71ms/step - loss: 1.4221 - accuracy: 0.5477 - val_loss: 1.5234 - val_accuracy: 0.5286
    Epoch 19/50
    313/313 [==============================] - 22s 70ms/step - loss: 1.3926 - accuracy: 0.5574 - val_loss: 1.4972 - val_accuracy: 0.5362
    Epoch 20/50
    313/313 [==============================] - 22s 70ms/step - loss: 1.3642 - accuracy: 0.5647 - val_loss: 1.4874 - val_accuracy: 0.5428
    Epoch 21/50
    313/313 [==============================] - 22s 72ms/step - loss: 1.3489 - accuracy: 0.5691 - val_loss: 1.4860 - val_accuracy: 0.5391
    Epoch 22/50
    313/313 [==============================] - 22s 71ms/step - loss: 1.3257 - accuracy: 0.5782 - val_loss: 1.5102 - val_accuracy: 0.5306
    Epoch 23/50
    313/313 [==============================] - 22s 71ms/step - loss: 1.3125 - accuracy: 0.5779 - val_loss: 1.5308 - val_accuracy: 0.5271
    Epoch 24/50
    313/313 [==============================] - 22s 71ms/step - loss: 1.2975 - accuracy: 0.5839 - val_loss: 1.5149 - val_accuracy: 0.5364
    Epoch 25/50
    313/313 [==============================] - 22s 71ms/step - loss: 1.2694 - accuracy: 0.5941 - val_loss: 1.4893 - val_accuracy: 0.5378
    Epoch 26/50
    313/313 [==============================] - 22s 71ms/step - loss: 1.2616 - accuracy: 0.5978 - val_loss: 1.4770 - val_accuracy: 0.5435
    Epoch 27/50
    313/313 [==============================] - 22s 71ms/step - loss: 1.2386 - accuracy: 0.6022 - val_loss: 1.4727 - val_accuracy: 0.5415
    Epoch 28/50
    313/313 [==============================] - 22s 71ms/step - loss: 1.2295 - accuracy: 0.6074 - val_loss: 1.4694 - val_accuracy: 0.5481
    Epoch 29/50
    313/313 [==============================] - 22s 71ms/step - loss: 1.2061 - accuracy: 0.6100 - val_loss: 1.4450 - val_accuracy: 0.5570
    Epoch 30/50
    313/313 [==============================] - 23s 74ms/step - loss: 1.1950 - accuracy: 0.6137 - val_loss: 1.4523 - val_accuracy: 0.5523
    Epoch 31/50
    313/313 [==============================] - 22s 71ms/step - loss: 1.1769 - accuracy: 0.6215 - val_loss: 1.4543 - val_accuracy: 0.5527
    Epoch 32/50
    313/313 [==============================] - 22s 71ms/step - loss: 1.1683 - accuracy: 0.6251 - val_loss: 1.4387 - val_accuracy: 0.5655
    Epoch 33/50
    313/313 [==============================] - 22s 72ms/step - loss: 1.1523 - accuracy: 0.6291 - val_loss: 1.4724 - val_accuracy: 0.5538
    Epoch 34/50
    313/313 [==============================] - 23s 74ms/step - loss: 1.1480 - accuracy: 0.6316 - val_loss: 1.4635 - val_accuracy: 0.5553
    Epoch 35/50
    313/313 [==============================] - 23s 72ms/step - loss: 1.1290 - accuracy: 0.6353 - val_loss: 1.4597 - val_accuracy: 0.5597
    Epoch 36/50
    313/313 [==============================] - 22s 71ms/step - loss: 1.1201 - accuracy: 0.6378 - val_loss: 1.4429 - val_accuracy: 0.5661
    Epoch 37/50
    313/313 [==============================] - 22s 71ms/step - loss: 1.1070 - accuracy: 0.6384 - val_loss: 1.4711 - val_accuracy: 0.5539
    Epoch 38/50
    313/313 [==============================] - 22s 71ms/step - loss: 1.1000 - accuracy: 0.6439 - val_loss: 1.4201 - val_accuracy: 0.5664
    Epoch 39/50
    313/313 [==============================] - 22s 71ms/step - loss: 1.0790 - accuracy: 0.6508 - val_loss: 1.4408 - val_accuracy: 0.5636
    Epoch 40/50
    313/313 [==============================] - 22s 72ms/step - loss: 1.0814 - accuracy: 0.6496 - val_loss: 1.4450 - val_accuracy: 0.5635
    Epoch 41/50
    313/313 [==============================] - 23s 73ms/step - loss: 1.0740 - accuracy: 0.6525 - val_loss: 1.4844 - val_accuracy: 0.5568
    Epoch 42/50
    313/313 [==============================] - 22s 71ms/step - loss: 1.0576 - accuracy: 0.6578 - val_loss: 1.4360 - val_accuracy: 0.5650
    Epoch 43/50
    313/313 [==============================] - 22s 71ms/step - loss: 1.0545 - accuracy: 0.6610 - val_loss: 1.4556 - val_accuracy: 0.5609
    Epoch 44/50
    313/313 [==============================] - 22s 71ms/step - loss: 1.0483 - accuracy: 0.6609 - val_loss: 1.4326 - val_accuracy: 0.5688
    Epoch 45/50
    313/313 [==============================] - 22s 72ms/step - loss: 1.0414 - accuracy: 0.6617 - val_loss: 1.4184 - val_accuracy: 0.5676
    Epoch 46/50
    313/313 [==============================] - 22s 71ms/step - loss: 1.0339 - accuracy: 0.6640 - val_loss: 1.4493 - val_accuracy: 0.5664
    Epoch 47/50
    313/313 [==============================] - 22s 71ms/step - loss: 1.0197 - accuracy: 0.6675 - val_loss: 1.4317 - val_accuracy: 0.5708
    Epoch 48/50
    313/313 [==============================] - 22s 71ms/step - loss: 1.0110 - accuracy: 0.6714 - val_loss: 1.4555 - val_accuracy: 0.5645
    Epoch 49/50
    313/313 [==============================] - 22s 71ms/step - loss: 1.0176 - accuracy: 0.6687 - val_loss: 1.4524 - val_accuracy: 0.5618
    Epoch 50/50
    313/313 [==============================] - 22s 71ms/step - loss: 1.0031 - accuracy: 0.6759 - val_loss: 1.4594 - val_accuracy: 0.5662
    Test loss: 1.4537464380264282
    Test accuracy: 0.5630999803543091
    
     
    
    


    
![png](output_94_1.png)
    



    
![png](output_94_2.png)
    


##### CNN 1 - Model 3


```python
CNN_model3 = Sequential()

# Create simple CNN model architecture with Pooling for dimensionality reduction 
# and Dropout to reduce overfitting
CNN_model3.add(Conv2D(128, kernel_size=(3, 3), activation = 'relu', input_shape = (32,32,3)))
CNN_model3.add(MaxPooling2D(pool_size=(2, 2)))
CNN_model3.add(Dropout(0.2))

CNN_model3.add(Conv2D(256, kernel_size=(3, 3), activation = 'relu'))
CNN_model3.add(MaxPooling2D(pool_size=(2, 2)))
CNN_model3.add(Dropout(0.2))

CNN_model3.add(Conv2D(512, kernel_size=(3, 3), activation = 'relu'))
CNN_model3.add(MaxPooling2D(pool_size=(2, 2)))
CNN_model3.add(Dropout(0.2))

# Flatten the output of our convolutional layers
CNN_model3.add(Flatten())

# Add dense layers
CNN_model3.add(Dense(512, activation= 'relu'))
CNN_model3.add(Dense(256, activation= 'relu'))
CNN_model3.add(Dense(128, activation= 'relu'))
CNN_model3.add(Dense(len(np.unique(y_train)), activation='softmax'))

# Print out a summary of the network
CNN_model3.summary()

# Compile the model with the desired loss function, optimizer, and metric(s) to track
CNN_model3.compile(loss = 'sparse_categorical_crossentropy', 
                  optimizer = 'Adam',
                  metrics = ['accuracy'])

# Fit the model on the training data, defining desired batch_size & number of epochs,
# running validation after each batch
CNN3 = CNN_model3.fit(X_train, y_train,
              batch_size = 128,
              epochs = 50,
              verbose = 1,
              validation_split = 0.2)



test_loss_score(CNN_model3)
accuracy_loss_plots(CNN3)
confusion(CNN_model3)
```

    Model: "sequential_16"
    _________________________________________________________________
    Layer (type)                 Output Shape              Param #   
    =================================================================
    conv2d_52 (Conv2D)           (None, 30, 30, 128)       3584      
    _________________________________________________________________
    max_pooling2d_48 (MaxPooling (None, 15, 15, 128)       0         
    _________________________________________________________________
    dropout_48 (Dropout)         (None, 15, 15, 128)       0         
    _________________________________________________________________
    conv2d_53 (Conv2D)           (None, 13, 13, 256)       295168    
    _________________________________________________________________
    max_pooling2d_49 (MaxPooling (None, 6, 6, 256)         0         
    _________________________________________________________________
    dropout_49 (Dropout)         (None, 6, 6, 256)         0         
    _________________________________________________________________
    conv2d_54 (Conv2D)           (None, 4, 4, 512)         1180160   
    _________________________________________________________________
    max_pooling2d_50 (MaxPooling (None, 2, 2, 512)         0         
    _________________________________________________________________
    dropout_50 (Dropout)         (None, 2, 2, 512)         0         
    _________________________________________________________________
    flatten_15 (Flatten)         (None, 2048)              0         
    _________________________________________________________________
    dense_57 (Dense)             (None, 512)               1049088   
    _________________________________________________________________
    dense_58 (Dense)             (None, 256)               131328    
    _________________________________________________________________
    dense_59 (Dense)             (None, 128)               32896     
    _________________________________________________________________
    dense_60 (Dense)             (None, 20)                2580      
    =================================================================
    Total params: 2,694,804
    Trainable params: 2,694,804
    Non-trainable params: 0
    _________________________________________________________________
    Epoch 1/50
    313/313 [==============================] - 141s 450ms/step - loss: 2.6009 - accuracy: 0.1866 - val_loss: 2.3475 - val_accuracy: 0.2655
    Epoch 2/50
    313/313 [==============================] - 135s 430ms/step - loss: 2.2364 - accuracy: 0.3047 - val_loss: 2.0788 - val_accuracy: 0.3518
    Epoch 3/50
    313/313 [==============================] - 136s 433ms/step - loss: 2.0135 - accuracy: 0.3746 - val_loss: 1.9713 - val_accuracy: 0.3887
    Epoch 4/50
    313/313 [==============================] - 135s 430ms/step - loss: 1.8475 - accuracy: 0.4237 - val_loss: 1.8172 - val_accuracy: 0.4338
    Epoch 5/50
    313/313 [==============================] - 135s 430ms/step - loss: 1.7015 - accuracy: 0.4638 - val_loss: 1.7162 - val_accuracy: 0.4690
    Epoch 6/50
    313/313 [==============================] - 135s 432ms/step - loss: 1.5801 - accuracy: 0.5020 - val_loss: 1.6460 - val_accuracy: 0.4906
    Epoch 7/50
    313/313 [==============================] - 135s 431ms/step - loss: 1.4703 - accuracy: 0.5359 - val_loss: 1.6172 - val_accuracy: 0.5002
    Epoch 8/50
    313/313 [==============================] - 134s 429ms/step - loss: 1.3764 - accuracy: 0.5620 - val_loss: 1.6158 - val_accuracy: 0.5063
    Epoch 9/50
    313/313 [==============================] - 134s 428ms/step - loss: 1.2752 - accuracy: 0.5942 - val_loss: 1.5302 - val_accuracy: 0.5267
    Epoch 10/50
    313/313 [==============================] - 134s 430ms/step - loss: 1.1825 - accuracy: 0.6222 - val_loss: 1.5249 - val_accuracy: 0.5355
    Epoch 11/50
    313/313 [==============================] - 134s 427ms/step - loss: 1.1059 - accuracy: 0.6460 - val_loss: 1.5363 - val_accuracy: 0.5371
    Epoch 12/50
    313/313 [==============================] - 133s 426ms/step - loss: 1.0327 - accuracy: 0.6661 - val_loss: 1.5215 - val_accuracy: 0.5473
    Epoch 13/50
    313/313 [==============================] - 133s 425ms/step - loss: 0.9593 - accuracy: 0.6901 - val_loss: 1.5767 - val_accuracy: 0.5372
    Epoch 14/50
    313/313 [==============================] - 133s 426ms/step - loss: 0.8919 - accuracy: 0.7101 - val_loss: 1.5586 - val_accuracy: 0.5576
    Epoch 15/50
    313/313 [==============================] - 32264s 103s/step - loss: 0.8370 - accuracy: 0.7257 - val_loss: 1.5790 - val_accuracy: 0.5545
    Epoch 16/50
    313/313 [==============================] - 155s 497ms/step - loss: 0.7805 - accuracy: 0.7459 - val_loss: 1.6494 - val_accuracy: 0.5400
    Epoch 17/50
    313/313 [==============================] - 157s 502ms/step - loss: 0.7358 - accuracy: 0.7590 - val_loss: 1.6670 - val_accuracy: 0.5414
    Epoch 18/50
    313/313 [==============================] - 144s 461ms/step - loss: 0.6840 - accuracy: 0.7740 - val_loss: 1.7260 - val_accuracy: 0.5465
    Epoch 19/50
    313/313 [==============================] - 147s 468ms/step - loss: 0.6452 - accuracy: 0.7854 - val_loss: 1.7486 - val_accuracy: 0.5469
    Epoch 20/50
    313/313 [==============================] - 142s 454ms/step - loss: 0.6155 - accuracy: 0.7965 - val_loss: 1.6950 - val_accuracy: 0.5566
    Epoch 21/50
    313/313 [==============================] - 137s 438ms/step - loss: 0.5736 - accuracy: 0.8097 - val_loss: 1.8413 - val_accuracy: 0.5463
    Epoch 22/50
    313/313 [==============================] - 138s 440ms/step - loss: 0.5326 - accuracy: 0.8217 - val_loss: 1.8195 - val_accuracy: 0.5552
    Epoch 23/50
    313/313 [==============================] - 137s 437ms/step - loss: 0.5228 - accuracy: 0.8268 - val_loss: 1.8264 - val_accuracy: 0.5550
    Epoch 24/50
    313/313 [==============================] - 136s 435ms/step - loss: 0.4995 - accuracy: 0.8357 - val_loss: 1.8971 - val_accuracy: 0.5423
    Epoch 25/50
    313/313 [==============================] - 140s 446ms/step - loss: 0.4719 - accuracy: 0.8442 - val_loss: 1.9538 - val_accuracy: 0.5455
    Epoch 26/50
    313/313 [==============================] - 140s 447ms/step - loss: 0.4549 - accuracy: 0.8490 - val_loss: 1.9963 - val_accuracy: 0.5490
    Epoch 27/50
    313/313 [==============================] - 136s 434ms/step - loss: 0.4311 - accuracy: 0.8561 - val_loss: 2.0067 - val_accuracy: 0.5485
    Epoch 28/50
    313/313 [==============================] - 139s 443ms/step - loss: 0.4158 - accuracy: 0.8622 - val_loss: 2.0466 - val_accuracy: 0.5454
    Epoch 29/50
    313/313 [==============================] - 136s 434ms/step - loss: 0.4038 - accuracy: 0.8666 - val_loss: 2.0662 - val_accuracy: 0.5407
    Epoch 30/50
    313/313 [==============================] - 139s 444ms/step - loss: 0.3863 - accuracy: 0.8714 - val_loss: 2.0698 - val_accuracy: 0.5496
    Epoch 31/50
    313/313 [==============================] - 154s 491ms/step - loss: 0.3777 - accuracy: 0.8780 - val_loss: 2.0651 - val_accuracy: 0.5471
    Epoch 32/50
    313/313 [==============================] - 141s 450ms/step - loss: 0.3756 - accuracy: 0.8755 - val_loss: 2.0902 - val_accuracy: 0.5470
    Epoch 33/50
    313/313 [==============================] - 139s 446ms/step - loss: 0.3449 - accuracy: 0.8840 - val_loss: 2.1876 - val_accuracy: 0.5328
    Epoch 34/50
    313/313 [==============================] - 139s 444ms/step - loss: 0.3474 - accuracy: 0.8837 - val_loss: 2.1845 - val_accuracy: 0.5484
    Epoch 35/50
    313/313 [==============================] - 139s 443ms/step - loss: 0.3334 - accuracy: 0.8882 - val_loss: 2.2441 - val_accuracy: 0.5461
    Epoch 36/50
    313/313 [==============================] - 139s 444ms/step - loss: 0.3222 - accuracy: 0.8942 - val_loss: 2.1943 - val_accuracy: 0.5451
    Epoch 37/50
    313/313 [==============================] - 137s 439ms/step - loss: 0.3224 - accuracy: 0.8942 - val_loss: 2.1578 - val_accuracy: 0.5468
    Epoch 38/50
    313/313 [==============================] - 140s 447ms/step - loss: 0.3036 - accuracy: 0.9008 - val_loss: 2.2991 - val_accuracy: 0.5461
    Epoch 39/50
    313/313 [==============================] - 142s 453ms/step - loss: 0.3092 - accuracy: 0.8988 - val_loss: 2.2325 - val_accuracy: 0.5394
    Epoch 40/50
    313/313 [==============================] - 142s 453ms/step - loss: 0.2954 - accuracy: 0.9036 - val_loss: 2.1999 - val_accuracy: 0.5458
    Epoch 41/50
    313/313 [==============================] - 140s 448ms/step - loss: 0.2857 - accuracy: 0.9039 - val_loss: 2.3784 - val_accuracy: 0.5327
    Epoch 42/50
    313/313 [==============================] - 140s 448ms/step - loss: 0.2814 - accuracy: 0.9069 - val_loss: 2.3705 - val_accuracy: 0.5431
    Epoch 43/50
    313/313 [==============================] - 140s 448ms/step - loss: 0.3008 - accuracy: 0.9013 - val_loss: 2.3054 - val_accuracy: 0.5472
    Epoch 44/50
    313/313 [==============================] - 140s 446ms/step - loss: 0.2700 - accuracy: 0.9099 - val_loss: 2.4313 - val_accuracy: 0.5443
    Epoch 45/50
    313/313 [==============================] - 139s 445ms/step - loss: 0.2733 - accuracy: 0.9103 - val_loss: 2.3512 - val_accuracy: 0.5402
    Epoch 46/50
    313/313 [==============================] - 135s 430ms/step - loss: 0.2668 - accuracy: 0.9123 - val_loss: 2.3687 - val_accuracy: 0.5467
    Epoch 47/50
    313/313 [==============================] - 137s 439ms/step - loss: 0.2558 - accuracy: 0.9184 - val_loss: 2.4111 - val_accuracy: 0.5344
    Epoch 48/50
    313/313 [==============================] - 135s 433ms/step - loss: 0.2540 - accuracy: 0.9166 - val_loss: 2.4064 - val_accuracy: 0.5377
    Epoch 49/50
    313/313 [==============================] - 140s 448ms/step - loss: 0.2572 - accuracy: 0.9161 - val_loss: 2.3527 - val_accuracy: 0.5421
    Epoch 50/50
    313/313 [==============================] - 142s 452ms/step - loss: 0.2534 - accuracy: 0.9171 - val_loss: 2.3972 - val_accuracy: 0.5428
    Test loss: 2.3179287910461426
    Test accuracy: 0.5450999736785889
    
     
    
    


    
![png](output_96_1.png)
    



    
![png](output_96_2.png)
    


##### CNN 1 - Model 4


```python

CNN_model4 = Sequential()

# Create simple CNN model architecture with Pooling for dimensionality reduction 
# and Dropout to reduce overfitting
CNN_model4.add(Conv2D(128, kernel_size=(3, 3), activation = 'relu', input_shape = (32,32,3)))
CNN_model4.add(MaxPooling2D(pool_size=(2, 2)))
CNN_model4.add(Dropout(0.1))

CNN_model4.add(Conv2D(256, kernel_size=(3, 3), activation = 'relu'))
CNN_model4.add(MaxPooling2D(pool_size=(2, 2)))
CNN_model4.add(Dropout(0.2))

CNN_model4.add(Conv2D(512, kernel_size=(3, 3), activation = 'relu'))
CNN_model4.add(MaxPooling2D(pool_size=(2, 2)))
CNN_model4.add(Dropout(0.4))

# Flatten the output of our convolutional layers
CNN_model4.add(Flatten())

# Add dense layers
CNN_model4.add(Dense(512, activation= 'relu'))
CNN_model4.add(Dense(256, activation= 'relu'))
CNN_model4.add(Dense(128, activation= 'relu'))
CNN_model4.add(Dense(len(np.unique(y_train)), activation='softmax'))

# Print out a summary of the network
CNN_model4.summary()

# Compile the model with the desired loss function, optimizer, and metric(s) to track
CNN_model4.compile(loss = 'sparse_categorical_crossentropy', 
                  optimizer = 'Adam',
                  metrics = ['accuracy'])

# Fit the model on the training data, defining desired batch_size & number of epochs,
# running validation after each batch
CNN4 = CNN_model4.fit(X_train, y_train,
              batch_size = 128,
              epochs = 50,
              verbose = 1,
              validation_split = 0.2,
              callbacks = ES)

```

    Model: "sequential_2"
    _________________________________________________________________
    Layer (type)                 Output Shape              Param #   
    =================================================================
    conv2d_6 (Conv2D)            (None, 30, 30, 128)       3584      
    _________________________________________________________________
    max_pooling2d_6 (MaxPooling2 (None, 15, 15, 128)       0         
    _________________________________________________________________
    dropout_6 (Dropout)          (None, 15, 15, 128)       0         
    _________________________________________________________________
    conv2d_7 (Conv2D)            (None, 13, 13, 256)       295168    
    _________________________________________________________________
    max_pooling2d_7 (MaxPooling2 (None, 6, 6, 256)         0         
    _________________________________________________________________
    dropout_7 (Dropout)          (None, 6, 6, 256)         0         
    _________________________________________________________________
    conv2d_8 (Conv2D)            (None, 4, 4, 512)         1180160   
    _________________________________________________________________
    max_pooling2d_8 (MaxPooling2 (None, 2, 2, 512)         0         
    _________________________________________________________________
    dropout_8 (Dropout)          (None, 2, 2, 512)         0         
    _________________________________________________________________
    flatten_2 (Flatten)          (None, 2048)              0         
    _________________________________________________________________
    dense_7 (Dense)              (None, 512)               1049088   
    _________________________________________________________________
    dense_8 (Dense)              (None, 256)               131328    
    _________________________________________________________________
    dense_9 (Dense)              (None, 128)               32896     
    _________________________________________________________________
    dense_10 (Dense)             (None, 20)                2580      
    =================================================================
    Total params: 2,694,804
    Trainable params: 2,694,804
    Non-trainable params: 0
    _________________________________________________________________
    Epoch 1/50
    313/313 [==============================] - 142s 455ms/step - loss: 2.6503 - accuracy: 0.1664 - val_loss: 2.4409 - val_accuracy: 0.2365
    Epoch 2/50
    313/313 [==============================] - 140s 447ms/step - loss: 2.3167 - accuracy: 0.2774 - val_loss: 2.1810 - val_accuracy: 0.3217
    Epoch 3/50
    313/313 [==============================] - 141s 451ms/step - loss: 2.1022 - accuracy: 0.3451 - val_loss: 1.9788 - val_accuracy: 0.3979
    Epoch 4/50
    313/313 [==============================] - 140s 447ms/step - loss: 1.9430 - accuracy: 0.3908 - val_loss: 1.8857 - val_accuracy: 0.4176
    Epoch 5/50
    313/313 [==============================] - 139s 444ms/step - loss: 1.8270 - accuracy: 0.4270 - val_loss: 1.7779 - val_accuracy: 0.4484
    Epoch 6/50
    313/313 [==============================] - 141s 451ms/step - loss: 1.7149 - accuracy: 0.4621 - val_loss: 1.6945 - val_accuracy: 0.4693
    Epoch 7/50
    313/313 [==============================] - 135s 431ms/step - loss: 1.6191 - accuracy: 0.4898 - val_loss: 1.6414 - val_accuracy: 0.4888
    Epoch 8/50
    313/313 [==============================] - 135s 432ms/step - loss: 1.5423 - accuracy: 0.5134 - val_loss: 1.6076 - val_accuracy: 0.5012
    Epoch 9/50
    313/313 [==============================] - 135s 432ms/step - loss: 1.4642 - accuracy: 0.5360 - val_loss: 1.5972 - val_accuracy: 0.5060
    Epoch 10/50
    313/313 [==============================] - 135s 431ms/step - loss: 1.3986 - accuracy: 0.5562 - val_loss: 1.5407 - val_accuracy: 0.5205
    Epoch 11/50
    313/313 [==============================] - 135s 431ms/step - loss: 1.3331 - accuracy: 0.5781 - val_loss: 1.4929 - val_accuracy: 0.5376
    Epoch 12/50
    313/313 [==============================] - 135s 431ms/step - loss: 1.2737 - accuracy: 0.5908 - val_loss: 1.5005 - val_accuracy: 0.5345
    Epoch 13/50
    313/313 [==============================] - 137s 436ms/step - loss: 1.2272 - accuracy: 0.6068 - val_loss: 1.4825 - val_accuracy: 0.5483
    Epoch 14/50
    313/313 [==============================] - 138s 442ms/step - loss: 1.1705 - accuracy: 0.6246 - val_loss: 1.4642 - val_accuracy: 0.5520
    Epoch 15/50
    313/313 [==============================] - 135s 432ms/step - loss: 1.1149 - accuracy: 0.6419 - val_loss: 1.4522 - val_accuracy: 0.5570
    Epoch 16/50
    313/313 [==============================] - 136s 435ms/step - loss: 1.0774 - accuracy: 0.6520 - val_loss: 1.4749 - val_accuracy: 0.5566
    Epoch 17/50
    313/313 [==============================] - 140s 447ms/step - loss: 1.0425 - accuracy: 0.6616 - val_loss: 1.4767 - val_accuracy: 0.5573
    Epoch 18/50
    313/313 [==============================] - 137s 437ms/step - loss: 1.0009 - accuracy: 0.6758 - val_loss: 1.5013 - val_accuracy: 0.5573
    Epoch 19/50
    313/313 [==============================] - 137s 437ms/step - loss: 0.9633 - accuracy: 0.6855 - val_loss: 1.4839 - val_accuracy: 0.5610
    Epoch 20/50
    313/313 [==============================] - 137s 438ms/step - loss: 0.9320 - accuracy: 0.6945 - val_loss: 1.4862 - val_accuracy: 0.5673
    Epoch 21/50
    313/313 [==============================] - 140s 448ms/step - loss: 0.9062 - accuracy: 0.7047 - val_loss: 1.4511 - val_accuracy: 0.5709
    Epoch 22/50
    313/313 [==============================] - 141s 449ms/step - loss: 0.8654 - accuracy: 0.7154 - val_loss: 1.5016 - val_accuracy: 0.5622
    Epoch 23/50
    313/313 [==============================] - 137s 437ms/step - loss: 0.8384 - accuracy: 0.7226 - val_loss: 1.5010 - val_accuracy: 0.5678
    Epoch 24/50
    313/313 [==============================] - 137s 437ms/step - loss: 0.8144 - accuracy: 0.7313 - val_loss: 1.5189 - val_accuracy: 0.5689
    Epoch 25/50
    313/313 [==============================] - 142s 452ms/step - loss: 0.7910 - accuracy: 0.7403 - val_loss: 1.5058 - val_accuracy: 0.5735
    Epoch 26/50
    313/313 [==============================] - 141s 450ms/step - loss: 0.7812 - accuracy: 0.7425 - val_loss: 1.5285 - val_accuracy: 0.5729
    Epoch 27/50
    313/313 [==============================] - 137s 439ms/step - loss: 0.7484 - accuracy: 0.7527 - val_loss: 1.5476 - val_accuracy: 0.5671
    Epoch 28/50
    313/313 [==============================] - 137s 438ms/step - loss: 0.7264 - accuracy: 0.7612 - val_loss: 1.5664 - val_accuracy: 0.5633
    Epoch 29/50
    313/313 [==============================] - 139s 443ms/step - loss: 0.7067 - accuracy: 0.7668 - val_loss: 1.5762 - val_accuracy: 0.5722
    Epoch 30/50
    313/313 [==============================] - 141s 450ms/step - loss: 0.6842 - accuracy: 0.7742 - val_loss: 1.5947 - val_accuracy: 0.5651
    Epoch 00030: early stopping
    Test loss: 1.5371804237365723
    Test accuracy: 0.567799985408783
    
     
    
    


    
![png](output_98_1.png)
    



    ---------------------------------------------------------------------------

    NameError                                 Traceback (most recent call last)

    <ipython-input-50-b7fb15837882> in <module>
         43 test_loss_score(CNN_model4)
         44 accuracy_loss_plots(CNN4)
    ---> 45 confusion(CNN_model4)
    

    <ipython-input-49-543da0387769> in confusion(model)
         65 
         66     plt.figure(figsize = (12,12))
    ---> 67     sns.heatmap(normalized_conf_mat,
         68                 annot=True,
         69                 cbar=False,
    

    NameError: name 'sns' is not defined



    <Figure size 864x864 with 0 Axes>



```python
test_loss_score(CNN_model4)
accuracy_loss_plots(CNN4)
confusion(CNN_model4)
```

    Test loss: 1.5371804237365723
    Test accuracy: 0.567799985408783
    
     
    
    


    
![png](output_99_1.png)
    



    
![png](output_99_2.png)
    


https://arxiv.org/pdf/1511.07289.pdf

##### CNN 2 - Model 5


```python
optim = Adam(lr=0.9)

CNN_model5 = Sequential()

# Create simple CNN model architecture with Pooling for dimensionality reduction 
# and Dropout to reduce overfitting
CNN_model5.add(Conv2D(192, kernel_size=(5, 5), activation = 'elu', input_shape = (32,32,3), kernel_regularizer=l2(0.0005))) 
CNN_model5.add(MaxPooling2D(pool_size=(2, 2), padding='same'))
CNN_model5.add(Dropout(0.0))

CNN_model5.add(Conv2D(192, kernel_size=(1, 1), activation = 'elu', padding='same', kernel_regularizer=l2(0.0005)))
CNN_model5.add(Conv2D(240, kernel_size=(3, 3), activation = 'elu', padding='same', kernel_regularizer=l2(0.0005)))
CNN_model5.add(MaxPooling2D(pool_size=(2, 2), padding='same'))
CNN_model5.add(Dropout(0.1))

CNN_model5.add(Conv2D(240, kernel_size=(1,1), activation = 'elu', padding='same', kernel_regularizer=l2(0.0005)))
CNN_model5.add(Conv2D(260, kernel_size=(2,2), activation = 'elu', padding='same', kernel_regularizer=l2(0.0005)))
CNN_model5.add(MaxPooling2D(pool_size=(2, 2), padding='same'))
CNN_model5.add(Dropout(0.2))

CNN_model5.add(Conv2D(260, kernel_size=(1,1), activation = 'elu', padding='same', kernel_regularizer=l2(0.0005)))
CNN_model5.add(Conv2D(280, kernel_size=(2,2), activation = 'elu', padding='same', kernel_regularizer=l2(0.0005)))
CNN_model5.add(MaxPooling2D(pool_size=(2, 2), padding='same'))
CNN_model5.add(Dropout(0.3))

CNN_model5.add(Conv2D(280, kernel_size=(1,1), activation = 'elu', padding='same', kernel_regularizer=l2(0.0005)))
CNN_model5.add(Conv2D(300, kernel_size=(2,2), activation = 'elu', padding='same', kernel_regularizer=l2(0.0005)))
CNN_model5.add(MaxPooling2D(pool_size=(2, 2), padding='same'))
CNN_model5.add(Dropout(0.4))

CNN_model5.add(Conv2D(300, kernel_size=(2,2), activation = 'elu', padding='same', kernel_regularizer=l2(0.0005)))
CNN_model5.add(MaxPooling2D(pool_size=(2, 2), padding='same'))
CNN_model5.add(Dropout(0.5))

# Flatten the output of our convolutional layers
CNN_model5.add(Flatten())

# Add dense layers
CNN_model5.add(Dense(len(np.unique(y_train)), activation='softmax'))

# Print out a summary of the network
CNN_model5.summary()

# Compile the model with the desired loss function, optimizer, and metric(s) to track
CNN_model5.compile(loss = 'sparse_categorical_crossentropy', #cross entropy is for multi-class classification
                  optimizer = 'Adam',
                  metrics = ['accuracy'])

# Fit the model on the training data, defining desired batch_size & number of epochs,
# running validation after each batch
CNN5 = CNN_model5.fit(X_train, y_train,
              batch_size = 128,
              epochs = 100,
              verbose = 1,
              validation_split = 0.2,
              callbacks=ES)

test_loss_score(CNN_model5)
accuracy_loss_plots(CNN5)
confusion(CNN_model5)
CNN_model5.save('CNNmodels/CNN_model5.h5')
```

    Model: "sequential_20"
    _________________________________________________________________
    Layer (type)                 Output Shape              Param #   
    =================================================================
    conv2d_156 (Conv2D)          (None, 28, 28, 192)       14592     
    _________________________________________________________________
    max_pooling2d_93 (MaxPooling (None, 14, 14, 192)       0         
    _________________________________________________________________
    dropout_84 (Dropout)         (None, 14, 14, 192)       0         
    _________________________________________________________________
    conv2d_157 (Conv2D)          (None, 14, 14, 192)       37056     
    _________________________________________________________________
    conv2d_158 (Conv2D)          (None, 14, 14, 240)       414960    
    _________________________________________________________________
    max_pooling2d_94 (MaxPooling (None, 7, 7, 240)         0         
    _________________________________________________________________
    dropout_85 (Dropout)         (None, 7, 7, 240)         0         
    _________________________________________________________________
    conv2d_159 (Conv2D)          (None, 7, 7, 240)         57840     
    _________________________________________________________________
    conv2d_160 (Conv2D)          (None, 7, 7, 260)         249860    
    _________________________________________________________________
    max_pooling2d_95 (MaxPooling (None, 4, 4, 260)         0         
    _________________________________________________________________
    dropout_86 (Dropout)         (None, 4, 4, 260)         0         
    _________________________________________________________________
    conv2d_161 (Conv2D)          (None, 4, 4, 260)         67860     
    _________________________________________________________________
    conv2d_162 (Conv2D)          (None, 4, 4, 280)         291480    
    _________________________________________________________________
    max_pooling2d_96 (MaxPooling (None, 2, 2, 280)         0         
    _________________________________________________________________
    dropout_87 (Dropout)         (None, 2, 2, 280)         0         
    _________________________________________________________________
    conv2d_163 (Conv2D)          (None, 2, 2, 280)         78680     
    _________________________________________________________________
    conv2d_164 (Conv2D)          (None, 2, 2, 300)         336300    
    _________________________________________________________________
    max_pooling2d_97 (MaxPooling (None, 1, 1, 300)         0         
    _________________________________________________________________
    dropout_88 (Dropout)         (None, 1, 1, 300)         0         
    _________________________________________________________________
    conv2d_165 (Conv2D)          (None, 1, 1, 300)         360300    
    _________________________________________________________________
    max_pooling2d_98 (MaxPooling (None, 1, 1, 300)         0         
    _________________________________________________________________
    dropout_89 (Dropout)         (None, 1, 1, 300)         0         
    _________________________________________________________________
    flatten_20 (Flatten)         (None, 300)               0         
    _________________________________________________________________
    dense_45 (Dense)             (None, 20)                6020      
    =================================================================
    Total params: 1,914,948
    Trainable params: 1,914,948
    Non-trainable params: 0
    _________________________________________________________________
    Epoch 1/100
    313/313 [==============================] - 209s 669ms/step - loss: 3.3778 - accuracy: 0.1627 - val_loss: 2.8638 - val_accuracy: 0.2653
    Epoch 2/100
    313/313 [==============================] - 206s 657ms/step - loss: 2.7855 - accuracy: 0.2650 - val_loss: 2.5909 - val_accuracy: 0.2995
    Epoch 3/100
    313/313 [==============================] - 207s 662ms/step - loss: 2.5895 - accuracy: 0.2989 - val_loss: 2.4535 - val_accuracy: 0.3319
    Epoch 4/100
    313/313 [==============================] - 210s 672ms/step - loss: 2.4715 - accuracy: 0.3260 - val_loss: 2.3494 - val_accuracy: 0.3589
    Epoch 5/100
    313/313 [==============================] - 213s 681ms/step - loss: 2.3871 - accuracy: 0.3463 - val_loss: 2.3171 - val_accuracy: 0.3637
    Epoch 6/100
    313/313 [==============================] - 216s 690ms/step - loss: 2.3237 - accuracy: 0.3639 - val_loss: 2.2065 - val_accuracy: 0.4007
    Epoch 7/100
    313/313 [==============================] - 214s 685ms/step - loss: 2.2777 - accuracy: 0.3798 - val_loss: 2.1903 - val_accuracy: 0.4102
    Epoch 8/100
    313/313 [==============================] - 215s 687ms/step - loss: 2.2271 - accuracy: 0.3936 - val_loss: 2.1073 - val_accuracy: 0.4384
    Epoch 9/100
    313/313 [==============================] - 214s 685ms/step - loss: 2.1926 - accuracy: 0.4078 - val_loss: 2.0871 - val_accuracy: 0.4373
    Epoch 10/100
    313/313 [==============================] - 210s 671ms/step - loss: 2.1437 - accuracy: 0.4238 - val_loss: 2.0714 - val_accuracy: 0.4477
    Epoch 11/100
    313/313 [==============================] - 237s 757ms/step - loss: 2.1182 - accuracy: 0.4337 - val_loss: 1.9584 - val_accuracy: 0.4759
    Epoch 12/100
    313/313 [==============================] - 217s 695ms/step - loss: 2.0910 - accuracy: 0.4446 - val_loss: 1.9782 - val_accuracy: 0.4794
    Epoch 13/100
    313/313 [==============================] - 231s 737ms/step - loss: 2.0561 - accuracy: 0.4542 - val_loss: 1.9898 - val_accuracy: 0.4760
    Epoch 14/100
    313/313 [==============================] - 230s 734ms/step - loss: 2.0300 - accuracy: 0.4642 - val_loss: 1.9692 - val_accuracy: 0.4856
    Epoch 15/100
    313/313 [==============================] - 213s 680ms/step - loss: 2.0142 - accuracy: 0.4717 - val_loss: 1.9944 - val_accuracy: 0.4796
    Epoch 16/100
    313/313 [==============================] - 217s 693ms/step - loss: 1.9956 - accuracy: 0.4814 - val_loss: 1.9647 - val_accuracy: 0.4921
    Epoch 17/100
    313/313 [==============================] - 210s 671ms/step - loss: 1.9779 - accuracy: 0.4859 - val_loss: 1.9963 - val_accuracy: 0.4797
    Epoch 18/100
    313/313 [==============================] - 217s 694ms/step - loss: 1.9716 - accuracy: 0.4939 - val_loss: 1.9435 - val_accuracy: 0.4906
    Epoch 19/100
    313/313 [==============================] - 207s 660ms/step - loss: 1.9456 - accuracy: 0.5002 - val_loss: 1.9017 - val_accuracy: 0.5122
    Epoch 20/100
    313/313 [==============================] - 207s 660ms/step - loss: 1.9415 - accuracy: 0.5049 - val_loss: 1.8923 - val_accuracy: 0.5167
    Epoch 21/100
    313/313 [==============================] - 198s 631ms/step - loss: 1.9149 - accuracy: 0.5159 - val_loss: 1.9216 - val_accuracy: 0.5099
    Epoch 22/100
    313/313 [==============================] - 197s 630ms/step - loss: 1.9116 - accuracy: 0.5177 - val_loss: 1.8712 - val_accuracy: 0.5277
    Epoch 23/100
    313/313 [==============================] - 197s 629ms/step - loss: 1.8937 - accuracy: 0.5265 - val_loss: 1.8557 - val_accuracy: 0.5355
    Epoch 24/100
    313/313 [==============================] - 200s 639ms/step - loss: 1.8834 - accuracy: 0.5324 - val_loss: 1.8668 - val_accuracy: 0.5386
    Epoch 25/100
    313/313 [==============================] - 198s 631ms/step - loss: 1.8664 - accuracy: 0.5364 - val_loss: 1.8825 - val_accuracy: 0.5313
    Epoch 26/100
    313/313 [==============================] - 198s 631ms/step - loss: 1.8549 - accuracy: 0.5425 - val_loss: 1.9131 - val_accuracy: 0.5276
    Epoch 27/100
    313/313 [==============================] - 198s 633ms/step - loss: 1.8586 - accuracy: 0.5416 - val_loss: 1.8734 - val_accuracy: 0.5427
    Epoch 28/100
    313/313 [==============================] - 198s 632ms/step - loss: 1.8501 - accuracy: 0.5472 - val_loss: 1.8502 - val_accuracy: 0.5483
    Epoch 29/100
    313/313 [==============================] - 207s 663ms/step - loss: 1.8448 - accuracy: 0.5501 - val_loss: 1.8393 - val_accuracy: 0.5543
    Epoch 30/100
    313/313 [==============================] - 209s 667ms/step - loss: 1.8273 - accuracy: 0.5581 - val_loss: 1.8513 - val_accuracy: 0.5483
    Epoch 31/100
    313/313 [==============================] - 248s 791ms/step - loss: 1.8238 - accuracy: 0.5617 - val_loss: 1.8784 - val_accuracy: 0.5464
    Epoch 32/100
    313/313 [==============================] - 230s 734ms/step - loss: 1.8112 - accuracy: 0.5656 - val_loss: 1.8283 - val_accuracy: 0.5613
    Epoch 33/100
    313/313 [==============================] - 211s 675ms/step - loss: 1.8136 - accuracy: 0.5657 - val_loss: 1.8471 - val_accuracy: 0.5648
    Epoch 34/100
    313/313 [==============================] - 206s 659ms/step - loss: 1.7993 - accuracy: 0.5733 - val_loss: 1.8263 - val_accuracy: 0.5661
    Epoch 35/100
    313/313 [==============================] - 208s 665ms/step - loss: 1.7942 - accuracy: 0.5751 - val_loss: 1.8138 - val_accuracy: 0.5694
    Epoch 36/100
    313/313 [==============================] - 211s 674ms/step - loss: 1.7914 - accuracy: 0.5753 - val_loss: 1.8483 - val_accuracy: 0.5588
    Epoch 37/100
    313/313 [==============================] - 222s 711ms/step - loss: 1.7923 - accuracy: 0.5806 - val_loss: 1.8375 - val_accuracy: 0.5674
    Epoch 38/100
    313/313 [==============================] - 221s 707ms/step - loss: 1.7750 - accuracy: 0.5827 - val_loss: 1.8514 - val_accuracy: 0.5664
    Epoch 39/100
    313/313 [==============================] - 200s 640ms/step - loss: 1.7728 - accuracy: 0.5898 - val_loss: 1.8536 - val_accuracy: 0.5718
    Epoch 40/100
    313/313 [==============================] - 199s 637ms/step - loss: 1.7751 - accuracy: 0.5854 - val_loss: 1.8282 - val_accuracy: 0.5766
    Epoch 41/100
    313/313 [==============================] - 198s 632ms/step - loss: 1.7650 - accuracy: 0.5914 - val_loss: 1.8410 - val_accuracy: 0.5776
    Epoch 42/100
    313/313 [==============================] - 204s 652ms/step - loss: 1.7619 - accuracy: 0.5953 - val_loss: 1.8582 - val_accuracy: 0.5683
    Epoch 43/100
    313/313 [==============================] - 208s 663ms/step - loss: 1.7562 - accuracy: 0.5983 - val_loss: 1.8432 - val_accuracy: 0.5796
    Epoch 44/100
    313/313 [==============================] - 206s 658ms/step - loss: 1.7593 - accuracy: 0.6000 - val_loss: 1.8319 - val_accuracy: 0.5825
    Epoch 45/100
    313/313 [==============================] - 201s 642ms/step - loss: 1.7396 - accuracy: 0.6046 - val_loss: 1.8240 - val_accuracy: 0.5872
    Epoch 46/100
    313/313 [==============================] - 203s 649ms/step - loss: 1.7369 - accuracy: 0.6100 - val_loss: 1.8566 - val_accuracy: 0.5751
    Epoch 47/100
    313/313 [==============================] - 207s 660ms/step - loss: 1.7425 - accuracy: 0.6066 - val_loss: 1.8423 - val_accuracy: 0.5821
    Epoch 48/100
    313/313 [==============================] - 207s 662ms/step - loss: 1.7384 - accuracy: 0.6106 - val_loss: 1.8603 - val_accuracy: 0.5796
    Epoch 49/100
    313/313 [==============================] - 206s 658ms/step - loss: 1.7261 - accuracy: 0.6141 - val_loss: 1.8451 - val_accuracy: 0.5872
    Epoch 50/100
    313/313 [==============================] - 206s 659ms/step - loss: 1.7086 - accuracy: 0.6189 - val_loss: 1.8583 - val_accuracy: 0.5781
    Epoch 00050: early stopping
    Test loss: 1.86613130569458
    Test accuracy: 0.5784000158309937
    
     
    
    


    
![png](output_102_1.png)
    



    
![png](output_102_2.png)
    


##### CNN 2 - Model 6


```python
CNN_model6 = Sequential()

# Create simple CNN model architecture with Pooling for dimensionality reduction 
# and Dropout to reduce overfitting
CNN_model6.add(Conv2D(32, kernel_size=(3,3), activation = 'elu', input_shape = (32,32,3), kernel_regularizer=l2(0.0005))) 
CNN_model6.add(MaxPooling2D(pool_size=(2, 2), padding='same'))

CNN_model6.add(Conv2D(64, kernel_size=(3,3), activation = 'elu', padding='same', kernel_regularizer=l2(0.0005)))
CNN_model6.add(Conv2D(128, kernel_size=(3,3), activation = 'elu', padding='same', kernel_regularizer=l2(0.0005)))
CNN_model6.add(MaxPooling2D(pool_size=(2, 2), padding='same'))
CNN_model6.add(Dropout(0.1))

CNN_model6.add(Conv2D(128, kernel_size=(2,2), activation = 'elu', padding='same', kernel_regularizer=l2(0.0005)))
CNN_model6.add(Conv2D(256, kernel_size=(2,2), activation = 'elu', padding='same', kernel_regularizer=l2(0.0005)))
CNN_model6.add(MaxPooling2D(pool_size=(2, 2), padding='same'))
CNN_model6.add(Dropout(0.2))

CNN_model6.add(Conv2D(256, kernel_size=(1,1), activation = 'elu', padding='same', kernel_regularizer=l2(0.0005)))
CNN_model6.add(Conv2D(512, kernel_size=(1,1), activation = 'elu', padding='same', kernel_regularizer=l2(0.0005)))
CNN_model6.add(MaxPooling2D(pool_size=(2, 2), padding='same'))
CNN_model6.add(Dropout(0.3))

# Flatten the output of our convolutional layers
CNN_model6.add(Flatten())

# Add dense layers
CNN_model6.add(Dense(512, activation = 'elu'))
CNN_model6.add(Dense(256, activation = 'elu'))
CNN_model6.add(Dense(len(np.unique(y_train)), activation='softmax'))

# Print out a summary of the network
CNN_model6.summary()

# Compile the model with the desired loss function, optimizer, and metric(s) to track
CNN_model6.compile(loss = 'sparse_categorical_crossentropy', #cross entropy is for multi-class classification
                  optimizer = 'Adam',
                  metrics = ['accuracy'])

# Fit the model on the training data, defining desired batch_size & number of epochs,
# running validation after each batch
CNN6 = CNN_model6.fit(X_train, y_train,
              batch_size = 128,
              epochs = 100,
              verbose = 1,
              validation_split = 0.2,
                callbacks=ES)

test_loss_score(CNN_model6)
accuracy_loss_plots(CNN6)
confusion(CNN_model6)

save_format='h5'
CNN_model6.save('CNNmodels/CNN_model6.h5')
```

    Model: "sequential_22"
    _________________________________________________________________
    Layer (type)                 Output Shape              Param #   
    =================================================================
    conv2d_173 (Conv2D)          (None, 30, 30, 32)        896       
    _________________________________________________________________
    max_pooling2d_103 (MaxPoolin (None, 15, 15, 32)        0         
    _________________________________________________________________
    conv2d_174 (Conv2D)          (None, 15, 15, 64)        18496     
    _________________________________________________________________
    conv2d_175 (Conv2D)          (None, 15, 15, 128)       73856     
    _________________________________________________________________
    max_pooling2d_104 (MaxPoolin (None, 8, 8, 128)         0         
    _________________________________________________________________
    dropout_93 (Dropout)         (None, 8, 8, 128)         0         
    _________________________________________________________________
    conv2d_176 (Conv2D)          (None, 8, 8, 128)         65664     
    _________________________________________________________________
    conv2d_177 (Conv2D)          (None, 8, 8, 256)         131328    
    _________________________________________________________________
    max_pooling2d_105 (MaxPoolin (None, 4, 4, 256)         0         
    _________________________________________________________________
    dropout_94 (Dropout)         (None, 4, 4, 256)         0         
    _________________________________________________________________
    conv2d_178 (Conv2D)          (None, 4, 4, 256)         65792     
    _________________________________________________________________
    conv2d_179 (Conv2D)          (None, 4, 4, 512)         131584    
    _________________________________________________________________
    max_pooling2d_106 (MaxPoolin (None, 2, 2, 512)         0         
    _________________________________________________________________
    dropout_95 (Dropout)         (None, 2, 2, 512)         0         
    _________________________________________________________________
    flatten_22 (Flatten)         (None, 2048)              0         
    _________________________________________________________________
    dense_49 (Dense)             (None, 512)               1049088   
    _________________________________________________________________
    dense_50 (Dense)             (None, 256)               131328    
    _________________________________________________________________
    dense_51 (Dense)             (None, 20)                5140      
    =================================================================
    Total params: 1,673,172
    Trainable params: 1,673,172
    Non-trainable params: 0
    _________________________________________________________________
    Epoch 1/100
    313/313 [==============================] - 70s 224ms/step - loss: 2.8260 - accuracy: 0.2581 - val_loss: 2.5127 - val_accuracy: 0.3274
    Epoch 2/100
    313/313 [==============================] - 72s 230ms/step - loss: 2.3472 - accuracy: 0.3695 - val_loss: 2.1611 - val_accuracy: 0.4113
    Epoch 3/100
    313/313 [==============================] - 70s 224ms/step - loss: 2.1037 - accuracy: 0.4248 - val_loss: 2.0587 - val_accuracy: 0.4374
    Epoch 4/100
    313/313 [==============================] - 75s 241ms/step - loss: 1.9524 - accuracy: 0.4621 - val_loss: 1.9694 - val_accuracy: 0.4657
    Epoch 5/100
    313/313 [==============================] - 72s 231ms/step - loss: 1.8418 - accuracy: 0.4930 - val_loss: 1.8463 - val_accuracy: 0.5010
    Epoch 6/100
    313/313 [==============================] - 72s 229ms/step - loss: 1.7414 - accuracy: 0.5222 - val_loss: 1.8153 - val_accuracy: 0.5099
    Epoch 7/100
    313/313 [==============================] - 73s 234ms/step - loss: 1.6670 - accuracy: 0.5410 - val_loss: 1.7790 - val_accuracy: 0.5211
    Epoch 8/100
    313/313 [==============================] - 74s 235ms/step - loss: 1.6094 - accuracy: 0.5605 - val_loss: 1.7114 - val_accuracy: 0.5408
    Epoch 9/100
    313/313 [==============================] - 72s 230ms/step - loss: 1.5392 - accuracy: 0.5802 - val_loss: 1.7159 - val_accuracy: 0.5467
    Epoch 10/100
    313/313 [==============================] - 71s 225ms/step - loss: 1.4883 - accuracy: 0.5974 - val_loss: 1.7453 - val_accuracy: 0.5359
    Epoch 11/100
    313/313 [==============================] - 70s 224ms/step - loss: 1.4291 - accuracy: 0.6140 - val_loss: 1.6530 - val_accuracy: 0.5678
    Epoch 12/100
    313/313 [==============================] - 69s 222ms/step - loss: 1.3820 - accuracy: 0.6326 - val_loss: 1.6673 - val_accuracy: 0.5600
    Epoch 13/100
    313/313 [==============================] - 70s 222ms/step - loss: 1.3281 - accuracy: 0.6509 - val_loss: 1.6580 - val_accuracy: 0.5754
    Epoch 14/100
    313/313 [==============================] - 71s 226ms/step - loss: 1.2785 - accuracy: 0.6667 - val_loss: 1.6962 - val_accuracy: 0.5686
    Epoch 15/100
    313/313 [==============================] - 71s 226ms/step - loss: 1.2259 - accuracy: 0.6815 - val_loss: 1.7007 - val_accuracy: 0.5780
    Epoch 16/100
    313/313 [==============================] - 72s 230ms/step - loss: 1.1753 - accuracy: 0.7016 - val_loss: 1.7187 - val_accuracy: 0.5755
    Epoch 17/100
    313/313 [==============================] - 75s 239ms/step - loss: 1.1274 - accuracy: 0.7167 - val_loss: 1.7353 - val_accuracy: 0.5814
    Epoch 18/100
    313/313 [==============================] - 71s 228ms/step - loss: 1.0835 - accuracy: 0.7327 - val_loss: 1.7957 - val_accuracy: 0.5725
    Epoch 19/100
    313/313 [==============================] - 75s 241ms/step - loss: 1.0384 - accuracy: 0.7462 - val_loss: 1.7819 - val_accuracy: 0.5817
    Epoch 20/100
    313/313 [==============================] - 75s 239ms/step - loss: 0.9915 - accuracy: 0.7628 - val_loss: 1.8403 - val_accuracy: 0.5769
    Epoch 21/100
    313/313 [==============================] - 72s 230ms/step - loss: 0.9671 - accuracy: 0.7703 - val_loss: 1.9335 - val_accuracy: 0.5806
    Epoch 22/100
    313/313 [==============================] - 70s 225ms/step - loss: 0.9246 - accuracy: 0.7847 - val_loss: 1.8570 - val_accuracy: 0.5872
    Epoch 23/100
    313/313 [==============================] - 72s 230ms/step - loss: 0.8865 - accuracy: 0.7997 - val_loss: 1.9090 - val_accuracy: 0.5836
    Epoch 24/100
    313/313 [==============================] - 71s 227ms/step - loss: 0.8525 - accuracy: 0.8103 - val_loss: 1.9338 - val_accuracy: 0.5859
    Epoch 25/100
    313/313 [==============================] - 74s 236ms/step - loss: 0.8249 - accuracy: 0.8188 - val_loss: 1.9668 - val_accuracy: 0.5836
    Epoch 26/100
    313/313 [==============================] - 74s 237ms/step - loss: 0.7965 - accuracy: 0.8295 - val_loss: 2.1004 - val_accuracy: 0.5718
    Epoch 27/100
    313/313 [==============================] - 71s 228ms/step - loss: 0.7867 - accuracy: 0.8328 - val_loss: 2.0385 - val_accuracy: 0.5855
    Epoch 00027: early stopping
    Test loss: 2.0565807819366455
    Test accuracy: 0.5838000178337097
    
     
    
    


    
![png](output_104_1.png)
    



    
![png](output_104_2.png)
    


### Transfer Learning

##### ResNet - Model 1


```python
model = ResNet50V2(weights='imagenet',
                   include_top=False,
                   pooling='max',
                   input_shape=(32,32,3))

for layer in model.layers:
    layer.trainable = False
    
model.summary()

```

    Model: "resnet50v2"
    __________________________________________________________________________________________________
    Layer (type)                    Output Shape         Param #     Connected to                     
    ==================================================================================================
    input_1 (InputLayer)            [(None, 32, 32, 3)]  0                                            
    __________________________________________________________________________________________________
    conv1_pad (ZeroPadding2D)       (None, 38, 38, 3)    0           input_1[0][0]                    
    __________________________________________________________________________________________________
    conv1_conv (Conv2D)             (None, 16, 16, 64)   9472        conv1_pad[0][0]                  
    __________________________________________________________________________________________________
    pool1_pad (ZeroPadding2D)       (None, 18, 18, 64)   0           conv1_conv[0][0]                 
    __________________________________________________________________________________________________
    pool1_pool (MaxPooling2D)       (None, 8, 8, 64)     0           pool1_pad[0][0]                  
    __________________________________________________________________________________________________
    conv2_block1_preact_bn (BatchNo (None, 8, 8, 64)     256         pool1_pool[0][0]                 
    __________________________________________________________________________________________________
    conv2_block1_preact_relu (Activ (None, 8, 8, 64)     0           conv2_block1_preact_bn[0][0]     
    __________________________________________________________________________________________________
    conv2_block1_1_conv (Conv2D)    (None, 8, 8, 64)     4096        conv2_block1_preact_relu[0][0]   
    __________________________________________________________________________________________________
    conv2_block1_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block1_1_conv[0][0]        
    __________________________________________________________________________________________________
    conv2_block1_1_relu (Activation (None, 8, 8, 64)     0           conv2_block1_1_bn[0][0]          
    __________________________________________________________________________________________________
    conv2_block1_2_pad (ZeroPadding (None, 10, 10, 64)   0           conv2_block1_1_relu[0][0]        
    __________________________________________________________________________________________________
    conv2_block1_2_conv (Conv2D)    (None, 8, 8, 64)     36864       conv2_block1_2_pad[0][0]         
    __________________________________________________________________________________________________
    conv2_block1_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block1_2_conv[0][0]        
    __________________________________________________________________________________________________
    conv2_block1_2_relu (Activation (None, 8, 8, 64)     0           conv2_block1_2_bn[0][0]          
    __________________________________________________________________________________________________
    conv2_block1_0_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block1_preact_relu[0][0]   
    __________________________________________________________________________________________________
    conv2_block1_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block1_2_relu[0][0]        
    __________________________________________________________________________________________________
    conv2_block1_out (Add)          (None, 8, 8, 256)    0           conv2_block1_0_conv[0][0]        
                                                                     conv2_block1_3_conv[0][0]        
    __________________________________________________________________________________________________
    conv2_block2_preact_bn (BatchNo (None, 8, 8, 256)    1024        conv2_block1_out[0][0]           
    __________________________________________________________________________________________________
    conv2_block2_preact_relu (Activ (None, 8, 8, 256)    0           conv2_block2_preact_bn[0][0]     
    __________________________________________________________________________________________________
    conv2_block2_1_conv (Conv2D)    (None, 8, 8, 64)     16384       conv2_block2_preact_relu[0][0]   
    __________________________________________________________________________________________________
    conv2_block2_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block2_1_conv[0][0]        
    __________________________________________________________________________________________________
    conv2_block2_1_relu (Activation (None, 8, 8, 64)     0           conv2_block2_1_bn[0][0]          
    __________________________________________________________________________________________________
    conv2_block2_2_pad (ZeroPadding (None, 10, 10, 64)   0           conv2_block2_1_relu[0][0]        
    __________________________________________________________________________________________________
    conv2_block2_2_conv (Conv2D)    (None, 8, 8, 64)     36864       conv2_block2_2_pad[0][0]         
    __________________________________________________________________________________________________
    conv2_block2_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block2_2_conv[0][0]        
    __________________________________________________________________________________________________
    conv2_block2_2_relu (Activation (None, 8, 8, 64)     0           conv2_block2_2_bn[0][0]          
    __________________________________________________________________________________________________
    conv2_block2_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block2_2_relu[0][0]        
    __________________________________________________________________________________________________
    conv2_block2_out (Add)          (None, 8, 8, 256)    0           conv2_block1_out[0][0]           
                                                                     conv2_block2_3_conv[0][0]        
    __________________________________________________________________________________________________
    conv2_block3_preact_bn (BatchNo (None, 8, 8, 256)    1024        conv2_block2_out[0][0]           
    __________________________________________________________________________________________________
    conv2_block3_preact_relu (Activ (None, 8, 8, 256)    0           conv2_block3_preact_bn[0][0]     
    __________________________________________________________________________________________________
    conv2_block3_1_conv (Conv2D)    (None, 8, 8, 64)     16384       conv2_block3_preact_relu[0][0]   
    __________________________________________________________________________________________________
    conv2_block3_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block3_1_conv[0][0]        
    __________________________________________________________________________________________________
    conv2_block3_1_relu (Activation (None, 8, 8, 64)     0           conv2_block3_1_bn[0][0]          
    __________________________________________________________________________________________________
    conv2_block3_2_pad (ZeroPadding (None, 10, 10, 64)   0           conv2_block3_1_relu[0][0]        
    __________________________________________________________________________________________________
    conv2_block3_2_conv (Conv2D)    (None, 4, 4, 64)     36864       conv2_block3_2_pad[0][0]         
    __________________________________________________________________________________________________
    conv2_block3_2_bn (BatchNormali (None, 4, 4, 64)     256         conv2_block3_2_conv[0][0]        
    __________________________________________________________________________________________________
    conv2_block3_2_relu (Activation (None, 4, 4, 64)     0           conv2_block3_2_bn[0][0]          
    __________________________________________________________________________________________________
    max_pooling2d_107 (MaxPooling2D (None, 4, 4, 256)    0           conv2_block2_out[0][0]           
    __________________________________________________________________________________________________
    conv2_block3_3_conv (Conv2D)    (None, 4, 4, 256)    16640       conv2_block3_2_relu[0][0]        
    __________________________________________________________________________________________________
    conv2_block3_out (Add)          (None, 4, 4, 256)    0           max_pooling2d_107[0][0]          
                                                                     conv2_block3_3_conv[0][0]        
    __________________________________________________________________________________________________
    conv3_block1_preact_bn (BatchNo (None, 4, 4, 256)    1024        conv2_block3_out[0][0]           
    __________________________________________________________________________________________________
    conv3_block1_preact_relu (Activ (None, 4, 4, 256)    0           conv3_block1_preact_bn[0][0]     
    __________________________________________________________________________________________________
    conv3_block1_1_conv (Conv2D)    (None, 4, 4, 128)    32768       conv3_block1_preact_relu[0][0]   
    __________________________________________________________________________________________________
    conv3_block1_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block1_1_conv[0][0]        
    __________________________________________________________________________________________________
    conv3_block1_1_relu (Activation (None, 4, 4, 128)    0           conv3_block1_1_bn[0][0]          
    __________________________________________________________________________________________________
    conv3_block1_2_pad (ZeroPadding (None, 6, 6, 128)    0           conv3_block1_1_relu[0][0]        
    __________________________________________________________________________________________________
    conv3_block1_2_conv (Conv2D)    (None, 4, 4, 128)    147456      conv3_block1_2_pad[0][0]         
    __________________________________________________________________________________________________
    conv3_block1_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block1_2_conv[0][0]        
    __________________________________________________________________________________________________
    conv3_block1_2_relu (Activation (None, 4, 4, 128)    0           conv3_block1_2_bn[0][0]          
    __________________________________________________________________________________________________
    conv3_block1_0_conv (Conv2D)    (None, 4, 4, 512)    131584      conv3_block1_preact_relu[0][0]   
    __________________________________________________________________________________________________
    conv3_block1_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block1_2_relu[0][0]        
    __________________________________________________________________________________________________
    conv3_block1_out (Add)          (None, 4, 4, 512)    0           conv3_block1_0_conv[0][0]        
                                                                     conv3_block1_3_conv[0][0]        
    __________________________________________________________________________________________________
    conv3_block2_preact_bn (BatchNo (None, 4, 4, 512)    2048        conv3_block1_out[0][0]           
    __________________________________________________________________________________________________
    conv3_block2_preact_relu (Activ (None, 4, 4, 512)    0           conv3_block2_preact_bn[0][0]     
    __________________________________________________________________________________________________
    conv3_block2_1_conv (Conv2D)    (None, 4, 4, 128)    65536       conv3_block2_preact_relu[0][0]   
    __________________________________________________________________________________________________
    conv3_block2_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block2_1_conv[0][0]        
    __________________________________________________________________________________________________
    conv3_block2_1_relu (Activation (None, 4, 4, 128)    0           conv3_block2_1_bn[0][0]          
    __________________________________________________________________________________________________
    conv3_block2_2_pad (ZeroPadding (None, 6, 6, 128)    0           conv3_block2_1_relu[0][0]        
    __________________________________________________________________________________________________
    conv3_block2_2_conv (Conv2D)    (None, 4, 4, 128)    147456      conv3_block2_2_pad[0][0]         
    __________________________________________________________________________________________________
    conv3_block2_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block2_2_conv[0][0]        
    __________________________________________________________________________________________________
    conv3_block2_2_relu (Activation (None, 4, 4, 128)    0           conv3_block2_2_bn[0][0]          
    __________________________________________________________________________________________________
    conv3_block2_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block2_2_relu[0][0]        
    __________________________________________________________________________________________________
    conv3_block2_out (Add)          (None, 4, 4, 512)    0           conv3_block1_out[0][0]           
                                                                     conv3_block2_3_conv[0][0]        
    __________________________________________________________________________________________________
    conv3_block3_preact_bn (BatchNo (None, 4, 4, 512)    2048        conv3_block2_out[0][0]           
    __________________________________________________________________________________________________
    conv3_block3_preact_relu (Activ (None, 4, 4, 512)    0           conv3_block3_preact_bn[0][0]     
    __________________________________________________________________________________________________
    conv3_block3_1_conv (Conv2D)    (None, 4, 4, 128)    65536       conv3_block3_preact_relu[0][0]   
    __________________________________________________________________________________________________
    conv3_block3_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block3_1_conv[0][0]        
    __________________________________________________________________________________________________
    conv3_block3_1_relu (Activation (None, 4, 4, 128)    0           conv3_block3_1_bn[0][0]          
    __________________________________________________________________________________________________
    conv3_block3_2_pad (ZeroPadding (None, 6, 6, 128)    0           conv3_block3_1_relu[0][0]        
    __________________________________________________________________________________________________
    conv3_block3_2_conv (Conv2D)    (None, 4, 4, 128)    147456      conv3_block3_2_pad[0][0]         
    __________________________________________________________________________________________________
    conv3_block3_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block3_2_conv[0][0]        
    __________________________________________________________________________________________________
    conv3_block3_2_relu (Activation (None, 4, 4, 128)    0           conv3_block3_2_bn[0][0]          
    __________________________________________________________________________________________________
    conv3_block3_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block3_2_relu[0][0]        
    __________________________________________________________________________________________________
    conv3_block3_out (Add)          (None, 4, 4, 512)    0           conv3_block2_out[0][0]           
                                                                     conv3_block3_3_conv[0][0]        
    __________________________________________________________________________________________________
    conv3_block4_preact_bn (BatchNo (None, 4, 4, 512)    2048        conv3_block3_out[0][0]           
    __________________________________________________________________________________________________
    conv3_block4_preact_relu (Activ (None, 4, 4, 512)    0           conv3_block4_preact_bn[0][0]     
    __________________________________________________________________________________________________
    conv3_block4_1_conv (Conv2D)    (None, 4, 4, 128)    65536       conv3_block4_preact_relu[0][0]   
    __________________________________________________________________________________________________
    conv3_block4_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block4_1_conv[0][0]        
    __________________________________________________________________________________________________
    conv3_block4_1_relu (Activation (None, 4, 4, 128)    0           conv3_block4_1_bn[0][0]          
    __________________________________________________________________________________________________
    conv3_block4_2_pad (ZeroPadding (None, 6, 6, 128)    0           conv3_block4_1_relu[0][0]        
    __________________________________________________________________________________________________
    conv3_block4_2_conv (Conv2D)    (None, 2, 2, 128)    147456      conv3_block4_2_pad[0][0]         
    __________________________________________________________________________________________________
    conv3_block4_2_bn (BatchNormali (None, 2, 2, 128)    512         conv3_block4_2_conv[0][0]        
    __________________________________________________________________________________________________
    conv3_block4_2_relu (Activation (None, 2, 2, 128)    0           conv3_block4_2_bn[0][0]          
    __________________________________________________________________________________________________
    max_pooling2d_108 (MaxPooling2D (None, 2, 2, 512)    0           conv3_block3_out[0][0]           
    __________________________________________________________________________________________________
    conv3_block4_3_conv (Conv2D)    (None, 2, 2, 512)    66048       conv3_block4_2_relu[0][0]        
    __________________________________________________________________________________________________
    conv3_block4_out (Add)          (None, 2, 2, 512)    0           max_pooling2d_108[0][0]          
                                                                     conv3_block4_3_conv[0][0]        
    __________________________________________________________________________________________________
    conv4_block1_preact_bn (BatchNo (None, 2, 2, 512)    2048        conv3_block4_out[0][0]           
    __________________________________________________________________________________________________
    conv4_block1_preact_relu (Activ (None, 2, 2, 512)    0           conv4_block1_preact_bn[0][0]     
    __________________________________________________________________________________________________
    conv4_block1_1_conv (Conv2D)    (None, 2, 2, 256)    131072      conv4_block1_preact_relu[0][0]   
    __________________________________________________________________________________________________
    conv4_block1_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block1_1_conv[0][0]        
    __________________________________________________________________________________________________
    conv4_block1_1_relu (Activation (None, 2, 2, 256)    0           conv4_block1_1_bn[0][0]          
    __________________________________________________________________________________________________
    conv4_block1_2_pad (ZeroPadding (None, 4, 4, 256)    0           conv4_block1_1_relu[0][0]        
    __________________________________________________________________________________________________
    conv4_block1_2_conv (Conv2D)    (None, 2, 2, 256)    589824      conv4_block1_2_pad[0][0]         
    __________________________________________________________________________________________________
    conv4_block1_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block1_2_conv[0][0]        
    __________________________________________________________________________________________________
    conv4_block1_2_relu (Activation (None, 2, 2, 256)    0           conv4_block1_2_bn[0][0]          
    __________________________________________________________________________________________________
    conv4_block1_0_conv (Conv2D)    (None, 2, 2, 1024)   525312      conv4_block1_preact_relu[0][0]   
    __________________________________________________________________________________________________
    conv4_block1_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block1_2_relu[0][0]        
    __________________________________________________________________________________________________
    conv4_block1_out (Add)          (None, 2, 2, 1024)   0           conv4_block1_0_conv[0][0]        
                                                                     conv4_block1_3_conv[0][0]        
    __________________________________________________________________________________________________
    conv4_block2_preact_bn (BatchNo (None, 2, 2, 1024)   4096        conv4_block1_out[0][0]           
    __________________________________________________________________________________________________
    conv4_block2_preact_relu (Activ (None, 2, 2, 1024)   0           conv4_block2_preact_bn[0][0]     
    __________________________________________________________________________________________________
    conv4_block2_1_conv (Conv2D)    (None, 2, 2, 256)    262144      conv4_block2_preact_relu[0][0]   
    __________________________________________________________________________________________________
    conv4_block2_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block2_1_conv[0][0]        
    __________________________________________________________________________________________________
    conv4_block2_1_relu (Activation (None, 2, 2, 256)    0           conv4_block2_1_bn[0][0]          
    __________________________________________________________________________________________________
    conv4_block2_2_pad (ZeroPadding (None, 4, 4, 256)    0           conv4_block2_1_relu[0][0]        
    __________________________________________________________________________________________________
    conv4_block2_2_conv (Conv2D)    (None, 2, 2, 256)    589824      conv4_block2_2_pad[0][0]         
    __________________________________________________________________________________________________
    conv4_block2_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block2_2_conv[0][0]        
    __________________________________________________________________________________________________
    conv4_block2_2_relu (Activation (None, 2, 2, 256)    0           conv4_block2_2_bn[0][0]          
    __________________________________________________________________________________________________
    conv4_block2_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block2_2_relu[0][0]        
    __________________________________________________________________________________________________
    conv4_block2_out (Add)          (None, 2, 2, 1024)   0           conv4_block1_out[0][0]           
                                                                     conv4_block2_3_conv[0][0]        
    __________________________________________________________________________________________________
    conv4_block3_preact_bn (BatchNo (None, 2, 2, 1024)   4096        conv4_block2_out[0][0]           
    __________________________________________________________________________________________________
    conv4_block3_preact_relu (Activ (None, 2, 2, 1024)   0           conv4_block3_preact_bn[0][0]     
    __________________________________________________________________________________________________
    conv4_block3_1_conv (Conv2D)    (None, 2, 2, 256)    262144      conv4_block3_preact_relu[0][0]   
    __________________________________________________________________________________________________
    conv4_block3_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block3_1_conv[0][0]        
    __________________________________________________________________________________________________
    conv4_block3_1_relu (Activation (None, 2, 2, 256)    0           conv4_block3_1_bn[0][0]          
    __________________________________________________________________________________________________
    conv4_block3_2_pad (ZeroPadding (None, 4, 4, 256)    0           conv4_block3_1_relu[0][0]        
    __________________________________________________________________________________________________
    conv4_block3_2_conv (Conv2D)    (None, 2, 2, 256)    589824      conv4_block3_2_pad[0][0]         
    __________________________________________________________________________________________________
    conv4_block3_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block3_2_conv[0][0]        
    __________________________________________________________________________________________________
    conv4_block3_2_relu (Activation (None, 2, 2, 256)    0           conv4_block3_2_bn[0][0]          
    __________________________________________________________________________________________________
    conv4_block3_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block3_2_relu[0][0]        
    __________________________________________________________________________________________________
    conv4_block3_out (Add)          (None, 2, 2, 1024)   0           conv4_block2_out[0][0]           
                                                                     conv4_block3_3_conv[0][0]        
    __________________________________________________________________________________________________
    conv4_block4_preact_bn (BatchNo (None, 2, 2, 1024)   4096        conv4_block3_out[0][0]           
    __________________________________________________________________________________________________
    conv4_block4_preact_relu (Activ (None, 2, 2, 1024)   0           conv4_block4_preact_bn[0][0]     
    __________________________________________________________________________________________________
    conv4_block4_1_conv (Conv2D)    (None, 2, 2, 256)    262144      conv4_block4_preact_relu[0][0]   
    __________________________________________________________________________________________________
    conv4_block4_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block4_1_conv[0][0]        
    __________________________________________________________________________________________________
    conv4_block4_1_relu (Activation (None, 2, 2, 256)    0           conv4_block4_1_bn[0][0]          
    __________________________________________________________________________________________________
    conv4_block4_2_pad (ZeroPadding (None, 4, 4, 256)    0           conv4_block4_1_relu[0][0]        
    __________________________________________________________________________________________________
    conv4_block4_2_conv (Conv2D)    (None, 2, 2, 256)    589824      conv4_block4_2_pad[0][0]         
    __________________________________________________________________________________________________
    conv4_block4_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block4_2_conv[0][0]        
    __________________________________________________________________________________________________
    conv4_block4_2_relu (Activation (None, 2, 2, 256)    0           conv4_block4_2_bn[0][0]          
    __________________________________________________________________________________________________
    conv4_block4_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block4_2_relu[0][0]        
    __________________________________________________________________________________________________
    conv4_block4_out (Add)          (None, 2, 2, 1024)   0           conv4_block3_out[0][0]           
                                                                     conv4_block4_3_conv[0][0]        
    __________________________________________________________________________________________________
    conv4_block5_preact_bn (BatchNo (None, 2, 2, 1024)   4096        conv4_block4_out[0][0]           
    __________________________________________________________________________________________________
    conv4_block5_preact_relu (Activ (None, 2, 2, 1024)   0           conv4_block5_preact_bn[0][0]     
    __________________________________________________________________________________________________
    conv4_block5_1_conv (Conv2D)    (None, 2, 2, 256)    262144      conv4_block5_preact_relu[0][0]   
    __________________________________________________________________________________________________
    conv4_block5_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block5_1_conv[0][0]        
    __________________________________________________________________________________________________
    conv4_block5_1_relu (Activation (None, 2, 2, 256)    0           conv4_block5_1_bn[0][0]          
    __________________________________________________________________________________________________
    conv4_block5_2_pad (ZeroPadding (None, 4, 4, 256)    0           conv4_block5_1_relu[0][0]        
    __________________________________________________________________________________________________
    conv4_block5_2_conv (Conv2D)    (None, 2, 2, 256)    589824      conv4_block5_2_pad[0][0]         
    __________________________________________________________________________________________________
    conv4_block5_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block5_2_conv[0][0]        
    __________________________________________________________________________________________________
    conv4_block5_2_relu (Activation (None, 2, 2, 256)    0           conv4_block5_2_bn[0][0]          
    __________________________________________________________________________________________________
    conv4_block5_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block5_2_relu[0][0]        
    __________________________________________________________________________________________________
    conv4_block5_out (Add)          (None, 2, 2, 1024)   0           conv4_block4_out[0][0]           
                                                                     conv4_block5_3_conv[0][0]        
    __________________________________________________________________________________________________
    conv4_block6_preact_bn (BatchNo (None, 2, 2, 1024)   4096        conv4_block5_out[0][0]           
    __________________________________________________________________________________________________
    conv4_block6_preact_relu (Activ (None, 2, 2, 1024)   0           conv4_block6_preact_bn[0][0]     
    __________________________________________________________________________________________________
    conv4_block6_1_conv (Conv2D)    (None, 2, 2, 256)    262144      conv4_block6_preact_relu[0][0]   
    __________________________________________________________________________________________________
    conv4_block6_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block6_1_conv[0][0]        
    __________________________________________________________________________________________________
    conv4_block6_1_relu (Activation (None, 2, 2, 256)    0           conv4_block6_1_bn[0][0]          
    __________________________________________________________________________________________________
    conv4_block6_2_pad (ZeroPadding (None, 4, 4, 256)    0           conv4_block6_1_relu[0][0]        
    __________________________________________________________________________________________________
    conv4_block6_2_conv (Conv2D)    (None, 1, 1, 256)    589824      conv4_block6_2_pad[0][0]         
    __________________________________________________________________________________________________
    conv4_block6_2_bn (BatchNormali (None, 1, 1, 256)    1024        conv4_block6_2_conv[0][0]        
    __________________________________________________________________________________________________
    conv4_block6_2_relu (Activation (None, 1, 1, 256)    0           conv4_block6_2_bn[0][0]          
    __________________________________________________________________________________________________
    max_pooling2d_109 (MaxPooling2D (None, 1, 1, 1024)   0           conv4_block5_out[0][0]           
    __________________________________________________________________________________________________
    conv4_block6_3_conv (Conv2D)    (None, 1, 1, 1024)   263168      conv4_block6_2_relu[0][0]        
    __________________________________________________________________________________________________
    conv4_block6_out (Add)          (None, 1, 1, 1024)   0           max_pooling2d_109[0][0]          
                                                                     conv4_block6_3_conv[0][0]        
    __________________________________________________________________________________________________
    conv5_block1_preact_bn (BatchNo (None, 1, 1, 1024)   4096        conv4_block6_out[0][0]           
    __________________________________________________________________________________________________
    conv5_block1_preact_relu (Activ (None, 1, 1, 1024)   0           conv5_block1_preact_bn[0][0]     
    __________________________________________________________________________________________________
    conv5_block1_1_conv (Conv2D)    (None, 1, 1, 512)    524288      conv5_block1_preact_relu[0][0]   
    __________________________________________________________________________________________________
    conv5_block1_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block1_1_conv[0][0]        
    __________________________________________________________________________________________________
    conv5_block1_1_relu (Activation (None, 1, 1, 512)    0           conv5_block1_1_bn[0][0]          
    __________________________________________________________________________________________________
    conv5_block1_2_pad (ZeroPadding (None, 3, 3, 512)    0           conv5_block1_1_relu[0][0]        
    __________________________________________________________________________________________________
    conv5_block1_2_conv (Conv2D)    (None, 1, 1, 512)    2359296     conv5_block1_2_pad[0][0]         
    __________________________________________________________________________________________________
    conv5_block1_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block1_2_conv[0][0]        
    __________________________________________________________________________________________________
    conv5_block1_2_relu (Activation (None, 1, 1, 512)    0           conv5_block1_2_bn[0][0]          
    __________________________________________________________________________________________________
    conv5_block1_0_conv (Conv2D)    (None, 1, 1, 2048)   2099200     conv5_block1_preact_relu[0][0]   
    __________________________________________________________________________________________________
    conv5_block1_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block1_2_relu[0][0]        
    __________________________________________________________________________________________________
    conv5_block1_out (Add)          (None, 1, 1, 2048)   0           conv5_block1_0_conv[0][0]        
                                                                     conv5_block1_3_conv[0][0]        
    __________________________________________________________________________________________________
    conv5_block2_preact_bn (BatchNo (None, 1, 1, 2048)   8192        conv5_block1_out[0][0]           
    __________________________________________________________________________________________________
    conv5_block2_preact_relu (Activ (None, 1, 1, 2048)   0           conv5_block2_preact_bn[0][0]     
    __________________________________________________________________________________________________
    conv5_block2_1_conv (Conv2D)    (None, 1, 1, 512)    1048576     conv5_block2_preact_relu[0][0]   
    __________________________________________________________________________________________________
    conv5_block2_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block2_1_conv[0][0]        
    __________________________________________________________________________________________________
    conv5_block2_1_relu (Activation (None, 1, 1, 512)    0           conv5_block2_1_bn[0][0]          
    __________________________________________________________________________________________________
    conv5_block2_2_pad (ZeroPadding (None, 3, 3, 512)    0           conv5_block2_1_relu[0][0]        
    __________________________________________________________________________________________________
    conv5_block2_2_conv (Conv2D)    (None, 1, 1, 512)    2359296     conv5_block2_2_pad[0][0]         
    __________________________________________________________________________________________________
    conv5_block2_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block2_2_conv[0][0]        
    __________________________________________________________________________________________________
    conv5_block2_2_relu (Activation (None, 1, 1, 512)    0           conv5_block2_2_bn[0][0]          
    __________________________________________________________________________________________________
    conv5_block2_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block2_2_relu[0][0]        
    __________________________________________________________________________________________________
    conv5_block2_out (Add)          (None, 1, 1, 2048)   0           conv5_block1_out[0][0]           
                                                                     conv5_block2_3_conv[0][0]        
    __________________________________________________________________________________________________
    conv5_block3_preact_bn (BatchNo (None, 1, 1, 2048)   8192        conv5_block2_out[0][0]           
    __________________________________________________________________________________________________
    conv5_block3_preact_relu (Activ (None, 1, 1, 2048)   0           conv5_block3_preact_bn[0][0]     
    __________________________________________________________________________________________________
    conv5_block3_1_conv (Conv2D)    (None, 1, 1, 512)    1048576     conv5_block3_preact_relu[0][0]   
    __________________________________________________________________________________________________
    conv5_block3_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block3_1_conv[0][0]        
    __________________________________________________________________________________________________
    conv5_block3_1_relu (Activation (None, 1, 1, 512)    0           conv5_block3_1_bn[0][0]          
    __________________________________________________________________________________________________
    conv5_block3_2_pad (ZeroPadding (None, 3, 3, 512)    0           conv5_block3_1_relu[0][0]        
    __________________________________________________________________________________________________
    conv5_block3_2_conv (Conv2D)    (None, 1, 1, 512)    2359296     conv5_block3_2_pad[0][0]         
    __________________________________________________________________________________________________
    conv5_block3_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block3_2_conv[0][0]        
    __________________________________________________________________________________________________
    conv5_block3_2_relu (Activation (None, 1, 1, 512)    0           conv5_block3_2_bn[0][0]          
    __________________________________________________________________________________________________
    conv5_block3_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block3_2_relu[0][0]        
    __________________________________________________________________________________________________
    conv5_block3_out (Add)          (None, 1, 1, 2048)   0           conv5_block2_out[0][0]           
                                                                     conv5_block3_3_conv[0][0]        
    __________________________________________________________________________________________________
    post_bn (BatchNormalization)    (None, 1, 1, 2048)   8192        conv5_block3_out[0][0]           
    __________________________________________________________________________________________________
    post_relu (Activation)          (None, 1, 1, 2048)   0           post_bn[0][0]                    
    __________________________________________________________________________________________________
    max_pool (GlobalMaxPooling2D)   (None, 2048)         0           post_relu[0][0]                  
    ==================================================================================================
    Total params: 23,564,800
    Trainable params: 0
    Non-trainable params: 23,564,800
    __________________________________________________________________________________________________
    


```python
model = ResNet50V2(weights='imagenet',
                   include_top=False,
                   pooling='max',
                   input_shape=(32,32,3))
for layer in model.layers:
    layer.trainable = False

    
RNmodel1 = Sequential()

RNmodel1.add(model)
RNmodel1.add(Flatten())
RNmodel1.add(Dense(2048, activation= 'relu'))
RNmodel1.add(Dense(1024, activation= 'relu'))
RNmodel1.add(Dense(512, activation= 'relu'))
RNmodel1.add(Dense(len(np.unique(y_train)), activation='softmax'))

RNmodel1.compile(optimizer='Adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

RN1 = RNmodel1.fit(X_train, y_train,
        batch_size = 128,
          epochs=50,
          validation_split=0.2,
         callbacks=ES)

test_loss_score(RNmodel1)
accuracy_loss_plots(RN1)
confusion(RNmodel1)
save_format='h5'
RNmodel1.save('CNNmodels/RNmodel1.h5')
```

    Epoch 1/50
    313/313 [==============================] - 63s 201ms/step - loss: 2.5359 - accuracy: 0.2256 - val_loss: 2.4325 - val_accuracy: 0.2582
    Epoch 2/50
    313/313 [==============================] - 65s 208ms/step - loss: 2.2364 - accuracy: 0.3076 - val_loss: 2.3891 - val_accuracy: 0.2762
    Epoch 3/50
    313/313 [==============================] - 64s 205ms/step - loss: 1.9908 - accuracy: 0.3817 - val_loss: 2.4434 - val_accuracy: 0.2719
    Epoch 4/50
    313/313 [==============================] - 64s 205ms/step - loss: 1.7066 - accuracy: 0.4631 - val_loss: 2.6170 - val_accuracy: 0.2724
    Epoch 5/50
    313/313 [==============================] - 67s 213ms/step - loss: 1.3866 - accuracy: 0.5649 - val_loss: 2.9649 - val_accuracy: 0.2688
    Epoch 6/50
    313/313 [==============================] - 66s 212ms/step - loss: 1.0867 - accuracy: 0.6614 - val_loss: 3.4140 - val_accuracy: 0.2578
    Epoch 7/50
    313/313 [==============================] - 65s 207ms/step - loss: 0.8133 - accuracy: 0.7469 - val_loss: 4.0021 - val_accuracy: 0.2582
    Epoch 00007: early stopping
    Test loss: 3.9391226768493652
    Test accuracy: 0.259799987077713
    
     
    
    


    
![png](output_108_1.png)
    



    
![png](output_108_2.png)
    



    ---------------------------------------------------------------------------

    NameError                                 Traceback (most recent call last)

    <ipython-input-203-ffddd202676b> in <module>
         30 confusion(RNmodel1)
         31 save_format='h5'
    ---> 32 RN_model1.save('CNNmodels/RN_model1.h5')
    

    NameError: name 'RN_model1' is not defined


##### ResNet - Model 2


```python
RNmodel2 = Sequential()

RNmodel2.add(model)
RNmodel2.add(Flatten())
RNmodel2.add(Dense(2048, activation= 'relu'))
RNmodel2.add(Dense(1024, activation= 'relu'))
RNmodel2.add(Dense(len(np.unique(y_train)), activation='softmax'))

RNmodel2.compile(optimizer='Adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

RN2 = RNmodel2.fit(X_train, y_train,
        batch_size = 128,
          epochs=50,
          validation_split=0.2,
            callbacks = ES)

test_loss_score(RNmodel2)
accuracy_loss_plots(RN2)
confusion(RNmodel2)
save_format='h5'
RNmodel2.save('CNNmodels/RNmodel2.h5')
```

    Epoch 1/50
    313/313 [==============================] - 61s 194ms/step - loss: 2.5131 - accuracy: 0.2344 - val_loss: 2.3996 - val_accuracy: 0.2622
    Epoch 2/50
    313/313 [==============================] - 63s 202ms/step - loss: 2.1947 - accuracy: 0.3185 - val_loss: 2.3780 - val_accuracy: 0.2717
    Epoch 3/50
    313/313 [==============================] - 65s 209ms/step - loss: 1.9339 - accuracy: 0.3975 - val_loss: 2.4178 - val_accuracy: 0.2771
    Epoch 4/50
    313/313 [==============================] - 64s 206ms/step - loss: 1.6310 - accuracy: 0.4903 - val_loss: 2.6389 - val_accuracy: 0.2796
    Epoch 5/50
    313/313 [==============================] - 64s 205ms/step - loss: 1.3183 - accuracy: 0.5877 - val_loss: 2.9479 - val_accuracy: 0.2761
    Epoch 6/50
    313/313 [==============================] - 65s 206ms/step - loss: 1.0249 - accuracy: 0.6821 - val_loss: 3.4199 - val_accuracy: 0.2650
    Epoch 7/50
    313/313 [==============================] - 64s 205ms/step - loss: 0.7925 - accuracy: 0.7581 - val_loss: 3.8239 - val_accuracy: 0.2628
    Epoch 8/50
    313/313 [==============================] - 64s 205ms/step - loss: 0.6136 - accuracy: 0.8173 - val_loss: 4.2884 - val_accuracy: 0.2623
    Epoch 9/50
    313/313 [==============================] - 65s 206ms/step - loss: 0.4706 - accuracy: 0.8606 - val_loss: 4.7897 - val_accuracy: 0.2596
    Epoch 00009: early stopping
    Test loss: 4.826961517333984
    Test accuracy: 0.25360000133514404
    
     
    
    


    
![png](output_110_1.png)
    



    
![png](output_110_2.png)
    


##### VGG16 - Model 1


```python
model = VGG16(weights='imagenet',
                   include_top=False,
                   pooling='max',
                   input_shape=(32,32,3))

for layer in model.layers:
    layer.trainable = False
    
model.summary()
```

    Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5
    58892288/58889256 [==============================] - 2s 0us/step
    Model: "vgg16"
    _________________________________________________________________
    Layer (type)                 Output Shape              Param #   
    =================================================================
    input_4 (InputLayer)         [(None, 32, 32, 3)]       0         
    _________________________________________________________________
    block1_conv1 (Conv2D)        (None, 32, 32, 64)        1792      
    _________________________________________________________________
    block1_conv2 (Conv2D)        (None, 32, 32, 64)        36928     
    _________________________________________________________________
    block1_pool (MaxPooling2D)   (None, 16, 16, 64)        0         
    _________________________________________________________________
    block2_conv1 (Conv2D)        (None, 16, 16, 128)       73856     
    _________________________________________________________________
    block2_conv2 (Conv2D)        (None, 16, 16, 128)       147584    
    _________________________________________________________________
    block2_pool (MaxPooling2D)   (None, 8, 8, 128)         0         
    _________________________________________________________________
    block3_conv1 (Conv2D)        (None, 8, 8, 256)         295168    
    _________________________________________________________________
    block3_conv2 (Conv2D)        (None, 8, 8, 256)         590080    
    _________________________________________________________________
    block3_conv3 (Conv2D)        (None, 8, 8, 256)         590080    
    _________________________________________________________________
    block3_pool (MaxPooling2D)   (None, 4, 4, 256)         0         
    _________________________________________________________________
    block4_conv1 (Conv2D)        (None, 4, 4, 512)         1180160   
    _________________________________________________________________
    block4_conv2 (Conv2D)        (None, 4, 4, 512)         2359808   
    _________________________________________________________________
    block4_conv3 (Conv2D)        (None, 4, 4, 512)         2359808   
    _________________________________________________________________
    block4_pool (MaxPooling2D)   (None, 2, 2, 512)         0         
    _________________________________________________________________
    block5_conv1 (Conv2D)        (None, 2, 2, 512)         2359808   
    _________________________________________________________________
    block5_conv2 (Conv2D)        (None, 2, 2, 512)         2359808   
    _________________________________________________________________
    block5_conv3 (Conv2D)        (None, 2, 2, 512)         2359808   
    _________________________________________________________________
    block5_pool (MaxPooling2D)   (None, 1, 1, 512)         0         
    _________________________________________________________________
    global_max_pooling2d (Global (None, 512)               0         
    =================================================================
    Total params: 14,714,688
    Trainable params: 0
    Non-trainable params: 14,714,688
    _________________________________________________________________
    


```python
model = VGG16(weights='imagenet',
                   include_top=False,
                   pooling='max',
                   input_shape=(32,32,3))

for layer in model.layers:
    layer.trainable = False
    
VGmodel1 = Sequential()

VGmodel1.add(model)
VGmodel1.add(Flatten())
VGmodel1.add(Dense(512, activation= 'relu'))
VGmodel1.add(Dense(256, activation= 'relu'))
VGmodel1.add(Dense(128, activation= 'relu'))
VGmodel1.add(Dense(len(np.unique(y_train)), activation='softmax'))

VGmodel1.compile(optimizer='Adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

VG1 = VGmodel1.fit(X_train, y_train,
        batch_size = 128,
          epochs=50,
          validation_split=0.2,
            callbacks = ES)

test_loss_score(VGmodel1)
accuracy_loss_plots(VG1)
confusion(VGmodel1)
save_format='h5'
VGmodel1.save('CNNmodels/VGmodel1.h5')
```

    Epoch 1/50
    313/313 [==============================] - 152s 485ms/step - loss: 2.0465 - accuracy: 0.3598 - val_loss: 1.8821 - val_accuracy: 0.4154
    Epoch 2/50
    313/313 [==============================] - 155s 495ms/step - loss: 1.7461 - accuracy: 0.4503 - val_loss: 1.7512 - val_accuracy: 0.4533
    Epoch 3/50
    313/313 [==============================] - 153s 490ms/step - loss: 1.6060 - accuracy: 0.4917 - val_loss: 1.7070 - val_accuracy: 0.4632
    Epoch 4/50
    313/313 [==============================] - 153s 487ms/step - loss: 1.4906 - accuracy: 0.5256 - val_loss: 1.6900 - val_accuracy: 0.4751
    Epoch 5/50
    313/313 [==============================] - 153s 489ms/step - loss: 1.3745 - accuracy: 0.5602 - val_loss: 1.6951 - val_accuracy: 0.4833
    Epoch 6/50
    313/313 [==============================] - 155s 494ms/step - loss: 1.2677 - accuracy: 0.5899 - val_loss: 1.7566 - val_accuracy: 0.4779
    Epoch 7/50
    313/313 [==============================] - 154s 493ms/step - loss: 1.1493 - accuracy: 0.6279 - val_loss: 1.7975 - val_accuracy: 0.4856
    Epoch 8/50
    313/313 [==============================] - 154s 492ms/step - loss: 1.0273 - accuracy: 0.6650 - val_loss: 1.8225 - val_accuracy: 0.4815
    Epoch 9/50
    313/313 [==============================] - 158s 505ms/step - loss: 0.9024 - accuracy: 0.7037 - val_loss: 1.9007 - val_accuracy: 0.4835
    Epoch 10/50
    313/313 [==============================] - 153s 489ms/step - loss: 0.7858 - accuracy: 0.7386 - val_loss: 2.1056 - val_accuracy: 0.4806
    Epoch 11/50
    313/313 [==============================] - 154s 491ms/step - loss: 0.6705 - accuracy: 0.7777 - val_loss: 2.2055 - val_accuracy: 0.4742
    Epoch 12/50
    313/313 [==============================] - 160s 510ms/step - loss: 0.5498 - accuracy: 0.8157 - val_loss: 2.4390 - val_accuracy: 0.4710
    Epoch 00012: early stopping
    Test loss: 2.465879440307617
    Test accuracy: 0.47209998965263367
    
     
    
    


    
![png](output_113_1.png)
    



    
![png](output_113_2.png)
    


##### VGG16 - Model 2


```python
model = VGG16(weights='imagenet',
                   include_top=False,
                   pooling='max',
                   input_shape=(32,32,3))

for layer in model.layers:
    layer.trainable = False
    
VGmodel2 = Sequential()

VGmodel2.add(model)
VGmodel2.add(Flatten())
VGmodel2.add(Dense(512, activation= 'relu'))
VGmodel2.add(Dense(256, activation= 'relu')) 
VGmodel2.add(Dense(len(np.unique(y_train)), activation='softmax'))

VGmodel2.compile(optimizer='Adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

VG2 = VGmodel2.fit(X_train, y_train,
        batch_size = 128,
          epochs=50,
          validation_split=0.2,
            callbacks=ES)

test_loss_score(VGmodel2)
accuracy_loss_plots(VG2)
confusion(VGmodel2)
save_format='h5'
VGmodel2.save('CNNmodels/VGmodel2.h5')
```

    Epoch 1/50
    313/313 [==============================] - 129s 411ms/step - loss: 2.0610 - accuracy: 0.3608 - val_loss: 1.8460 - val_accuracy: 0.4225
    Epoch 2/50
    313/313 [==============================] - 128s 409ms/step - loss: 1.7715 - accuracy: 0.4451 - val_loss: 1.7822 - val_accuracy: 0.4421
    Epoch 3/50
    313/313 [==============================] - 129s 412ms/step - loss: 1.6624 - accuracy: 0.4753 - val_loss: 1.7272 - val_accuracy: 0.4591
    Epoch 4/50
    313/313 [==============================] - 130s 414ms/step - loss: 1.5699 - accuracy: 0.5035 - val_loss: 1.7158 - val_accuracy: 0.4674
    Epoch 5/50
    313/313 [==============================] - 130s 414ms/step - loss: 1.4885 - accuracy: 0.5277 - val_loss: 1.6857 - val_accuracy: 0.4721
    Epoch 6/50
    313/313 [==============================] - 135s 430ms/step - loss: 1.4149 - accuracy: 0.5498 - val_loss: 1.7089 - val_accuracy: 0.4733
    Epoch 7/50
    313/313 [==============================] - 148s 472ms/step - loss: 1.3425 - accuracy: 0.5726 - val_loss: 1.6849 - val_accuracy: 0.4764
    Epoch 8/50
    313/313 [==============================] - 137s 437ms/step - loss: 1.2736 - accuracy: 0.5926 - val_loss: 1.6924 - val_accuracy: 0.4789
    Epoch 9/50
    313/313 [==============================] - 139s 445ms/step - loss: 1.2045 - accuracy: 0.6144 - val_loss: 1.7087 - val_accuracy: 0.4879
    Epoch 10/50
    313/313 [==============================] - 135s 430ms/step - loss: 1.1373 - accuracy: 0.6353 - val_loss: 1.7374 - val_accuracy: 0.4797
    Epoch 11/50
    313/313 [==============================] - 135s 431ms/step - loss: 1.0717 - accuracy: 0.6549 - val_loss: 1.7815 - val_accuracy: 0.4858
    Epoch 12/50
    313/313 [==============================] - 137s 439ms/step - loss: 1.0011 - accuracy: 0.6794 - val_loss: 1.8132 - val_accuracy: 0.4855
    Epoch 13/50
    313/313 [==============================] - 129s 412ms/step - loss: 0.9436 - accuracy: 0.6981 - val_loss: 1.8303 - val_accuracy: 0.4880
    Epoch 14/50
    313/313 [==============================] - 129s 413ms/step - loss: 0.8805 - accuracy: 0.7181 - val_loss: 1.8936 - val_accuracy: 0.4799
    Epoch 15/50
    313/313 [==============================] - 129s 413ms/step - loss: 0.8129 - accuracy: 0.7385 - val_loss: 1.9728 - val_accuracy: 0.4799
    Epoch 16/50
    313/313 [==============================] - 129s 412ms/step - loss: 0.7594 - accuracy: 0.7568 - val_loss: 2.0334 - val_accuracy: 0.4849
    Epoch 17/50
    313/313 [==============================] - 129s 412ms/step - loss: 0.6967 - accuracy: 0.7768 - val_loss: 2.1336 - val_accuracy: 0.4780
    Epoch 18/50
    313/313 [==============================] - 128s 410ms/step - loss: 0.6458 - accuracy: 0.7934 - val_loss: 2.1765 - val_accuracy: 0.4752
    Epoch 00018: early stopping
    Test loss: 2.2008650302886963
    Test accuracy: 0.4683000147342682
    
     
    
    


    
![png](output_115_1.png)
    



    
![png](output_115_2.png)
    


## Color -  Superclass (Augmented)

### Set up Data Augmentation


```python
# Set our X_train, y_train and X_test, y_test

X_train = Train_data
y_train = Train_coarse #set coarse/superclass as our classification target

X_test = Test_data
y_test = Test_coarse

# Create training image data generator
train_datagen = ImageDataGenerator(rescale=1./255, 
                                   rotation_range=0,
                                   horizontal_flip=True,
                                  validation_split = 0.2)

 
train_generator=train_datagen.flow(X_train, y_train, shuffle=False, batch_size=128, subset='training')
validation_generator = train_datagen.flow(X_train, y_train, shuffle=False, batch_size=128, subset='validation')
 
ES = EarlyStopping(monitor='val_accuracy', patience=5, mode='auto', min_delta=0.0001, verbose=1)
```


```python
Train_coarse
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>coarse</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>11</td>
    </tr>
    <tr>
      <th>1</th>
      <td>15</td>
    </tr>
    <tr>
      <th>2</th>
      <td>4</td>
    </tr>
    <tr>
      <th>3</th>
      <td>14</td>
    </tr>
    <tr>
      <th>4</th>
      <td>1</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
    </tr>
    <tr>
      <th>49995</th>
      <td>16</td>
    </tr>
    <tr>
      <th>49996</th>
      <td>7</td>
    </tr>
    <tr>
      <th>49997</th>
      <td>8</td>
    </tr>
    <tr>
      <th>49998</th>
      <td>7</td>
    </tr>
    <tr>
      <th>49999</th>
      <td>1</td>
    </tr>
  </tbody>
</table>
<p>50000 rows × 1 columns</p>
</div>



The `train_generator` consisted of 313 tuple of image data (X) and y (class). In each set of tuple except for the last one, there are 128 images which corresponds to the batch size we set. The last set contains only 64 images. In total, there are 40,000 images (312 x 128 + 1 x 64) for training.


```python
len(train_generator)
```




    313




```python
X, y = train_generator[312]
len(X)
```




    64



In the CNN models below, we yielded some very low accuracy scores and perhaps the classes in the train/validation set is not stratified properly. We will check it below.


```python
# find out if the classes are stratified in the train_generator


# create dataframe to store the count
class_in_train = pd.DataFrame(np.zeros((1, 20)))

# loop through train_generator and count classes
for i in range(len(train_generator)):
    X, y = train_generator[i]
    for n in range(len(y)):
        count = class_in_train[int(y[n])]
        class_in_train[int(y[n])] = count + 1

# Print df
class_in_train.T
    
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>0</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1967.0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2008.0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1989.0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>2006.0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>1986.0</td>
    </tr>
    <tr>
      <th>5</th>
      <td>2001.0</td>
    </tr>
    <tr>
      <th>6</th>
      <td>1995.0</td>
    </tr>
    <tr>
      <th>7</th>
      <td>2034.0</td>
    </tr>
    <tr>
      <th>8</th>
      <td>2025.0</td>
    </tr>
    <tr>
      <th>9</th>
      <td>2044.0</td>
    </tr>
    <tr>
      <th>10</th>
      <td>2000.0</td>
    </tr>
    <tr>
      <th>11</th>
      <td>1988.0</td>
    </tr>
    <tr>
      <th>12</th>
      <td>1969.0</td>
    </tr>
    <tr>
      <th>13</th>
      <td>1991.0</td>
    </tr>
    <tr>
      <th>14</th>
      <td>2002.0</td>
    </tr>
    <tr>
      <th>15</th>
      <td>2010.0</td>
    </tr>
    <tr>
      <th>16</th>
      <td>2020.0</td>
    </tr>
    <tr>
      <th>17</th>
      <td>2017.0</td>
    </tr>
    <tr>
      <th>18</th>
      <td>1961.0</td>
    </tr>
    <tr>
      <th>19</th>
      <td>1987.0</td>
    </tr>
  </tbody>
</table>
</div>




```python
class_in_train.T.sum(axis=0)
```




    0    40000.0
    dtype: float64



We expect 2000 images per class, so the class are relatively balance. 

The `validation_generator` consisted of 79 tuple of image data (X) and y (class). In each set of tuple except for the last one, there are 128 images which corresponds to the batch size we set. The last set contains only 16 images. In total, there are 10,000 images (78 x 128 + 1 x 16) for training. This corresponds to the 20% validation split we set.


```python
len(validation_generator)
```




    79




```python
X, y = validation_generator[78]
len(X)
```




    16




```python
# find out if the classes are stratifiedb in the validation_generator


# create dataframe to store the count
class_in_validation = pd.DataFrame(np.zeros((1, 20)))

# loop through validation_generator and count classes
for i in range(len(validation_generator)):
    X, y = validation_generator[i]
    for n in range(len(y)):
        count = class_in_validation[int(y[n])]
        class_in_validation[int(y[n])] = count + 1

# Print df
class_in_validation.T
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>0</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>533.0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>492.0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>511.0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>494.0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>514.0</td>
    </tr>
    <tr>
      <th>5</th>
      <td>499.0</td>
    </tr>
    <tr>
      <th>6</th>
      <td>505.0</td>
    </tr>
    <tr>
      <th>7</th>
      <td>466.0</td>
    </tr>
    <tr>
      <th>8</th>
      <td>475.0</td>
    </tr>
    <tr>
      <th>9</th>
      <td>456.0</td>
    </tr>
    <tr>
      <th>10</th>
      <td>500.0</td>
    </tr>
    <tr>
      <th>11</th>
      <td>512.0</td>
    </tr>
    <tr>
      <th>12</th>
      <td>531.0</td>
    </tr>
    <tr>
      <th>13</th>
      <td>509.0</td>
    </tr>
    <tr>
      <th>14</th>
      <td>498.0</td>
    </tr>
    <tr>
      <th>15</th>
      <td>490.0</td>
    </tr>
    <tr>
      <th>16</th>
      <td>480.0</td>
    </tr>
    <tr>
      <th>17</th>
      <td>483.0</td>
    </tr>
    <tr>
      <th>18</th>
      <td>539.0</td>
    </tr>
    <tr>
      <th>19</th>
      <td>513.0</td>
    </tr>
  </tbody>
</table>
</div>



We expect 500 images per class, so the classes seem balance for the most part.


```python
# Print random images from train generator

# Create subplots

plt.subplots(5,5, figsize=(10,10))


for i in range(25):
    X, y = train_generator[i]
    image = X[i]
    title = Superclass_label.iloc[int(y[i])]['Superclass_label']
    plt.subplot(5,5,i+1) 
    plt.xlabel(title)
    plt.imshow(image)   

plt.tight_layout()
plt.show()

```


    
![png](output_132_0.png)
    



```python
# Print random images from validation generator

# Create subplots

plt.subplots(5,5, figsize=(10,10))


for i in range(25):
    X, y = validation_generator[i]
    image = X[i]
    title = Superclass_label.iloc[int(y[i])]['Superclass_label']
    plt.subplot(5,5,i+1) 
    plt.xlabel(title)
    plt.imshow(image)   

plt.tight_layout()
plt.show()
```


    
![png](output_133_0.png)
    


##### ACNN 1 - Model 2


```python
ACNN_model2 = Sequential()

# Create simple CNN model architecture with Pooling for dimensionality reduction 
# and Dropout to reduce overfitting
ACNN_model2.add(Conv2D(32, kernel_size=(3, 3), activation = 'relu', input_shape = (32,32,3)))
ACNN_model2.add(MaxPooling2D(pool_size=(2, 2)))
ACNN_model2.add(Dropout(0.1))

ACNN_model2.add(Conv2D(64, kernel_size=(3, 3), activation = 'relu'))
ACNN_model2.add(MaxPooling2D(pool_size=(2, 2)))
ACNN_model2.add(Dropout(0.2))

ACNN_model2.add(Conv2D(256, kernel_size=(3, 3), activation = 'relu'))
ACNN_model2.add(MaxPooling2D(pool_size=(2, 2)))
ACNN_model2.add(Dropout(0.4))

# Flatten the output of our convolutional layers
ACNN_model2.add(Flatten())

# Add dense layers
ACNN_model2.add(Dense(256, activation= 'relu'))
ACNN_model2.add(Dense(64, activation= 'relu'))
ACNN_model2.add(Dense(32, activation= 'relu'))
ACNN_model2.add(Dense(len(np.unique(y_train)), activation='softmax'))

# Print out a summary of the network
ACNN_model2.summary()

# Compile the model with the desired loss function, optimizer, and metric(s) to track
ACNN_model2.compile(loss = 'sparse_categorical_crossentropy', 
                  optimizer = 'Adam',
                  metrics = ['accuracy'])

# Fit the model on the training data, defining desired batch_size & number of epochs,
# running validation after each batch
ACNN2 = ACNN_model2.fit(train_generator,
                          epochs = 50,
                          verbose = 1,
                          validation_data = validation_generator)



test_loss_score(ACNN_model2)
accuracy_loss_plots(ACNN2)
confusion(ACNN_model2)

save_format='h5'
ACNN_model2.save('CNNmodels/ACNN_model2.h5')
```

    Model: "sequential_3"
    _________________________________________________________________
    Layer (type)                 Output Shape              Param #   
    =================================================================
    conv2d_9 (Conv2D)            (None, 30, 30, 32)        896       
    _________________________________________________________________
    max_pooling2d_9 (MaxPooling2 (None, 15, 15, 32)        0         
    _________________________________________________________________
    dropout_9 (Dropout)          (None, 15, 15, 32)        0         
    _________________________________________________________________
    conv2d_10 (Conv2D)           (None, 13, 13, 64)        18496     
    _________________________________________________________________
    max_pooling2d_10 (MaxPooling (None, 6, 6, 64)          0         
    _________________________________________________________________
    dropout_10 (Dropout)         (None, 6, 6, 64)          0         
    _________________________________________________________________
    conv2d_11 (Conv2D)           (None, 4, 4, 256)         147712    
    _________________________________________________________________
    max_pooling2d_11 (MaxPooling (None, 2, 2, 256)         0         
    _________________________________________________________________
    dropout_11 (Dropout)         (None, 2, 2, 256)         0         
    _________________________________________________________________
    flatten_3 (Flatten)          (None, 1024)              0         
    _________________________________________________________________
    dense_12 (Dense)             (None, 256)               262400    
    _________________________________________________________________
    dense_13 (Dense)             (None, 64)                16448     
    _________________________________________________________________
    dense_14 (Dense)             (None, 32)                2080      
    _________________________________________________________________
    dense_15 (Dense)             (None, 20)                660       
    =================================================================
    Total params: 448,692
    Trainable params: 448,692
    Non-trainable params: 0
    _________________________________________________________________
    Epoch 1/50
    313/313 [==============================] - 21s 66ms/step - loss: 2.7252 - accuracy: 0.0272 - val_loss: 2.5231 - val_accuracy: 0.0086
    Epoch 2/50
    313/313 [==============================] - 22s 71ms/step - loss: 2.4072 - accuracy: 0.0459 - val_loss: 2.3132 - val_accuracy: 0.0269
    Epoch 3/50
    313/313 [==============================] - 22s 71ms/step - loss: 2.2363 - accuracy: 0.0516 - val_loss: 2.1392 - val_accuracy: 0.0361
    Epoch 4/50
    313/313 [==============================] - 22s 71ms/step - loss: 2.1136 - accuracy: 0.0496 - val_loss: 2.0201 - val_accuracy: 0.0550
    Epoch 5/50
    313/313 [==============================] - 22s 71ms/step - loss: 2.0229 - accuracy: 0.0494 - val_loss: 1.9511 - val_accuracy: 0.0168
    Epoch 6/50
    313/313 [==============================] - 22s 71ms/step - loss: 1.9487 - accuracy: 0.0488 - val_loss: 1.8830 - val_accuracy: 0.0419
    Epoch 7/50
    313/313 [==============================] - 22s 70ms/step - loss: 1.8780 - accuracy: 0.0507 - val_loss: 1.7931 - val_accuracy: 0.0418
    Epoch 8/50
    313/313 [==============================] - 22s 71ms/step - loss: 1.8274 - accuracy: 0.0474 - val_loss: 1.7564 - val_accuracy: 0.0739
    Epoch 9/50
    313/313 [==============================] - 22s 70ms/step - loss: 1.7726 - accuracy: 0.0478 - val_loss: 1.7302 - val_accuracy: 0.0512
    Epoch 10/50
    313/313 [==============================] - 22s 71ms/step - loss: 1.7315 - accuracy: 0.0476 - val_loss: 1.6894 - val_accuracy: 0.0620
    Epoch 11/50
    313/313 [==============================] - 22s 71ms/step - loss: 1.6913 - accuracy: 0.0483 - val_loss: 1.6530 - val_accuracy: 0.0317
    Epoch 12/50
    313/313 [==============================] - 22s 72ms/step - loss: 1.6681 - accuracy: 0.0476 - val_loss: 1.6108 - val_accuracy: 0.0484
    Epoch 13/50
    313/313 [==============================] - 22s 71ms/step - loss: 1.6343 - accuracy: 0.0473 - val_loss: 1.6067 - val_accuracy: 0.0395
    Epoch 14/50
    313/313 [==============================] - 22s 70ms/step - loss: 1.6131 - accuracy: 0.0473 - val_loss: 1.5673 - val_accuracy: 0.0468
    Epoch 15/50
    313/313 [==============================] - 22s 71ms/step - loss: 1.5801 - accuracy: 0.0472 - val_loss: 1.5658 - val_accuracy: 0.0443
    Epoch 16/50
    313/313 [==============================] - 22s 71ms/step - loss: 1.5545 - accuracy: 0.0465 - val_loss: 1.5387 - val_accuracy: 0.0412
    Epoch 17/50
    313/313 [==============================] - 22s 71ms/step - loss: 1.5337 - accuracy: 0.0465 - val_loss: 1.5466 - val_accuracy: 0.0398
    Epoch 18/50
    313/313 [==============================] - 22s 71ms/step - loss: 1.5158 - accuracy: 0.0472 - val_loss: 1.5189 - val_accuracy: 0.0585
    Epoch 19/50
    313/313 [==============================] - 22s 70ms/step - loss: 1.5014 - accuracy: 0.0478 - val_loss: 1.5269 - val_accuracy: 0.0527
    Epoch 20/50
    313/313 [==============================] - 22s 70ms/step - loss: 1.4725 - accuracy: 0.0469 - val_loss: 1.4618 - val_accuracy: 0.0528
    Epoch 21/50
    313/313 [==============================] - 22s 71ms/step - loss: 1.4603 - accuracy: 0.0486 - val_loss: 1.4961 - val_accuracy: 0.0429
    Epoch 22/50
    313/313 [==============================] - 22s 71ms/step - loss: 1.4510 - accuracy: 0.0462 - val_loss: 1.4686 - val_accuracy: 0.0481
    Epoch 23/50
    313/313 [==============================] - 22s 72ms/step - loss: 1.4257 - accuracy: 0.0460 - val_loss: 1.4593 - val_accuracy: 0.0658
    Epoch 24/50
    313/313 [==============================] - 22s 71ms/step - loss: 1.4093 - accuracy: 0.0472 - val_loss: 1.4477 - val_accuracy: 0.0468
    Epoch 25/50
    313/313 [==============================] - 22s 71ms/step - loss: 1.3986 - accuracy: 0.0469 - val_loss: 1.4382 - val_accuracy: 0.0536
    Epoch 26/50
    313/313 [==============================] - 22s 71ms/step - loss: 1.3852 - accuracy: 0.0465 - val_loss: 1.4467 - val_accuracy: 0.0426
    Epoch 27/50
    313/313 [==============================] - 22s 71ms/step - loss: 1.3630 - accuracy: 0.0450 - val_loss: 1.4096 - val_accuracy: 0.0453
    Epoch 28/50
    313/313 [==============================] - 22s 71ms/step - loss: 1.3625 - accuracy: 0.0484 - val_loss: 1.4369 - val_accuracy: 0.0667
    Epoch 29/50
    313/313 [==============================] - 22s 71ms/step - loss: 1.3561 - accuracy: 0.0468 - val_loss: 1.4061 - val_accuracy: 0.0496
    Epoch 30/50
    313/313 [==============================] - 22s 70ms/step - loss: 1.3410 - accuracy: 0.0459 - val_loss: 1.4133 - val_accuracy: 0.0569
    Epoch 31/50
    313/313 [==============================] - 22s 71ms/step - loss: 1.3215 - accuracy: 0.0481 - val_loss: 1.4174 - val_accuracy: 0.0384
    Epoch 32/50
    313/313 [==============================] - 22s 71ms/step - loss: 1.3262 - accuracy: 0.0474 - val_loss: 1.4110 - val_accuracy: 0.0378
    Epoch 33/50
    313/313 [==============================] - 22s 71ms/step - loss: 1.3026 - accuracy: 0.0467 - val_loss: 1.4066 - val_accuracy: 0.0572
    Epoch 34/50
    313/313 [==============================] - 22s 70ms/step - loss: 1.2924 - accuracy: 0.0485 - val_loss: 1.3865 - val_accuracy: 0.0582
    Epoch 35/50
    313/313 [==============================] - 22s 71ms/step - loss: 1.2956 - accuracy: 0.0474 - val_loss: 1.3988 - val_accuracy: 0.0818
    Epoch 36/50
    313/313 [==============================] - 22s 71ms/step - loss: 1.2764 - accuracy: 0.0474 - val_loss: 1.3969 - val_accuracy: 0.0536
    Epoch 37/50
    313/313 [==============================] - 22s 71ms/step - loss: 1.2675 - accuracy: 0.0476 - val_loss: 1.3725 - val_accuracy: 0.0443
    Epoch 38/50
    313/313 [==============================] - 22s 72ms/step - loss: 1.2610 - accuracy: 0.0471 - val_loss: 1.3753 - val_accuracy: 0.0571
    Epoch 39/50
    313/313 [==============================] - 22s 70ms/step - loss: 1.2536 - accuracy: 0.0483 - val_loss: 1.3774 - val_accuracy: 0.0424
    Epoch 40/50
    313/313 [==============================] - 22s 71ms/step - loss: 1.2521 - accuracy: 0.0478 - val_loss: 1.3785 - val_accuracy: 0.0373
    Epoch 41/50
    313/313 [==============================] - 22s 71ms/step - loss: 1.2419 - accuracy: 0.0459 - val_loss: 1.3790 - val_accuracy: 0.0440
    Epoch 42/50
    313/313 [==============================] - 22s 70ms/step - loss: 1.2295 - accuracy: 0.0470 - val_loss: 1.3574 - val_accuracy: 0.0534
    Epoch 43/50
    313/313 [==============================] - 22s 70ms/step - loss: 1.2250 - accuracy: 0.0479 - val_loss: 1.3745 - val_accuracy: 0.0511
    Epoch 44/50
    313/313 [==============================] - 22s 70ms/step - loss: 1.2227 - accuracy: 0.0472 - val_loss: 1.3840 - val_accuracy: 0.0747
    Epoch 45/50
    313/313 [==============================] - 22s 70ms/step - loss: 1.2198 - accuracy: 0.0489 - val_loss: 1.3624 - val_accuracy: 0.0596
    Epoch 46/50
    313/313 [==============================] - 22s 70ms/step - loss: 1.2126 - accuracy: 0.0475 - val_loss: 1.3765 - val_accuracy: 0.0526
    Epoch 47/50
    313/313 [==============================] - 22s 69ms/step - loss: 1.2017 - accuracy: 0.0492 - val_loss: 1.3651 - val_accuracy: 0.0490
    Epoch 48/50
    313/313 [==============================] - 22s 69ms/step - loss: 1.1943 - accuracy: 0.0476 - val_loss: 1.3763 - val_accuracy: 0.0686
    Epoch 49/50
    313/313 [==============================] - 22s 71ms/step - loss: 1.1906 - accuracy: 0.0481 - val_loss: 1.3457 - val_accuracy: 0.0409
    Epoch 50/50
    313/313 [==============================] - 22s 70ms/step - loss: 1.1831 - accuracy: 0.0471 - val_loss: 1.3604 - val_accuracy: 0.0415
    Test loss: 359.4486083984375
    Test accuracy: 0.0031999999191612005
    
     
    
    


    
![png](output_135_1.png)
    



    
![png](output_135_2.png)
    


##### ACNN 1 - Model 4


```python

ACNN_model4 = Sequential()

# Create simple CNN model architecture with Pooling for dimensionality reduction 
# and Dropout to reduce overfitting
ACNN_model4.add(Conv2D(128, kernel_size=(3, 3), activation = 'relu', input_shape = (32,32,3)))
ACNN_model4.add(MaxPooling2D(pool_size=(2, 2)))
ACNN_model4.add(Dropout(0.1))

ACNN_model4.add(Conv2D(256, kernel_size=(3, 3), activation = 'relu'))
ACNN_model4.add(MaxPooling2D(pool_size=(2, 2)))
ACNN_model4.add(Dropout(0.2))

ACNN_model4.add(Conv2D(512, kernel_size=(3, 3), activation = 'relu'))
ACNN_model4.add(MaxPooling2D(pool_size=(2, 2)))
ACNN_model4.add(Dropout(0.4))

# Flatten the output of our convolutional layers
ACNN_model4.add(Flatten())

# Add dense layers
ACNN_model4.add(Dense(512, activation= 'relu'))
ACNN_model4.add(Dense(256, activation= 'relu'))
ACNN_model4.add(Dense(128, activation= 'relu'))
ACNN_model4.add(Dense(len(np.unique(y_train)), activation='softmax'))

# Print out a summary of the network
ACNN_model4.summary()

# Compile the model with the desired loss function, optimizer, and metric(s) to track
ACNN_model4.compile(loss = 'sparse_categorical_crossentropy', 
                  optimizer = 'Adam',
                  metrics = ['accuracy'])

# Fit the model on the training data, defining desired batch_size & number of epochs,
# running validation after each batch
ACNN4 = ACNN_model4.fit(train_generator,
                          epochs = 50,
                          verbose = 1,
                          validation_data = validation_generator,
                            callbacks = ES)



test_loss_score(ACNN_model4)
accuracy_loss_plots(ACNN4)
confusion(ACNN_model4)

save_format='h5'
ACNN_model4.save('CNNmodels/ACNN_model4.h5')
```

    Model: "sequential_2"
    _________________________________________________________________
    Layer (type)                 Output Shape              Param #   
    =================================================================
    conv2d_6 (Conv2D)            (None, 30, 30, 128)       3584      
    _________________________________________________________________
    max_pooling2d_6 (MaxPooling2 (None, 15, 15, 128)       0         
    _________________________________________________________________
    dropout_6 (Dropout)          (None, 15, 15, 128)       0         
    _________________________________________________________________
    conv2d_7 (Conv2D)            (None, 13, 13, 256)       295168    
    _________________________________________________________________
    max_pooling2d_7 (MaxPooling2 (None, 6, 6, 256)         0         
    _________________________________________________________________
    dropout_7 (Dropout)          (None, 6, 6, 256)         0         
    _________________________________________________________________
    conv2d_8 (Conv2D)            (None, 4, 4, 512)         1180160   
    _________________________________________________________________
    max_pooling2d_8 (MaxPooling2 (None, 2, 2, 512)         0         
    _________________________________________________________________
    dropout_8 (Dropout)          (None, 2, 2, 512)         0         
    _________________________________________________________________
    flatten_2 (Flatten)          (None, 2048)              0         
    _________________________________________________________________
    dense_8 (Dense)              (None, 512)               1049088   
    _________________________________________________________________
    dense_9 (Dense)              (None, 256)               131328    
    _________________________________________________________________
    dense_10 (Dense)             (None, 128)               32896     
    _________________________________________________________________
    dense_11 (Dense)             (None, 20)                2580      
    =================================================================
    Total params: 2,694,804
    Trainable params: 2,694,804
    Non-trainable params: 0
    _________________________________________________________________
    Epoch 1/50
    313/313 [==============================] - 133s 424ms/step - loss: 3.3479 - accuracy: 0.0342 - val_loss: 2.5674 - val_accuracy: 0.0075
    Epoch 2/50
    196/313 [=================>............] - ETA: 49s - loss: 2.5110 - accuracy: 0.0417


    ---------------------------------------------------------------------------

    KeyboardInterrupt                         Traceback (most recent call last)

    <ipython-input-52-135d0eb2c8d8> in <module>
         34 # Fit the model on the training data, defining desired batch_size & number of epochs,
         35 # running validation after each batch
    ---> 36 ACNN4 = ACNN_model4.fit(train_generator,
         37                           epochs = 50,
         38                           verbose = 1,
    

    ~\anaconda3\envs\deeplearning\lib\site-packages\tensorflow\python\keras\engine\training.py in _method_wrapper(self, *args, **kwargs)
         64   def _method_wrapper(self, *args, **kwargs):
         65     if not self._in_multi_worker_mode():  # pylint: disable=protected-access
    ---> 66       return method(self, *args, **kwargs)
         67 
         68     # Running inside `run_distribute_coordinator` already.
    

    ~\anaconda3\envs\deeplearning\lib\site-packages\tensorflow\python\keras\engine\training.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)
        846                 batch_size=batch_size):
        847               callbacks.on_train_batch_begin(step)
    --> 848               tmp_logs = train_function(iterator)
        849               # Catch OutOfRangeError for Datasets of unknown size.
        850               # This blocks until the batch has finished executing.
    

    ~\anaconda3\envs\deeplearning\lib\site-packages\tensorflow\python\eager\def_function.py in __call__(self, *args, **kwds)
        578         xla_context.Exit()
        579     else:
    --> 580       result = self._call(*args, **kwds)
        581 
        582     if tracing_count == self._get_tracing_count():
    

    ~\anaconda3\envs\deeplearning\lib\site-packages\tensorflow\python\eager\def_function.py in _call(self, *args, **kwds)
        609       # In this case we have created variables on the first call, so we run the
        610       # defunned version which is guaranteed to never create variables.
    --> 611       return self._stateless_fn(*args, **kwds)  # pylint: disable=not-callable
        612     elif self._stateful_fn is not None:
        613       # Release the lock early so that multiple threads can perform the call
    

    ~\anaconda3\envs\deeplearning\lib\site-packages\tensorflow\python\eager\function.py in __call__(self, *args, **kwargs)
       2418     with self._lock:
       2419       graph_function, args, kwargs = self._maybe_define_function(args, kwargs)
    -> 2420     return graph_function._filtered_call(args, kwargs)  # pylint: disable=protected-access
       2421 
       2422   @property
    

    ~\anaconda3\envs\deeplearning\lib\site-packages\tensorflow\python\eager\function.py in _filtered_call(self, args, kwargs)
       1659       `args` and `kwargs`.
       1660     """
    -> 1661     return self._call_flat(
       1662         (t for t in nest.flatten((args, kwargs), expand_composites=True)
       1663          if isinstance(t, (ops.Tensor,
    

    ~\anaconda3\envs\deeplearning\lib\site-packages\tensorflow\python\eager\function.py in _call_flat(self, args, captured_inputs, cancellation_manager)
       1743         and executing_eagerly):
       1744       # No tape is watching; skip to running the function.
    -> 1745       return self._build_call_outputs(self._inference_function.call(
       1746           ctx, args, cancellation_manager=cancellation_manager))
       1747     forward_backward = self._select_forward_and_backward_functions(
    

    ~\anaconda3\envs\deeplearning\lib\site-packages\tensorflow\python\eager\function.py in call(self, ctx, args, cancellation_manager)
        591       with _InterpolateFunctionError(self):
        592         if cancellation_manager is None:
    --> 593           outputs = execute.execute(
        594               str(self.signature.name),
        595               num_outputs=self._num_outputs,
    

    ~\anaconda3\envs\deeplearning\lib\site-packages\tensorflow\python\eager\execute.py in quick_execute(op_name, num_outputs, inputs, attrs, ctx, name)
         57   try:
         58     ctx.ensure_initialized()
    ---> 59     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,
         60                                         inputs, attrs, num_outputs)
         61   except core._NotOkStatusException as e:
    

    KeyboardInterrupt: 


https://arxiv.org/pdf/1511.07289.pdf

##### ACNN 2 - Model 5


```python

ACNN_model5 = Sequential()

# Create simple CNN model architecture with Pooling for dimensionality reduction 
# and Dropout to reduce overfitting
ACNN_model5.add(Conv2D(192, kernel_size=(5, 5), activation = 'elu', input_shape = (32,32,3), kernel_regularizer=l2(0.0005))) 
ACNN_model5.add(MaxPooling2D(pool_size=(2, 2), padding='same'))
ACNN_model5.add(Dropout(0.0))

ACNN_model5.add(Conv2D(192, kernel_size=(1, 1), activation = 'elu', padding='same', kernel_regularizer=l2(0.0005)))
ACNN_model5.add(Conv2D(240, kernel_size=(3, 3), activation = 'elu', padding='same', kernel_regularizer=l2(0.0005)))
ACNN_model5.add(MaxPooling2D(pool_size=(2, 2), padding='same'))
ACNN_model5.add(Dropout(0.1))

ACNN_model5.add(Conv2D(240, kernel_size=(1,1), activation = 'elu', padding='same', kernel_regularizer=l2(0.0005)))
ACNN_model5.add(Conv2D(260, kernel_size=(2,2), activation = 'elu', padding='same', kernel_regularizer=l2(0.0005)))
ACNN_model5.add(MaxPooling2D(pool_size=(2, 2), padding='same'))
ACNN_model5.add(Dropout(0.2))

ACNN_model5.add(Conv2D(260, kernel_size=(1,1), activation = 'elu', padding='same', kernel_regularizer=l2(0.0005)))
ACNN_model5.add(Conv2D(280, kernel_size=(2,2), activation = 'elu', padding='same', kernel_regularizer=l2(0.0005)))
ACNN_model5.add(MaxPooling2D(pool_size=(2, 2), padding='same'))
ACNN_model5.add(Dropout(0.3))

ACNN_model5.add(Conv2D(280, kernel_size=(1,1), activation = 'elu', padding='same', kernel_regularizer=l2(0.0005)))
ACNN_model5.add(Conv2D(300, kernel_size=(2,2), activation = 'elu', padding='same', kernel_regularizer=l2(0.0005)))
ACNN_model5.add(MaxPooling2D(pool_size=(2, 2), padding='same'))
ACNN_model5.add(Dropout(0.4))

ACNN_model5.add(Conv2D(300, kernel_size=(2,2), activation = 'elu', padding='same', kernel_regularizer=l2(0.0005)))
ACNN_model5.add(MaxPooling2D(pool_size=(2, 2), padding='same'))
ACNN_model5.add(Dropout(0.5))

# Flatten the output of our convolutional layers
ACNN_model5.add(Flatten())

# Add dense layers
ACNN_model5.add(Dense(len(np.unique(y_train)), activation='softmax'))

# Print out a summary of the network
ACNN_model5.summary()

# Compile the model with the desired loss function, optimizer, and metric(s) to track
ACNN_model5.compile(loss = 'sparse_categorical_crossentropy', #cross entropy is for multi-class classification
                  optimizer = 'Adam',
                  metrics = ['accuracy'])

# Fit the model on the training data, defining desired batch_size & number of epochs,
# running validation after each batch
ACNN5 = ACNN_model5.fit(train_generator,
                          epochs = 100,
                          verbose = 1,
                          validation_data = validation_generator,
                            callbacks = ES)
test_loss_score(ACNN_model5)
accuracy_loss_plots(ACNN5)
confusion(ACNN_model5)

save_format='h5'
ACNN_model5.save('CNNmodels/ACNN_model5.h5')
```

    Model: "sequential_7"
    _________________________________________________________________
    Layer (type)                 Output Shape              Param #   
    =================================================================
    conv2d_21 (Conv2D)           (None, 28, 28, 192)       14592     
    _________________________________________________________________
    max_pooling2d_21 (MaxPooling (None, 14, 14, 192)       0         
    _________________________________________________________________
    dropout_21 (Dropout)         (None, 14, 14, 192)       0         
    _________________________________________________________________
    conv2d_22 (Conv2D)           (None, 14, 14, 192)       37056     
    _________________________________________________________________
    conv2d_23 (Conv2D)           (None, 14, 14, 240)       414960    
    _________________________________________________________________
    max_pooling2d_22 (MaxPooling (None, 7, 7, 240)         0         
    _________________________________________________________________
    dropout_22 (Dropout)         (None, 7, 7, 240)         0         
    _________________________________________________________________
    conv2d_24 (Conv2D)           (None, 7, 7, 240)         57840     
    _________________________________________________________________
    conv2d_25 (Conv2D)           (None, 7, 7, 260)         249860    
    _________________________________________________________________
    max_pooling2d_23 (MaxPooling (None, 4, 4, 260)         0         
    _________________________________________________________________
    dropout_23 (Dropout)         (None, 4, 4, 260)         0         
    _________________________________________________________________
    conv2d_26 (Conv2D)           (None, 4, 4, 260)         67860     
    _________________________________________________________________
    conv2d_27 (Conv2D)           (None, 4, 4, 280)         291480    
    _________________________________________________________________
    max_pooling2d_24 (MaxPooling (None, 2, 2, 280)         0         
    _________________________________________________________________
    dropout_24 (Dropout)         (None, 2, 2, 280)         0         
    _________________________________________________________________
    conv2d_28 (Conv2D)           (None, 2, 2, 280)         78680     
    _________________________________________________________________
    conv2d_29 (Conv2D)           (None, 2, 2, 300)         336300    
    _________________________________________________________________
    max_pooling2d_25 (MaxPooling (None, 1, 1, 300)         0         
    _________________________________________________________________
    dropout_25 (Dropout)         (None, 1, 1, 300)         0         
    _________________________________________________________________
    conv2d_30 (Conv2D)           (None, 1, 1, 300)         360300    
    _________________________________________________________________
    max_pooling2d_26 (MaxPooling (None, 1, 1, 300)         0         
    _________________________________________________________________
    dropout_26 (Dropout)         (None, 1, 1, 300)         0         
    _________________________________________________________________
    flatten_7 (Flatten)          (None, 300)               0         
    _________________________________________________________________
    dense_28 (Dense)             (None, 20)                6020      
    =================================================================
    Total params: 1,914,948
    Trainable params: 1,914,948
    Non-trainable params: 0
    _________________________________________________________________
    Epoch 1/100
    313/313 [==============================] - 211s 675ms/step - loss: 3.3901 - accuracy: 0.0546 - val_loss: 2.9219 - val_accuracy: 0.1118
    Epoch 2/100
    313/313 [==============================] - 211s 673ms/step - loss: 2.8080 - accuracy: 0.0514 - val_loss: 2.5764 - val_accuracy: 0.0387
    Epoch 3/100
    313/313 [==============================] - 206s 659ms/step - loss: 2.6347 - accuracy: 0.0483 - val_loss: 2.4541 - val_accuracy: 0.1091
    Epoch 4/100
    313/313 [==============================] - 205s 654ms/step - loss: 2.5247 - accuracy: 0.0494 - val_loss: 2.3811 - val_accuracy: 0.0361
    Epoch 5/100
    313/313 [==============================] - 204s 652ms/step - loss: 2.4501 - accuracy: 0.0501 - val_loss: 2.3433 - val_accuracy: 0.0510
    Epoch 6/100
    313/313 [==============================] - 204s 652ms/step - loss: 2.4222 - accuracy: 0.0493 - val_loss: 2.2909 - val_accuracy: 0.0484
    Epoch 00006: early stopping
    Test loss: 17.973800659179688
    Test accuracy: 0.0
    
     
    
    


    
![png](output_140_1.png)
    



    
![png](output_140_2.png)
    


##### ACNN 2 - Model 6


```python
ACNN_model6 = Sequential()

# Create simple CNN model architecture with Pooling for dimensionality reduction 
# and Dropout to reduce overfitting
ACNN_model6.add(Conv2D(32, kernel_size=(3,3), activation = 'elu', input_shape = (32,32,3), kernel_regularizer=l2(0.0005))) 
ACNN_model6.add(MaxPooling2D(pool_size=(2, 2), padding='same'))

ACNN_model6.add(Conv2D(64, kernel_size=(3,3), activation = 'elu', padding='same', kernel_regularizer=l2(0.0005)))
ACNN_model6.add(Conv2D(128, kernel_size=(3,3), activation = 'elu', padding='same', kernel_regularizer=l2(0.0005)))
ACNN_model6.add(MaxPooling2D(pool_size=(2, 2), padding='same'))
ACNN_model6.add(Dropout(0.1))

ACNN_model6.add(Conv2D(128, kernel_size=(2,2), activation = 'elu', padding='same', kernel_regularizer=l2(0.0005)))
ACNN_model6.add(Conv2D(256, kernel_size=(2,2), activation = 'elu', padding='same', kernel_regularizer=l2(0.0005)))
ACNN_model6.add(MaxPooling2D(pool_size=(2, 2), padding='same'))
ACNN_model6.add(Dropout(0.2))

ACNN_model6.add(Conv2D(256, kernel_size=(1,1), activation = 'elu', padding='same', kernel_regularizer=l2(0.0005)))
ACNN_model6.add(Conv2D(512, kernel_size=(1,1), activation = 'elu', padding='same', kernel_regularizer=l2(0.0005)))
ACNN_model6.add(MaxPooling2D(pool_size=(2, 2), padding='same'))
ACNN_model6.add(Dropout(0.3))

# Flatten the output of our convolutional layers
ACNN_model6.add(Flatten())

# Add dense layers
ACNN_model6.add(Dense(512, activation = 'elu'))
ACNN_model6.add(Dense(256, activation = 'elu'))
ACNN_model6.add(Dense(len(np.unique(y_train)), activation='softmax'))

# Print out a summary of the network
ACNN_model6.summary()

# Compile the model with the desired loss function, optimizer, and metric(s) to track
ACNN_model6.compile(loss = 'sparse_categorical_crossentropy', #cross entropy is for multi-class classification
                  optimizer = 'Adam',
                  metrics = ['accuracy'])

# Fit the model on the training data, defining desired batch_size & number of epochs,
# running validation after each batch
ACNN6 = ACNN_model6.fit(train_generator,
                              epochs = 100,
                              verbose = 1,
                              validation_data = validation_generator,
                                callbacks = ES)

test_loss_score(ACNN_model6)
accuracy_loss_plots(ACNN6)
confusion(ACNN_model6)

ACNN_model6.save('CNNmodels/ACNN_model6.h5')
```

    Model: "sequential_8"
    _________________________________________________________________
    Layer (type)                 Output Shape              Param #   
    =================================================================
    conv2d_31 (Conv2D)           (None, 30, 30, 32)        896       
    _________________________________________________________________
    max_pooling2d_27 (MaxPooling (None, 15, 15, 32)        0         
    _________________________________________________________________
    conv2d_32 (Conv2D)           (None, 15, 15, 64)        18496     
    _________________________________________________________________
    conv2d_33 (Conv2D)           (None, 15, 15, 128)       73856     
    _________________________________________________________________
    max_pooling2d_28 (MaxPooling (None, 8, 8, 128)         0         
    _________________________________________________________________
    dropout_27 (Dropout)         (None, 8, 8, 128)         0         
    _________________________________________________________________
    conv2d_34 (Conv2D)           (None, 8, 8, 128)         65664     
    _________________________________________________________________
    conv2d_35 (Conv2D)           (None, 8, 8, 256)         131328    
    _________________________________________________________________
    max_pooling2d_29 (MaxPooling (None, 4, 4, 256)         0         
    _________________________________________________________________
    dropout_28 (Dropout)         (None, 4, 4, 256)         0         
    _________________________________________________________________
    conv2d_36 (Conv2D)           (None, 4, 4, 256)         65792     
    _________________________________________________________________
    conv2d_37 (Conv2D)           (None, 4, 4, 512)         131584    
    _________________________________________________________________
    max_pooling2d_30 (MaxPooling (None, 2, 2, 512)         0         
    _________________________________________________________________
    dropout_29 (Dropout)         (None, 2, 2, 512)         0         
    _________________________________________________________________
    flatten_8 (Flatten)          (None, 2048)              0         
    _________________________________________________________________
    dense_29 (Dense)             (None, 512)               1049088   
    _________________________________________________________________
    dense_30 (Dense)             (None, 256)               131328    
    _________________________________________________________________
    dense_31 (Dense)             (None, 20)                5140      
    =================================================================
    Total params: 1,673,172
    Trainable params: 1,673,172
    Non-trainable params: 0
    _________________________________________________________________
    Epoch 1/100
    313/313 [==============================] - 73s 232ms/step - loss: 2.8711 - accuracy: 0.0481 - val_loss: 2.5972 - val_accuracy: 0.1236
    Epoch 2/100
    313/313 [==============================] - 73s 232ms/step - loss: 2.4574 - accuracy: 0.0511 - val_loss: 2.3205 - val_accuracy: 0.0870
    Epoch 3/100
    313/313 [==============================] - 73s 232ms/step - loss: 2.2418 - accuracy: 0.0506 - val_loss: 2.1603 - val_accuracy: 0.0478
    Epoch 4/100
    313/313 [==============================] - 73s 233ms/step - loss: 2.1194 - accuracy: 0.0504 - val_loss: 2.0772 - val_accuracy: 0.0172
    Epoch 5/100
    313/313 [==============================] - 73s 233ms/step - loss: 2.0244 - accuracy: 0.0520 - val_loss: 1.9405 - val_accuracy: 0.0374
    Epoch 6/100
    313/313 [==============================] - 73s 232ms/step - loss: 1.9433 - accuracy: 0.0498 - val_loss: 1.9686 - val_accuracy: 0.0726
    Epoch 00006: early stopping
    Test loss: 23.75376319885254
    Test accuracy: 0.0
    
     
    
    


    
![png](output_142_1.png)
    



    
![png](output_142_2.png)
    


##### AResNet - Model 1


```python
model = ResNet50V2(weights='imagenet',
                   include_top=False,
                   pooling='max',
                   input_shape=(32,32,3))
for layer in model.layers:
    layer.trainable = False

    
ARNmodel1 = Sequential()

ARNmodel1.add(model)
ARNmodel1.add(Flatten())
ARNmodel1.add(Dense(2048, activation= 'relu'))
ARNmodel1.add(Dense(1024, activation= 'relu'))
ARNmodel1.add(Dense(512, activation= 'relu'))
ARNmodel1.add(Dense(len(np.unique(y_train)), activation='softmax'))

ARNmodel1.compile(optimizer='Adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

ARN1 = ARNmodel1.fit(train_generator,
                      epochs = 50,
                      verbose = 1,
                      validation_data = validation_generator,
                        callbacks = ES)

test_loss_score(ARNmodel1)
accuracy_loss_plots(ARN1)
confusion(ARNmodel1)
save_format='h5'
ARNmodel1.save('CNNmodels/ARNmodel1.h5')
```

    Epoch 1/50
    313/313 [==============================] - 65s 207ms/step - loss: 2.5799 - accuracy: 0.0329 - val_loss: 2.4589 - val_accuracy: 0.0137
    Epoch 2/50
    313/313 [==============================] - 64s 204ms/step - loss: 2.4115 - accuracy: 0.0353 - val_loss: 2.4021 - val_accuracy: 0.0156
    Epoch 3/50
    313/313 [==============================] - 64s 206ms/step - loss: 2.3441 - accuracy: 0.0344 - val_loss: 2.3891 - val_accuracy: 0.0634
    Epoch 4/50
    313/313 [==============================] - 66s 210ms/step - loss: 2.3100 - accuracy: 0.0328 - val_loss: 2.3572 - val_accuracy: 0.0264
    Epoch 5/50
    313/313 [==============================] - 66s 211ms/step - loss: 2.2672 - accuracy: 0.0360 - val_loss: 2.3383 - val_accuracy: 0.0344
    Epoch 6/50
    313/313 [==============================] - 65s 208ms/step - loss: 2.2414 - accuracy: 0.0379 - val_loss: 2.3234 - val_accuracy: 0.0279
    Epoch 7/50
    313/313 [==============================] - 65s 208ms/step - loss: 2.2092 - accuracy: 0.0360 - val_loss: 2.3325 - val_accuracy: 0.0558
    Epoch 8/50
    313/313 [==============================] - 66s 212ms/step - loss: 2.1886 - accuracy: 0.0362 - val_loss: 2.3265 - val_accuracy: 0.0472
    Epoch 00008: early stopping
    Test loss: 582.4730834960938
    Test accuracy: 0.0
    
     
    
    


    
![png](output_144_1.png)
    



    
![png](output_144_2.png)
    


##### AVGG16 - Model 2


```python
model = VGG16(weights='imagenet',
                   include_top=False,
                   pooling='max',
                   input_shape=(32,32,3))

for layer in model.layers:
    layer.trainable = False
    
AVGmodel2 = Sequential()

AVGmodel2.add(model)
AVGmodel2.add(Flatten())
AVGmodel2.add(Dense(512, activation= 'relu'))
AVGmodel2.add(Dense(256, activation= 'relu')) 
AVGmodel2.add(Dense(len(np.unique(y_train)), activation='softmax'))

AVGmodel2.compile(optimizer='Adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

AVG2 = AVGmodel2.fit(train_generator,
                      epochs = 50,
                      verbose = 1,
                      validation_data = validation_generator,
                        callbacks = ES)

test_loss_score(AVGmodel2)
accuracy_loss_plots(AVG2)
confusion(AVGmodel2)
save_format='h5'
AVGmodel2.save('CNNmodels/AVGmodel2.h5')
```

    Epoch 1/50
    313/313 [==============================] - 124s 398ms/step - loss: 2.1280 - accuracy: 0.0472 - val_loss: 1.9941 - val_accuracy: 0.0554
    Epoch 2/50
    313/313 [==============================] - 142s 453ms/step - loss: 1.8743 - accuracy: 0.0470 - val_loss: 1.8612 - val_accuracy: 0.0126
    Epoch 3/50
    313/313 [==============================] - 141s 450ms/step - loss: 1.7783 - accuracy: 0.0474 - val_loss: 1.8121 - val_accuracy: 0.0558
    Epoch 4/50
    313/313 [==============================] - 140s 448ms/step - loss: 1.7089 - accuracy: 0.0466 - val_loss: 1.7889 - val_accuracy: 0.0215
    Epoch 5/50
    313/313 [==============================] - 142s 454ms/step - loss: 1.6571 - accuracy: 0.0448 - val_loss: 1.7759 - val_accuracy: 0.0556
    Epoch 6/50
    313/313 [==============================] - 140s 449ms/step - loss: 1.6024 - accuracy: 0.0440 - val_loss: 1.7436 - val_accuracy: 0.0559
    Epoch 7/50
    313/313 [==============================] - 142s 455ms/step - loss: 1.5521 - accuracy: 0.0459 - val_loss: 1.7373 - val_accuracy: 0.0418
    Epoch 8/50
    313/313 [==============================] - 143s 456ms/step - loss: 1.5127 - accuracy: 0.0442 - val_loss: 1.7340 - val_accuracy: 0.0563
    Epoch 9/50
    313/313 [==============================] - 141s 452ms/step - loss: 1.4671 - accuracy: 0.0454 - val_loss: 1.7547 - val_accuracy: 0.0409
    Epoch 10/50
    313/313 [==============================] - 144s 459ms/step - loss: 1.4286 - accuracy: 0.0463 - val_loss: 1.7390 - val_accuracy: 0.0350
    Epoch 11/50
    313/313 [==============================] - 141s 449ms/step - loss: 1.3905 - accuracy: 0.0448 - val_loss: 1.7494 - val_accuracy: 0.0411
    Epoch 12/50
    313/313 [==============================] - 142s 455ms/step - loss: 1.3529 - accuracy: 0.0461 - val_loss: 1.7565 - val_accuracy: 0.0417
    Epoch 13/50
    138/313 [============>.................] - ETA: 1:03 - loss: 1.3154 - accuracy: 0.0459

## Grayscale - Superclass

### Basic Models - Logistic Regression

We will try out the basic model and see how the accuracy scores are.


```python
# Set our X_train, y_train and X_test, y_test

X_train_flat = Train_flat_data_gray
y_train = np.array(train[b'coarse_labels']) #set coarse/superclass as our classification target

X_test_flat = Test_flat_data_gray
y_test = np.array(test[b'coarse_labels'])
```


```python
from sklearn.linear_model import LogisticRegression

LR = LogisticRegression(random_state=1, n_jobs=-1)
LR.fit(X_train_flat, y_train)
print('Train score: ', LR.score(X_train_flat, y_train))
print('Test score: ', LR.score(X_test_flat, y_test))
```

    Train score:  0.19532
    Test score:  0.1635
    


```python
from sklearn.metrics import confusion_matrix
import seaborn as sns
# Make classifications based on the test features, and assign the classifications to a variable
LR_y_pred = LR.predict(X_test_flat)

# Build the confusion matrix as a dataframe
confusion_df = pd.DataFrame(confusion_matrix(y_test, LR_y_pred))
confusion_df.index = [f'Actually {i}' for i in Superclass_label['Superclass_label']]
confusion_df.columns = [f'Predicted {i}' for i in Superclass_label['Superclass_label']]


plt.figure(figsize = (12,12))
sns.heatmap(confusion_df,
            annot=True,
            cbar=False,
            cmap="rocket_r",
            linewidths=0.5
           )
plt.title('Confusion Matrix',size = 25,y=1.01)
plt.xlabel("Predicted Label", size = 20)
plt.ylabel("True Label", size = 20)
plt.show()
```


    
![png](output_152_0.png)
    


##### GCNN 1 - Model 2


```python
# Set our X_train, y_train and X_test, y_test

X_train = Train_data_gray
y_train = Train_coarse #set coarse/superclass as our classification target

X_test = Test_data_gray
y_test = Test_coarse
```


```python
X_train.shape, y_train.shape, X_test.shape, y_test.shape
```




    ((50000, 32, 32, 1), (50000, 1), (10000, 32, 32, 1), (10000, 1))




```python
GCNN_model2 = Sequential()

# Create simple CNN model architecture with Pooling for dimensionality reduction 
# and Dropout to reduce overfitting
GCNN_model2.add(Conv2D(32, kernel_size=(3, 3), activation = 'relu', input_shape = X_train[0].shape))
GCNN_model2.add(MaxPooling2D(pool_size=(2, 2)))
GCNN_model2.add(Dropout(0.1))

GCNN_model2.add(Conv2D(64, kernel_size=(3, 3), activation = 'relu'))
GCNN_model2.add(MaxPooling2D(pool_size=(2, 2)))
GCNN_model2.add(Dropout(0.2))

GCNN_model2.add(Conv2D(256, kernel_size=(3, 3), activation = 'relu'))
GCNN_model2.add(MaxPooling2D(pool_size=(2, 2)))
GCNN_model2.add(Dropout(0.4))

# Flatten the output of our convolutional layers
GCNN_model2.add(Flatten())

# Add dense layers
GCNN_model2.add(Dense(256, activation= 'relu'))
GCNN_model2.add(Dense(64, activation= 'relu'))
GCNN_model2.add(Dense(32, activation= 'relu'))
GCNN_model2.add(Dense(len(np.unique(y_train)), activation='softmax'))

# Print out a summary of the network
GCNN_model2.summary()

# Compile the model with the desired loss function, optimizer, and metric(s) to track
GCNN_model2.compile(loss = 'sparse_categorical_crossentropy', 
                  optimizer = 'Adam',
                  metrics = ['accuracy'])

# Fit the model on the training data, defining desired batch_size & number of epochs,
# running validation after each batch
GCNN2 = GCNN_model2.fit(X_train, y_train,
                          epochs = 50,
                          verbose = 1,
                          validation_split=0.2,
                            callbacks = ES)



test_loss_score(GCNN_model2)
accuracy_loss_plots(GCNN2)
confusion(GCNN_model2)

save_format='h5'
GCNN_model2.save('CNNmodels/GCNN_model2.h5')
```

    Model: "sequential_15"
    _________________________________________________________________
    Layer (type)                 Output Shape              Param #   
    =================================================================
    conv2d_43 (Conv2D)           (None, 30, 30, 32)        320       
    _________________________________________________________________
    max_pooling2d_37 (MaxPooling (None, 15, 15, 32)        0         
    _________________________________________________________________
    dropout_33 (Dropout)         (None, 15, 15, 32)        0         
    _________________________________________________________________
    conv2d_44 (Conv2D)           (None, 13, 13, 64)        18496     
    _________________________________________________________________
    max_pooling2d_38 (MaxPooling (None, 6, 6, 64)          0         
    _________________________________________________________________
    dropout_34 (Dropout)         (None, 6, 6, 64)          0         
    _________________________________________________________________
    conv2d_45 (Conv2D)           (None, 4, 4, 256)         147712    
    _________________________________________________________________
    max_pooling2d_39 (MaxPooling (None, 2, 2, 256)         0         
    _________________________________________________________________
    dropout_35 (Dropout)         (None, 2, 2, 256)         0         
    _________________________________________________________________
    flatten_13 (Flatten)         (None, 1024)              0         
    _________________________________________________________________
    dense_46 (Dense)             (None, 256)               262400    
    _________________________________________________________________
    dense_47 (Dense)             (None, 64)                16448     
    _________________________________________________________________
    dense_48 (Dense)             (None, 32)                2080      
    _________________________________________________________________
    dense_49 (Dense)             (None, 20)                660       
    =================================================================
    Total params: 448,116
    Trainable params: 448,116
    Non-trainable params: 0
    _________________________________________________________________
    Epoch 1/50
    1250/1250 [==============================] - 20s 16ms/step - loss: 3.0112 - accuracy: 0.0714 - val_loss: 2.9290 - val_accuracy: 0.1002
    Epoch 2/50
    1250/1250 [==============================] - 23s 18ms/step - loss: 2.8173 - accuracy: 0.1391 - val_loss: 2.6854 - val_accuracy: 0.1853
    Epoch 3/50
    1250/1250 [==============================] - 23s 19ms/step - loss: 2.6518 - accuracy: 0.1893 - val_loss: 2.5503 - val_accuracy: 0.2205
    Epoch 4/50
    1250/1250 [==============================] - 21s 17ms/step - loss: 2.5305 - accuracy: 0.2289 - val_loss: 2.4521 - val_accuracy: 0.2680
    Epoch 5/50
    1250/1250 [==============================] - 21s 17ms/step - loss: 2.4286 - accuracy: 0.2574 - val_loss: 2.3657 - val_accuracy: 0.2951
    Epoch 6/50
    1250/1250 [==============================] - 22s 17ms/step - loss: 2.3395 - accuracy: 0.2839 - val_loss: 2.3118 - val_accuracy: 0.2951
    Epoch 7/50
    1250/1250 [==============================] - 21s 17ms/step - loss: 2.2783 - accuracy: 0.2997 - val_loss: 2.2246 - val_accuracy: 0.3281
    Epoch 8/50
    1250/1250 [==============================] - 22s 18ms/step - loss: 2.2312 - accuracy: 0.3160 - val_loss: 2.2325 - val_accuracy: 0.3251
    Epoch 9/50
    1250/1250 [==============================] - 23s 18ms/step - loss: 2.1840 - accuracy: 0.3308 - val_loss: 2.1661 - val_accuracy: 0.3388
    Epoch 10/50
    1250/1250 [==============================] - 23s 19ms/step - loss: 2.1466 - accuracy: 0.3410 - val_loss: 2.1064 - val_accuracy: 0.3615
    Epoch 11/50
    1250/1250 [==============================] - 23s 18ms/step - loss: 2.1124 - accuracy: 0.3504 - val_loss: 2.1151 - val_accuracy: 0.3636
    Epoch 12/50
    1250/1250 [==============================] - 23s 19ms/step - loss: 2.0805 - accuracy: 0.3618 - val_loss: 2.0732 - val_accuracy: 0.3704
    Epoch 13/50
    1250/1250 [==============================] - 23s 19ms/step - loss: 2.0545 - accuracy: 0.3712 - val_loss: 2.0604 - val_accuracy: 0.3795
    Epoch 14/50
    1250/1250 [==============================] - 23s 19ms/step - loss: 2.0301 - accuracy: 0.3776 - val_loss: 2.0768 - val_accuracy: 0.3632
    Epoch 15/50
    1250/1250 [==============================] - 23s 18ms/step - loss: 2.0065 - accuracy: 0.3877 - val_loss: 2.0115 - val_accuracy: 0.3870
    Epoch 16/50
    1250/1250 [==============================] - 23s 19ms/step - loss: 1.9812 - accuracy: 0.3905 - val_loss: 1.9925 - val_accuracy: 0.3963
    Epoch 17/50
    1250/1250 [==============================] - 23s 18ms/step - loss: 1.9659 - accuracy: 0.3984 - val_loss: 2.0322 - val_accuracy: 0.3860
    Epoch 18/50
    1250/1250 [==============================] - 23s 18ms/step - loss: 1.9433 - accuracy: 0.4052 - val_loss: 1.9737 - val_accuracy: 0.4007
    Epoch 19/50
    1250/1250 [==============================] - 25s 20ms/step - loss: 1.9168 - accuracy: 0.4117 - val_loss: 2.0243 - val_accuracy: 0.3874
    Epoch 20/50
    1250/1250 [==============================] - 24s 19ms/step - loss: 1.9053 - accuracy: 0.4150 - val_loss: 1.9438 - val_accuracy: 0.4126
    Epoch 21/50
    1250/1250 [==============================] - 23s 18ms/step - loss: 1.8914 - accuracy: 0.4204 - val_loss: 1.9247 - val_accuracy: 0.4178
    Epoch 22/50
    1250/1250 [==============================] - 24s 19ms/step - loss: 1.8682 - accuracy: 0.4254 - val_loss: 1.9304 - val_accuracy: 0.4174
    Epoch 23/50
    1250/1250 [==============================] - 24s 19ms/step - loss: 1.8464 - accuracy: 0.4322 - val_loss: 1.9530 - val_accuracy: 0.4120
    Epoch 24/50
    1250/1250 [==============================] - 24s 19ms/step - loss: 1.8347 - accuracy: 0.4379 - val_loss: 1.9503 - val_accuracy: 0.4149
    Epoch 25/50
    1250/1250 [==============================] - 23s 19ms/step - loss: 1.8124 - accuracy: 0.4430 - val_loss: 1.9541 - val_accuracy: 0.4119
    Epoch 26/50
    1250/1250 [==============================] - 24s 20ms/step - loss: 1.8090 - accuracy: 0.4441 - val_loss: 1.9671 - val_accuracy: 0.4116
    Epoch 00026: early stopping
    Test loss: 1.9598146677017212
    Test accuracy: 0.4124000072479248
    
     
    
    


    
![png](output_156_1.png)
    



    
![png](output_156_2.png)
    


##### GCNN 1 - Model 4


```python

GCNN_model4 = Sequential()

# Create simple CNN model architecture with Pooling for dimensionality reduction 
# and Dropout to reduce overfitting
GCNN_model4.add(Conv2D(128, kernel_size=(3, 3), activation = 'relu',input_shape = X_train[0].shape))
GCNN_model4.add(MaxPooling2D(pool_size=(2, 2)))
GCNN_model4.add(Dropout(0.1))

GCNN_model4.add(Conv2D(256, kernel_size=(3, 3), activation = 'relu'))
GCNN_model4.add(MaxPooling2D(pool_size=(2, 2)))
GCNN_model4.add(Dropout(0.2))

GCNN_model4.add(Conv2D(512, kernel_size=(3, 3), activation = 'relu'))
GCNN_model4.add(MaxPooling2D(pool_size=(2, 2)))
GCNN_model4.add(Dropout(0.4))

# Flatten the output of our convolutional layers
GCNN_model4.add(Flatten())

# Add dense layers
GCNN_model4.add(Dense(512, activation= 'relu'))
GCNN_model4.add(Dense(256, activation= 'relu'))
GCNN_model4.add(Dense(128, activation= 'relu'))
GCNN_model4.add(Dense(len(np.unique(y_train)), activation='softmax'))

# Print out a summary of the network
GCNN_model4.summary()

# Compile the model with the desired loss function, optimizer, and metric(s) to track
GCNN_model4.compile(loss = 'sparse_categorical_crossentropy', 
                  optimizer = 'Adam',
                  metrics = ['accuracy'])

# Fit the model on the training data, defining desired batch_size & number of epochs,
# running validation after each batch
GCNN4 = GCNN_model4.fit(X_train, y_train,
                          epochs = 50,
                          verbose = 1,
                          validation_split=0.2,
                            callbacks = ES)


test_loss_score(GCNN_model4)
accuracy_loss_plots(GCNN4)
confusion(GCNN_model4)

save_format='h5'
GCNN_model4.save('CNNmodels/GCNN_model4.h5')
```

    Model: "sequential_16"
    _________________________________________________________________
    Layer (type)                 Output Shape              Param #   
    =================================================================
    conv2d_46 (Conv2D)           (None, 30, 30, 128)       1280      
    _________________________________________________________________
    max_pooling2d_40 (MaxPooling (None, 15, 15, 128)       0         
    _________________________________________________________________
    dropout_36 (Dropout)         (None, 15, 15, 128)       0         
    _________________________________________________________________
    conv2d_47 (Conv2D)           (None, 13, 13, 256)       295168    
    _________________________________________________________________
    max_pooling2d_41 (MaxPooling (None, 6, 6, 256)         0         
    _________________________________________________________________
    dropout_37 (Dropout)         (None, 6, 6, 256)         0         
    _________________________________________________________________
    conv2d_48 (Conv2D)           (None, 4, 4, 512)         1180160   
    _________________________________________________________________
    max_pooling2d_42 (MaxPooling (None, 2, 2, 512)         0         
    _________________________________________________________________
    dropout_38 (Dropout)         (None, 2, 2, 512)         0         
    _________________________________________________________________
    flatten_14 (Flatten)         (None, 2048)              0         
    _________________________________________________________________
    dense_50 (Dense)             (None, 512)               1049088   
    _________________________________________________________________
    dense_51 (Dense)             (None, 256)               131328    
    _________________________________________________________________
    dense_52 (Dense)             (None, 128)               32896     
    _________________________________________________________________
    dense_53 (Dense)             (None, 20)                2580      
    =================================================================
    Total params: 2,692,500
    Trainable params: 2,692,500
    Non-trainable params: 0
    _________________________________________________________________
    Epoch 1/50
    1250/1250 [==============================] - 157s 126ms/step - loss: 2.9839 - accuracy: 0.1008 - val_loss: 2.8046 - val_accuracy: 0.1410
    Epoch 2/50
    1250/1250 [==============================] - 153s 123ms/step - loss: 2.7661 - accuracy: 0.1578 - val_loss: 2.6267 - val_accuracy: 0.2047
    Epoch 3/50
    1250/1250 [==============================] - 155s 124ms/step - loss: 2.5552 - accuracy: 0.2211 - val_loss: 2.5186 - val_accuracy: 0.2397
    Epoch 4/50
    1250/1250 [==============================] - 156s 125ms/step - loss: 2.4099 - accuracy: 0.2618 - val_loss: 2.3868 - val_accuracy: 0.2774
    Epoch 5/50
    1250/1250 [==============================] - 154s 123ms/step - loss: 2.3133 - accuracy: 0.2926 - val_loss: 2.2672 - val_accuracy: 0.3139
    Epoch 6/50
    1250/1250 [==============================] - 158s 126ms/step - loss: 2.2280 - accuracy: 0.3178 - val_loss: 2.2041 - val_accuracy: 0.3336
    Epoch 7/50
    1250/1250 [==============================] - 162s 130ms/step - loss: 2.1573 - accuracy: 0.3388 - val_loss: 2.2190 - val_accuracy: 0.3280
    Epoch 8/50
    1250/1250 [==============================] - 153s 122ms/step - loss: 2.1028 - accuracy: 0.3558 - val_loss: 2.1340 - val_accuracy: 0.3596
    Epoch 9/50
    1250/1250 [==============================] - 155s 124ms/step - loss: 2.0515 - accuracy: 0.3738 - val_loss: 2.0824 - val_accuracy: 0.3741
    Epoch 10/50
    1250/1250 [==============================] - 155s 124ms/step - loss: 2.0180 - accuracy: 0.3817 - val_loss: 2.0772 - val_accuracy: 0.3758
    Epoch 11/50
    1250/1250 [==============================] - 149s 119ms/step - loss: 1.9690 - accuracy: 0.3992 - val_loss: 2.0534 - val_accuracy: 0.3843
    Epoch 12/50
    1250/1250 [==============================] - 149s 119ms/step - loss: 1.9312 - accuracy: 0.4104 - val_loss: 2.0479 - val_accuracy: 0.3835
    Epoch 13/50
    1250/1250 [==============================] - 149s 119ms/step - loss: 1.8992 - accuracy: 0.4188 - val_loss: 1.9876 - val_accuracy: 0.3974
    Epoch 14/50
    1250/1250 [==============================] - 155s 124ms/step - loss: 1.8722 - accuracy: 0.4279 - val_loss: 1.9912 - val_accuracy: 0.4050
    Epoch 15/50
    1250/1250 [==============================] - 156s 125ms/step - loss: 1.8302 - accuracy: 0.4401 - val_loss: 1.9355 - val_accuracy: 0.4187
    Epoch 16/50
    1250/1250 [==============================] - 156s 124ms/step - loss: 1.8002 - accuracy: 0.4509 - val_loss: 1.9383 - val_accuracy: 0.4127
    Epoch 17/50
    1250/1250 [==============================] - 155s 124ms/step - loss: 1.7692 - accuracy: 0.4631 - val_loss: 2.0340 - val_accuracy: 0.3953
    Epoch 18/50
    1250/1250 [==============================] - 156s 125ms/step - loss: 1.7402 - accuracy: 0.4679 - val_loss: 1.9727 - val_accuracy: 0.4178
    Epoch 19/50
    1250/1250 [==============================] - 158s 127ms/step - loss: 1.7197 - accuracy: 0.4732 - val_loss: 1.9672 - val_accuracy: 0.4143
    Epoch 20/50
    1250/1250 [==============================] - 154s 123ms/step - loss: 1.7010 - accuracy: 0.4836 - val_loss: 1.9187 - val_accuracy: 0.4232
    Epoch 21/50
    1250/1250 [==============================] - 153s 122ms/step - loss: 1.6688 - accuracy: 0.4921 - val_loss: 1.9424 - val_accuracy: 0.4245
    Epoch 22/50
    1250/1250 [==============================] - 153s 123ms/step - loss: 1.6459 - accuracy: 0.4978 - val_loss: 1.9236 - val_accuracy: 0.4286
    Epoch 23/50
    1250/1250 [==============================] - 153s 123ms/step - loss: 1.6265 - accuracy: 0.5037 - val_loss: 1.9114 - val_accuracy: 0.4317
    Epoch 24/50
    1250/1250 [==============================] - 153s 122ms/step - loss: 1.6064 - accuracy: 0.5114 - val_loss: 1.8984 - val_accuracy: 0.4340
    Epoch 25/50
    1250/1250 [==============================] - 153s 122ms/step - loss: 1.5745 - accuracy: 0.5226 - val_loss: 1.9041 - val_accuracy: 0.4362
    Epoch 26/50
    1250/1250 [==============================] - 151s 121ms/step - loss: 1.5524 - accuracy: 0.5266 - val_loss: 1.9294 - val_accuracy: 0.4227
    Epoch 27/50
    1250/1250 [==============================] - 152s 122ms/step - loss: 1.5317 - accuracy: 0.5344 - val_loss: 1.9193 - val_accuracy: 0.4378
    Epoch 28/50
    1250/1250 [==============================] - 152s 122ms/step - loss: 1.4956 - accuracy: 0.5463 - val_loss: 1.9353 - val_accuracy: 0.4301
    Epoch 29/50
    1250/1250 [==============================] - 151s 121ms/step - loss: 1.5059 - accuracy: 0.5428 - val_loss: 1.8752 - val_accuracy: 0.4398
    Epoch 30/50
    1250/1250 [==============================] - 151s 121ms/step - loss: 1.4681 - accuracy: 0.5537 - val_loss: 1.9621 - val_accuracy: 0.4222
    Epoch 31/50
    1250/1250 [==============================] - 151s 121ms/step - loss: 1.4479 - accuracy: 0.5601 - val_loss: 1.8981 - val_accuracy: 0.4517
    Epoch 32/50
    1250/1250 [==============================] - 152s 121ms/step - loss: 1.4267 - accuracy: 0.5678 - val_loss: 1.8982 - val_accuracy: 0.4482
    Epoch 33/50
    1250/1250 [==============================] - 151s 121ms/step - loss: 1.4192 - accuracy: 0.5689 - val_loss: 1.9043 - val_accuracy: 0.4501
    Epoch 34/50
    1250/1250 [==============================] - 148s 118ms/step - loss: 1.3903 - accuracy: 0.5802 - val_loss: 1.9520 - val_accuracy: 0.4358
    Epoch 35/50
    1250/1250 [==============================] - 146s 117ms/step - loss: 1.3892 - accuracy: 0.5823 - val_loss: 1.9294 - val_accuracy: 0.4513
    Epoch 36/50
    1250/1250 [==============================] - 145s 116ms/step - loss: 1.3519 - accuracy: 0.5901 - val_loss: 1.9231 - val_accuracy: 0.4416
    Epoch 00036: early stopping
    Test loss: 1.9213827848434448
    Test accuracy: 0.44110000133514404
    
     
    
    


    
![png](output_158_1.png)
    



    
![png](output_158_2.png)
    


https://arxiv.org/pdf/1511.07289.pdf

##### GCNN 2 - Model 5


```python

GCNN_model5 = Sequential()

# Create simple CNN model architecture with Pooling for dimensionality reduction 
# and Dropout to reduce overfitting
GCNN_model5.add(Conv2D(192, kernel_size=(5, 5), activation = 'elu', input_shape = X_train[0].shape, kernel_regularizer=l2(0.0005))) 
GCNN_model5.add(MaxPooling2D(pool_size=(2, 2), padding='same'))
GCNN_model5.add(Dropout(0.0))

GCNN_model5.add(Conv2D(192, kernel_size=(1, 1), activation = 'elu', padding='same', kernel_regularizer=l2(0.0005)))
GCNN_model5.add(Conv2D(240, kernel_size=(3, 3), activation = 'elu', padding='same', kernel_regularizer=l2(0.0005)))
GCNN_model5.add(MaxPooling2D(pool_size=(2, 2), padding='same'))
GCNN_model5.add(Dropout(0.1))

GCNN_model5.add(Conv2D(240, kernel_size=(1,1), activation = 'elu', padding='same', kernel_regularizer=l2(0.0005)))
GCNN_model5.add(Conv2D(260, kernel_size=(2,2), activation = 'elu', padding='same', kernel_regularizer=l2(0.0005)))
GCNN_model5.add(MaxPooling2D(pool_size=(2, 2), padding='same'))
GCNN_model5.add(Dropout(0.2))

GCNN_model5.add(Conv2D(260, kernel_size=(1,1), activation = 'elu', padding='same', kernel_regularizer=l2(0.0005)))
GCNN_model5.add(Conv2D(280, kernel_size=(2,2), activation = 'elu', padding='same', kernel_regularizer=l2(0.0005)))
GCNN_model5.add(MaxPooling2D(pool_size=(2, 2), padding='same'))
GCNN_model5.add(Dropout(0.3))

GCNN_model5.add(Conv2D(280, kernel_size=(1,1), activation = 'elu', padding='same', kernel_regularizer=l2(0.0005)))
GCNN_model5.add(Conv2D(300, kernel_size=(2,2), activation = 'elu', padding='same', kernel_regularizer=l2(0.0005)))
GCNN_model5.add(MaxPooling2D(pool_size=(2, 2), padding='same'))
GCNN_model5.add(Dropout(0.4))

GCNN_model5.add(Conv2D(300, kernel_size=(2,2), activation = 'elu', padding='same', kernel_regularizer=l2(0.0005)))
GCNN_model5.add(MaxPooling2D(pool_size=(2, 2), padding='same'))
GCNN_model5.add(Dropout(0.5))

# Flatten the output of our convolutional layers
GCNN_model5.add(Flatten())

# Add dense layers
GCNN_model5.add(Dense(len(np.unique(y_train)), activation='softmax'))

# Print out a summary of the network
GCNN_model5.summary()

# Compile the model with the desired loss function, optimizer, and metric(s) to track
GCNN_model5.compile(loss = 'sparse_categorical_crossentropy', #cross entropy is for multi-class classification
                  optimizer = 'Adam',
                  metrics = ['accuracy'])

# Fit the model on the training data, defining desired batch_size & number of epochs,
# running validation after each batch
GCNN5 = GCNN_model5.fit(X_train, y_train,
                          epochs = 100,
                          verbose = 1,
                          validation_split = 0.2,
                            callbacks = ES)
test_loss_score(GCNN_model5)
accuracy_loss_plots(GCNN5)
confusion(GCNN_model5)

save_format='h5'
GCNN_model5.save('CNNmodels/GCNN_model5.h5')
```

    Model: "sequential_23"
    _________________________________________________________________
    Layer (type)                 Output Shape              Param #   
    =================================================================
    conv2d_94 (Conv2D)           (None, 28, 28, 192)       4992      
    _________________________________________________________________
    max_pooling2d_69 (MaxPooling (None, 14, 14, 192)       0         
    _________________________________________________________________
    dropout_60 (Dropout)         (None, 14, 14, 192)       0         
    _________________________________________________________________
    conv2d_95 (Conv2D)           (None, 14, 14, 192)       37056     
    _________________________________________________________________
    conv2d_96 (Conv2D)           (None, 14, 14, 240)       414960    
    _________________________________________________________________
    max_pooling2d_70 (MaxPooling (None, 7, 7, 240)         0         
    _________________________________________________________________
    dropout_61 (Dropout)         (None, 7, 7, 240)         0         
    _________________________________________________________________
    conv2d_97 (Conv2D)           (None, 7, 7, 240)         57840     
    _________________________________________________________________
    conv2d_98 (Conv2D)           (None, 7, 7, 260)         249860    
    _________________________________________________________________
    max_pooling2d_71 (MaxPooling (None, 4, 4, 260)         0         
    _________________________________________________________________
    dropout_62 (Dropout)         (None, 4, 4, 260)         0         
    _________________________________________________________________
    conv2d_99 (Conv2D)           (None, 4, 4, 260)         67860     
    _________________________________________________________________
    conv2d_100 (Conv2D)          (None, 4, 4, 280)         291480    
    _________________________________________________________________
    max_pooling2d_72 (MaxPooling (None, 2, 2, 280)         0         
    _________________________________________________________________
    dropout_63 (Dropout)         (None, 2, 2, 280)         0         
    _________________________________________________________________
    conv2d_101 (Conv2D)          (None, 2, 2, 280)         78680     
    _________________________________________________________________
    conv2d_102 (Conv2D)          (None, 2, 2, 300)         336300    
    _________________________________________________________________
    max_pooling2d_73 (MaxPooling (None, 1, 1, 300)         0         
    _________________________________________________________________
    dropout_64 (Dropout)         (None, 1, 1, 300)         0         
    _________________________________________________________________
    conv2d_103 (Conv2D)          (None, 1, 1, 300)         360300    
    _________________________________________________________________
    max_pooling2d_74 (MaxPooling (None, 1, 1, 300)         0         
    _________________________________________________________________
    dropout_65 (Dropout)         (None, 1, 1, 300)         0         
    _________________________________________________________________
    flatten_21 (Flatten)         (None, 300)               0         
    _________________________________________________________________
    dense_70 (Dense)             (None, 20)                6020      
    =================================================================
    Total params: 1,905,348
    Trainable params: 1,905,348
    Non-trainable params: 0
    _________________________________________________________________
    Epoch 1/100
    1250/1250 [==============================] - 210s 168ms/step - loss: 3.7320 - accuracy: 0.0696 - val_loss: 3.3296 - val_accuracy: 0.0945
    Epoch 2/100
    1250/1250 [==============================] - 208s 167ms/step - loss: 3.1848 - accuracy: 0.1112 - val_loss: 3.0089 - val_accuracy: 0.1410
    Epoch 3/100
    1250/1250 [==============================] - 214s 171ms/step - loss: 2.9958 - accuracy: 0.1379 - val_loss: 2.9325 - val_accuracy: 0.1531
    Epoch 4/100
    1250/1250 [==============================] - 208s 166ms/step - loss: 2.9391 - accuracy: 0.1621 - val_loss: 2.9276 - val_accuracy: 0.1854
    Epoch 5/100
    1250/1250 [==============================] - 207s 166ms/step - loss: 2.9135 - accuracy: 0.1829 - val_loss: 2.8625 - val_accuracy: 0.1951
    Epoch 6/100
    1250/1250 [==============================] - 211s 169ms/step - loss: 2.8897 - accuracy: 0.1992 - val_loss: 2.8497 - val_accuracy: 0.2147
    Epoch 7/100
    1250/1250 [==============================] - 244s 195ms/step - loss: 2.8723 - accuracy: 0.2155 - val_loss: 2.7329 - val_accuracy: 0.2579
    Epoch 8/100
    1250/1250 [==============================] - 220s 176ms/step - loss: 2.8495 - accuracy: 0.2275 - val_loss: 2.7369 - val_accuracy: 0.2611
    Epoch 9/100
    1250/1250 [==============================] - 225s 180ms/step - loss: 2.8466 - accuracy: 0.2361 - val_loss: 2.7326 - val_accuracy: 0.2719
    Epoch 10/100
    1250/1250 [==============================] - 223s 178ms/step - loss: 2.8297 - accuracy: 0.2469 - val_loss: 2.6376 - val_accuracy: 0.3063
    Epoch 11/100
    1250/1250 [==============================] - 221s 177ms/step - loss: 2.8280 - accuracy: 0.2552 - val_loss: 2.8233 - val_accuracy: 0.2473
    Epoch 12/100
    1250/1250 [==============================] - 211s 169ms/step - loss: 2.8170 - accuracy: 0.2597 - val_loss: 2.6854 - val_accuracy: 0.2974
    Epoch 13/100
    1250/1250 [==============================] - 211s 169ms/step - loss: 2.8194 - accuracy: 0.2654 - val_loss: 2.7368 - val_accuracy: 0.2943
    Epoch 14/100
    1250/1250 [==============================] - 211s 169ms/step - loss: 2.8050 - accuracy: 0.2726 - val_loss: 2.6539 - val_accuracy: 0.3147
    Epoch 15/100
    1250/1250 [==============================] - 211s 169ms/step - loss: 2.8034 - accuracy: 0.2799 - val_loss: 2.7515 - val_accuracy: 0.3028
    Epoch 16/100
    1250/1250 [==============================] - 212s 170ms/step - loss: 2.7964 - accuracy: 0.2836 - val_loss: 2.6700 - val_accuracy: 0.3093
    Epoch 17/100
    1250/1250 [==============================] - 211s 169ms/step - loss: 2.7922 - accuracy: 0.2862 - val_loss: 2.7312 - val_accuracy: 0.3025
    Epoch 18/100
    1250/1250 [==============================] - 216s 173ms/step - loss: 2.7840 - accuracy: 0.2910 - val_loss: 2.6146 - val_accuracy: 0.3371
    Epoch 19/100
    1250/1250 [==============================] - 211s 169ms/step - loss: 2.7831 - accuracy: 0.2951 - val_loss: 2.7266 - val_accuracy: 0.3106
    Epoch 20/100
    1250/1250 [==============================] - 211s 169ms/step - loss: 2.7735 - accuracy: 0.3027 - val_loss: 2.6324 - val_accuracy: 0.3393
    Epoch 21/100
    1250/1250 [==============================] - 211s 169ms/step - loss: 2.7700 - accuracy: 0.3036 - val_loss: 2.6471 - val_accuracy: 0.3337
    Epoch 22/100
    1250/1250 [==============================] - 211s 169ms/step - loss: 2.7726 - accuracy: 0.3080 - val_loss: 2.6452 - val_accuracy: 0.3450
    Epoch 23/100
    1250/1250 [==============================] - 211s 169ms/step - loss: 2.7693 - accuracy: 0.3067 - val_loss: 2.6215 - val_accuracy: 0.3488
    Epoch 24/100
    1250/1250 [==============================] - 214s 171ms/step - loss: 2.7585 - accuracy: 0.3133 - val_loss: 2.6421 - val_accuracy: 0.3462
    Epoch 25/100
    1250/1250 [==============================] - 214s 171ms/step - loss: 2.7511 - accuracy: 0.3180 - val_loss: 2.6090 - val_accuracy: 0.3576
    Epoch 26/100
    1250/1250 [==============================] - 214s 171ms/step - loss: 2.7535 - accuracy: 0.3185 - val_loss: 2.7783 - val_accuracy: 0.3156
    Epoch 27/100
    1250/1250 [==============================] - 215s 172ms/step - loss: 2.7385 - accuracy: 0.3217 - val_loss: 2.5669 - val_accuracy: 0.3693
    Epoch 28/100
    1250/1250 [==============================] - 214s 172ms/step - loss: 2.7351 - accuracy: 0.3270 - val_loss: 2.5833 - val_accuracy: 0.3686
    Epoch 29/100
    1250/1250 [==============================] - 214s 171ms/step - loss: 2.7356 - accuracy: 0.3330 - val_loss: 2.6208 - val_accuracy: 0.3679
    Epoch 30/100
    1250/1250 [==============================] - 223s 178ms/step - loss: 2.7412 - accuracy: 0.3289 - val_loss: 2.6055 - val_accuracy: 0.3638
    Epoch 31/100
    1250/1250 [==============================] - 223s 178ms/step - loss: 2.7344 - accuracy: 0.3360 - val_loss: 2.5878 - val_accuracy: 0.3671
    Epoch 32/100
    1250/1250 [==============================] - 227s 182ms/step - loss: 2.7222 - accuracy: 0.3377 - val_loss: 2.5993 - val_accuracy: 0.3774
    Epoch 33/100
    1250/1250 [==============================] - 219s 176ms/step - loss: 2.7198 - accuracy: 0.3396 - val_loss: 2.6210 - val_accuracy: 0.3664
    Epoch 34/100
    1250/1250 [==============================] - 220s 176ms/step - loss: 2.7170 - accuracy: 0.3388 - val_loss: 2.7257 - val_accuracy: 0.3374
    Epoch 35/100
    1250/1250 [==============================] - 222s 178ms/step - loss: 2.7133 - accuracy: 0.3471 - val_loss: 2.5329 - val_accuracy: 0.3984
    Epoch 36/100
    1250/1250 [==============================] - 230s 184ms/step - loss: 2.7145 - accuracy: 0.3475 - val_loss: 2.7181 - val_accuracy: 0.3552
    Epoch 37/100
    1250/1250 [==============================] - 218s 174ms/step - loss: 2.7068 - accuracy: 0.3520 - val_loss: 2.5754 - val_accuracy: 0.3852
    Epoch 38/100
    1250/1250 [==============================] - 208s 166ms/step - loss: 2.7054 - accuracy: 0.3514 - val_loss: 2.5646 - val_accuracy: 0.3837
    Epoch 39/100
    1250/1250 [==============================] - 205s 164ms/step - loss: 2.7116 - accuracy: 0.3541 - val_loss: 2.5798 - val_accuracy: 0.3859
    Epoch 40/100
    1250/1250 [==============================] - 203s 162ms/step - loss: 2.7112 - accuracy: 0.3535 - val_loss: 2.5361 - val_accuracy: 0.3986
    Epoch 41/100
    1250/1250 [==============================] - 203s 163ms/step - loss: 2.7096 - accuracy: 0.3546 - val_loss: 2.5984 - val_accuracy: 0.3868
    Epoch 42/100
    1250/1250 [==============================] - 204s 163ms/step - loss: 2.7073 - accuracy: 0.3605 - val_loss: 2.5685 - val_accuracy: 0.4001
    Epoch 43/100
    1250/1250 [==============================] - 209s 167ms/step - loss: 2.7032 - accuracy: 0.3618 - val_loss: 2.5858 - val_accuracy: 0.3946
    Epoch 44/100
    1250/1250 [==============================] - 207s 166ms/step - loss: 2.7028 - accuracy: 0.3629 - val_loss: 2.5477 - val_accuracy: 0.4032
    Epoch 45/100
    1250/1250 [==============================] - 208s 167ms/step - loss: 2.6874 - accuracy: 0.3664 - val_loss: 2.5836 - val_accuracy: 0.3938
    Epoch 46/100
    1250/1250 [==============================] - 208s 166ms/step - loss: 2.6899 - accuracy: 0.3708 - val_loss: 2.6769 - val_accuracy: 0.3705
    Epoch 47/100
    1250/1250 [==============================] - 207s 166ms/step - loss: 2.6901 - accuracy: 0.3687 - val_loss: 2.6432 - val_accuracy: 0.3780
    Epoch 48/100
    1250/1250 [==============================] - 208s 167ms/step - loss: 2.6920 - accuracy: 0.3702 - val_loss: 2.5558 - val_accuracy: 0.4033
    Epoch 49/100
    1250/1250 [==============================] - 207s 165ms/step - loss: 2.6927 - accuracy: 0.3771 - val_loss: 2.5511 - val_accuracy: 0.4182
    Epoch 50/100
    1250/1250 [==============================] - 206s 165ms/step - loss: 2.6835 - accuracy: 0.3773 - val_loss: 2.5555 - val_accuracy: 0.4057
    Epoch 51/100
    1250/1250 [==============================] - 206s 165ms/step - loss: 2.6831 - accuracy: 0.3765 - val_loss: 2.6751 - val_accuracy: 0.3689
    Epoch 52/100
    1250/1250 [==============================] - 206s 165ms/step - loss: 2.6754 - accuracy: 0.3816 - val_loss: 2.5735 - val_accuracy: 0.4046
    Epoch 53/100
    1250/1250 [==============================] - 206s 164ms/step - loss: 2.6824 - accuracy: 0.3781 - val_loss: 2.5487 - val_accuracy: 0.4127
    Epoch 54/100
    1250/1250 [==============================] - 206s 165ms/step - loss: 2.6816 - accuracy: 0.3806 - val_loss: 2.6713 - val_accuracy: 0.3830
    Epoch 00054: early stopping
    Test loss: 2.6437888145446777
    Test accuracy: 0.38850000500679016
    
     
    
    


    
![png](output_161_1.png)
    



    
![png](output_161_2.png)
    


##### GCNN 2 - Model 6


```python
GCNN_model6 = Sequential()

# Create simple CNN model architecture with Pooling for dimensionality reduction 
# and Dropout to reduce overfitting
GCNN_model6.add(Conv2D(32, kernel_size=(3,3), activation = 'elu', input_shape = X_train[0].shape, kernel_regularizer=l2(0.0005))) 
GCNN_model6.add(MaxPooling2D(pool_size=(2, 2), padding='same'))

GCNN_model6.add(Conv2D(64, kernel_size=(3,3), activation = 'elu', padding='same', kernel_regularizer=l2(0.0005)))
GCNN_model6.add(Conv2D(128, kernel_size=(3,3), activation = 'elu', padding='same', kernel_regularizer=l2(0.0005)))
GCNN_model6.add(MaxPooling2D(pool_size=(2, 2), padding='same'))
GCNN_model6.add(Dropout(0.1))

GCNN_model6.add(Conv2D(128, kernel_size=(2,2), activation = 'elu', padding='same', kernel_regularizer=l2(0.0005)))
GCNN_model6.add(Conv2D(256, kernel_size=(2,2), activation = 'elu', padding='same', kernel_regularizer=l2(0.0005)))
GCNN_model6.add(MaxPooling2D(pool_size=(2, 2), padding='same'))
GCNN_model6.add(Dropout(0.2))

GCNN_model6.add(Conv2D(256, kernel_size=(1,1), activation = 'elu', padding='same', kernel_regularizer=l2(0.0005)))
GCNN_model6.add(Conv2D(512, kernel_size=(1,1), activation = 'elu', padding='same', kernel_regularizer=l2(0.0005)))
GCNN_model6.add(MaxPooling2D(pool_size=(2, 2), padding='same'))
GCNN_model6.add(Dropout(0.3))

# Flatten the output of our convolutional layers
GCNN_model6.add(Flatten())

# Add dense layers
GCNN_model6.add(Dense(512, activation = 'elu'))
GCNN_model6.add(Dense(256, activation = 'elu'))
GCNN_model6.add(Dense(len(np.unique(y_train)), activation='softmax'))

# Print out a summary of the network
GCNN_model6.summary()

# Compile the model with the desired loss function, optimizer, and metric(s) to track
GCNN_model6.compile(loss = 'sparse_categorical_crossentropy', #cross entropy is for multi-class classification
                  optimizer = 'Adam',
                  metrics = ['accuracy'])

# Fit the model on the training data, defining desired batch_size & number of epochs,
# running validation after each batch
GCNN6 = GCNN_model6.fit(X_train, y_train,
                          epochs = 100,
                          verbose = 1,
                          validation_split=0.2,
                            callbacks = ES)


test_loss_score(GCNN_model6)
accuracy_loss_plots(GCNN6)
confusion(GCNN_model6)

GCNN_model6.save('CNNmodels/GCNN_model6.h5')
```

    Model: "sequential_22"
    _________________________________________________________________
    Layer (type)                 Output Shape              Param #   
    =================================================================
    conv2d_87 (Conv2D)           (None, 30, 30, 32)        320       
    _________________________________________________________________
    max_pooling2d_65 (MaxPooling (None, 15, 15, 32)        0         
    _________________________________________________________________
    conv2d_88 (Conv2D)           (None, 15, 15, 64)        18496     
    _________________________________________________________________
    conv2d_89 (Conv2D)           (None, 15, 15, 128)       73856     
    _________________________________________________________________
    max_pooling2d_66 (MaxPooling (None, 8, 8, 128)         0         
    _________________________________________________________________
    dropout_57 (Dropout)         (None, 8, 8, 128)         0         
    _________________________________________________________________
    conv2d_90 (Conv2D)           (None, 8, 8, 128)         65664     
    _________________________________________________________________
    conv2d_91 (Conv2D)           (None, 8, 8, 256)         131328    
    _________________________________________________________________
    max_pooling2d_67 (MaxPooling (None, 4, 4, 256)         0         
    _________________________________________________________________
    dropout_58 (Dropout)         (None, 4, 4, 256)         0         
    _________________________________________________________________
    conv2d_92 (Conv2D)           (None, 4, 4, 256)         65792     
    _________________________________________________________________
    conv2d_93 (Conv2D)           (None, 4, 4, 512)         131584    
    _________________________________________________________________
    max_pooling2d_68 (MaxPooling (None, 2, 2, 512)         0         
    _________________________________________________________________
    dropout_59 (Dropout)         (None, 2, 2, 512)         0         
    _________________________________________________________________
    flatten_20 (Flatten)         (None, 2048)              0         
    _________________________________________________________________
    dense_67 (Dense)             (None, 512)               1049088   
    _________________________________________________________________
    dense_68 (Dense)             (None, 256)               131328    
    _________________________________________________________________
    dense_69 (Dense)             (None, 20)                5140      
    =================================================================
    Total params: 1,672,596
    Trainable params: 1,672,596
    Non-trainable params: 0
    _________________________________________________________________
    Epoch 1/100
    1250/1250 [==============================] - 79s 63ms/step - loss: 3.1718 - accuracy: 0.1620 - val_loss: 2.7570 - val_accuracy: 0.2479
    Epoch 2/100
    1250/1250 [==============================] - 81s 65ms/step - loss: 2.6500 - accuracy: 0.2673 - val_loss: 2.6145 - val_accuracy: 0.2655
    Epoch 3/100
    1250/1250 [==============================] - 80s 64ms/step - loss: 2.4335 - accuracy: 0.3221 - val_loss: 2.3289 - val_accuracy: 0.3523
    Epoch 4/100
    1250/1250 [==============================] - 80s 64ms/step - loss: 2.3249 - accuracy: 0.3586 - val_loss: 2.2297 - val_accuracy: 0.3873
    Epoch 5/100
    1250/1250 [==============================] - 81s 64ms/step - loss: 2.2512 - accuracy: 0.3913 - val_loss: 2.2238 - val_accuracy: 0.4045
    Epoch 6/100
    1250/1250 [==============================] - 80s 64ms/step - loss: 2.1872 - accuracy: 0.4171 - val_loss: 2.1690 - val_accuracy: 0.4320
    Epoch 7/100
    1250/1250 [==============================] - 80s 64ms/step - loss: 2.1435 - accuracy: 0.4386 - val_loss: 2.2055 - val_accuracy: 0.4380
    Epoch 8/100
    1250/1250 [==============================] - 80s 64ms/step - loss: 2.1125 - accuracy: 0.4551 - val_loss: 2.1647 - val_accuracy: 0.4466
    Epoch 9/100
    1250/1250 [==============================] - 81s 64ms/step - loss: 2.0923 - accuracy: 0.4677 - val_loss: 2.1347 - val_accuracy: 0.4562
    Epoch 10/100
    1250/1250 [==============================] - 81s 65ms/step - loss: 2.0633 - accuracy: 0.4794 - val_loss: 2.2313 - val_accuracy: 0.4366
    Epoch 11/100
    1250/1250 [==============================] - 81s 65ms/step - loss: 2.0498 - accuracy: 0.4902 - val_loss: 2.2323 - val_accuracy: 0.4513
    Epoch 12/100
    1250/1250 [==============================] - 80s 64ms/step - loss: 2.0255 - accuracy: 0.5038 - val_loss: 2.2446 - val_accuracy: 0.4494
    Epoch 13/100
    1250/1250 [==============================] - 81s 65ms/step - loss: 2.0129 - accuracy: 0.5082 - val_loss: 2.1112 - val_accuracy: 0.4926
    Epoch 14/100
    1250/1250 [==============================] - 81s 65ms/step - loss: 2.0049 - accuracy: 0.5138 - val_loss: 2.2055 - val_accuracy: 0.4677
    Epoch 15/100
    1250/1250 [==============================] - 81s 64ms/step - loss: 1.9856 - accuracy: 0.5239 - val_loss: 2.1489 - val_accuracy: 0.4913
    Epoch 16/100
    1250/1250 [==============================] - 81s 65ms/step - loss: 1.9838 - accuracy: 0.5256 - val_loss: 2.1912 - val_accuracy: 0.4859
    Epoch 17/100
    1250/1250 [==============================] - 81s 65ms/step - loss: 1.9787 - accuracy: 0.5309 - val_loss: 2.1531 - val_accuracy: 0.4869
    Epoch 18/100
    1250/1250 [==============================] - 81s 65ms/step - loss: 1.9532 - accuracy: 0.5429 - val_loss: 2.1553 - val_accuracy: 0.5002
    Epoch 19/100
    1250/1250 [==============================] - 81s 64ms/step - loss: 1.9499 - accuracy: 0.5441 - val_loss: 2.1181 - val_accuracy: 0.5062
    Epoch 20/100
    1250/1250 [==============================] - 87s 69ms/step - loss: 1.9473 - accuracy: 0.5494 - val_loss: 2.2089 - val_accuracy: 0.4921
    Epoch 21/100
    1250/1250 [==============================] - 84s 67ms/step - loss: 1.9338 - accuracy: 0.5542 - val_loss: 2.2257 - val_accuracy: 0.4901
    Epoch 22/100
    1250/1250 [==============================] - 83s 66ms/step - loss: 1.9510 - accuracy: 0.5528 - val_loss: 2.1990 - val_accuracy: 0.4863
    Epoch 23/100
    1250/1250 [==============================] - 82s 66ms/step - loss: 1.9619 - accuracy: 0.5530 - val_loss: 2.2437 - val_accuracy: 0.4777
    Epoch 24/100
    1250/1250 [==============================] - 84s 67ms/step - loss: 1.9406 - accuracy: 0.5603 - val_loss: 2.2419 - val_accuracy: 0.4778
    Epoch 00024: early stopping
    Test loss: 2.237199068069458
    Test accuracy: 0.47620001435279846
    
     
    
    


    
![png](output_163_1.png)
    



    
![png](output_163_2.png)
    



```python

```

# Classification Models - Class

## Color - Class

### Basic Models - Logistic Regression

We will try out the basic model and see how the accuracy scores are.


```python
# Set our X_train, y_train and X_test, y_test

X_train_flat = Train_flat_data
y_train = np.array(train[b'fine_labels']) #set coarse/superclass as our classification target

X_test_flat = Test_flat_data
y_test = np.array(test[b'fine_labels'])
```


```python
from sklearn.linear_model import LogisticRegression

LR = LogisticRegression(random_state=1, n_jobs=-1)
LR.fit(X_train_flat, y_train)
print('Train score: ', LR.score(X_train_flat, y_train))
print('Test score: ', LR.score(X_test_flat, y_test))
```

    Train score:  0.26188
    Test score:  0.1733
    


```python
from sklearn.metrics import confusion_matrix
import seaborn as sns
# Make classifications based on the test features, and assign the classifications to a variable
LR_y_pred = LR.predict(X_test_flat)

# Build the confusion matrix as a dataframe
confusion_df = pd.DataFrame(confusion_matrix(y_test, LR_y_pred))
confusion_df.index = [f'Actually {i}' for i in Class_label['Class_label']]
confusion_df.columns = [f'Predicted {i}' for i in Class_label['Class_label']]


plt.figure(figsize = (12,12))
sns.heatmap(confusion_df,
            annot=True,
            cbar=False,
            cmap="rocket_r",
            linewidths=0.5
           )
plt.title('Confusion Matrix',size = 25,y=1.01)
plt.xlabel("Predicted Label", size = 20)
plt.ylabel("True Label", size = 20)
plt.show()
```


    
![png](output_171_0.png)
    


### Self-Constructed CNN

##### Set up train and test sets


```python
# Set our X_train, y_train and X_test, y_test

X_train = Train_data
y_train = Train_fine #set fine/class as our classification target

X_test = Test_data
y_test = Test_fine
```


```python
print(f'X_train range: {X_train.min()}-{X_train.max()}')
print(f'X_train range: {X_test.min()}-{X_test.max()}')
```

    X_train range: 0-255
    X_train range: 0-255
    


```python
# Scale the X values to between 0 to 1
X_train = X_train.astype('float32')
X_test = X_test.astype('float32')
X_train /= 255
X_test /= 255
print(f'X_train range: {X_train.min()}-{X_train.max()}')
```

    X_train range: 0.0-1.0
    


```python
X_train.shape, y_train.shape, X_test.shape, y_test.shape
```




    ((50000, 32, 32, 3), (50000, 1), (10000, 32, 32, 3), (10000, 1))




```python
    #=========================================================================================
    # ACCURACY ON TEST SCORE
    #=========================================================================================
    
    def test_loss_score(model):

        # Evaluate the model's performance on the test data
        score = model.evaluate(X_test, y_test, verbose=3)

        print('Test loss:', score[0])
        print('Test accuracy:', score[1])
        print('\n', '\n')
    
    #=========================================================================================
     # TRAINING/VALIDATION ACCURACY AND LOSS
    #=========================================================================================
    
    def accuracy_loss_plots(model):
        # Set up two subplots
        plt.subplots(1, 2, figsize=(18, 6))

        # Plot accuracies
        plt.subplot(1, 2, 1)
        plt.plot(model.history['accuracy'], label='Train', marker='.')
        plt.plot(model.history['val_accuracy'], label='Validation', marker='.')
        plt.title('Accuracies Across Epochs')
        plt.xlabel('Epoch')
        plt.ylabel('Accuracy')
        plt.legend()

        # Plot losses
        plt.subplot(1, 2, 2)
        plt.plot(model.history['loss'], label='Train', marker='.')
        plt.plot(model.history['val_loss'], label='Validation', marker='.')
        plt.title('Losses Across Epochs')
        plt.xlabel('Epoch')
        plt.ylabel('Loss')
        plt.legend()

        # This ensures the subplots do not overlap
        plt.tight_layout()

        # Show the subplots
        plt.show()

    #=========================================================================================
    # CONFUSION MATRIX
    #=========================================================================================
   
    from sklearn.metrics import confusion_matrix
    def confusion(model):
        # Calculate the predicted labels for each test image.
        predict_probas = model.predict(X_test)
        y_predict = np.argmax(predict_probas, axis=1)

        # Create the confusion matrix using sklearn 
        conf_mat = confusion_matrix(y_test, y_predict)

        # Since we have many images, it is helpful to show our 
        # results as fractions of the total number of images 
        # for each class.
        normalized_conf_mat = conf_mat / conf_mat.sum(axis=1)

        normalized_conf_mat = pd.DataFrame(normalized_conf_mat, columns=CL).set_index(CL)

        plt.figure(figsize = (30,30))
        sns.heatmap(normalized_conf_mat,
                    annot=True,
                    cbar=False,
                    cmap="rocket_r",
                    linewidths=1
                   )
        plt.title('Confusion Matrix',size = 25,y=1.01)
        plt.xlabel("Predicted Label", size = 20)
        plt.ylabel("True Label", size = 20)
        plt.show()
        
ES = EarlyStopping(monitor='val_accuracy', patience=5, mode='auto', min_delta=0.0001, verbose=1)

```

##### CNN 1 - Model 1


```python
CNN_model_class = Sequential()

# Create simple CNN model architecture with Pooling for dimensionality reduction 
# and Dropout to reduce overfitting
CNN_model_class.add(Conv2D(32, kernel_size=(3, 3), activation = 'relu', input_shape = (32,32,3)))
CNN_model_class.add(MaxPooling2D(pool_size=(2, 2)))
CNN_model_class.add(Dropout(0.2))

CNN_model_class.add(Conv2D(64, kernel_size=(3, 3), activation = 'relu'))
CNN_model_class.add(MaxPooling2D(pool_size=(2, 2), padding='same'))
CNN_model_class.add(Dropout(0.2))


CNN_model_class.add(Conv2D(128, kernel_size=(3, 3), activation = 'relu'))
CNN_model_class.add(MaxPooling2D(pool_size=(2, 2), padding='same'))
CNN_model_class.add(Dropout(0.2))

CNN_model_class.add(Conv2D(256, kernel_size=(3, 3), activation = 'relu', padding='same'))
CNN_model_class.add(MaxPooling2D(pool_size=(2, 2), padding='same'))
CNN_model_class.add(Dropout(0.2))

CNN_model_class.add(Conv2D(512, kernel_size=(3, 3), activation = 'relu', padding='same'))
CNN_model_class.add(MaxPooling2D(pool_size=(2, 2), padding='same'))
CNN_model_class.add(Dropout(0.2))

CNN_model_class.add(Conv2D(1024, kernel_size=(3, 3), activation = 'relu', padding='same'))
CNN_model_class.add(MaxPooling2D(pool_size=(2, 2), padding='same'))
CNN_model_class.add(Dropout(0.3))
 

# Flatten the output of our convolutional layers
CNN_model_class.add(Flatten())

# Add dense layers
CNN_model_class.add(Dense(1024, activation= 'relu'))
CNN_model_class.add(Dense(512, activation= 'relu')) 
CNN_model_class.add(Dense(len(np.unique(y_train)), activation='softmax'))

# Print out a summary of the network
CNN_model_class.summary()

# Compile the model with the desired loss function, optimizer, and metric(s) to track
CNN_model_class.compile(loss = 'sparse_categorical_crossentropy', 
                  optimizer = 'Adam',
                  metrics = ['accuracy'])

# Fit the model on the training data, defining desired batch_size & number of epochs,
# running validation after each batch
CNN1_class = CNN_model_class.fit(X_train, y_train,
              batch_size = 128,
              epochs = 50,
              verbose = 1,
              validation_split = 0.2)



test_loss_score(CNN_model_class)
accuracy_loss_plots(CNN1_class)
confusion(CNN_model_class)
save_format='h5'
CNN_model1_class.save('CNNmodels/CNN_model1_class.h5')
```

    Model: "sequential_35"
    _________________________________________________________________
    Layer (type)                 Output Shape              Param #   
    =================================================================
    conv2d_160 (Conv2D)          (None, 30, 30, 32)        896       
    _________________________________________________________________
    max_pooling2d_122 (MaxPoolin (None, 15, 15, 32)        0         
    _________________________________________________________________
    dropout_108 (Dropout)        (None, 15, 15, 32)        0         
    _________________________________________________________________
    conv2d_161 (Conv2D)          (None, 13, 13, 64)        18496     
    _________________________________________________________________
    max_pooling2d_123 (MaxPoolin (None, 7, 7, 64)          0         
    _________________________________________________________________
    dropout_109 (Dropout)        (None, 7, 7, 64)          0         
    _________________________________________________________________
    conv2d_162 (Conv2D)          (None, 5, 5, 128)         73856     
    _________________________________________________________________
    max_pooling2d_124 (MaxPoolin (None, 3, 3, 128)         0         
    _________________________________________________________________
    dropout_110 (Dropout)        (None, 3, 3, 128)         0         
    _________________________________________________________________
    conv2d_163 (Conv2D)          (None, 3, 3, 256)         295168    
    _________________________________________________________________
    max_pooling2d_125 (MaxPoolin (None, 2, 2, 256)         0         
    _________________________________________________________________
    dropout_111 (Dropout)        (None, 2, 2, 256)         0         
    _________________________________________________________________
    conv2d_164 (Conv2D)          (None, 2, 2, 512)         1180160   
    _________________________________________________________________
    max_pooling2d_126 (MaxPoolin (None, 1, 1, 512)         0         
    _________________________________________________________________
    dropout_112 (Dropout)        (None, 1, 1, 512)         0         
    _________________________________________________________________
    conv2d_165 (Conv2D)          (None, 1, 1, 1024)        4719616   
    _________________________________________________________________
    max_pooling2d_127 (MaxPoolin (None, 1, 1, 1024)        0         
    _________________________________________________________________
    dropout_113 (Dropout)        (None, 1, 1, 1024)        0         
    _________________________________________________________________
    flatten_31 (Flatten)         (None, 1024)              0         
    _________________________________________________________________
    dense_100 (Dense)            (None, 1024)              1049600   
    _________________________________________________________________
    dense_101 (Dense)            (None, 512)               524800    
    _________________________________________________________________
    dense_102 (Dense)            (None, 100)               51300     
    =================================================================
    Total params: 7,913,892
    Trainable params: 7,913,892
    Non-trainable params: 0
    _________________________________________________________________
    Epoch 1/50
    313/313 [==============================] - 500s 2s/step - loss: 4.3939 - accuracy: 0.0227 - val_loss: 4.2431 - val_accuracy: 0.0370
    Epoch 2/50
    313/313 [==============================] - 505s 2s/step - loss: 4.0765 - accuracy: 0.0515 - val_loss: 4.0014 - val_accuracy: 0.0670
    Epoch 3/50
    313/313 [==============================] - 481s 2s/step - loss: 3.8561 - accuracy: 0.0830 - val_loss: 3.7975 - val_accuracy: 0.1021
    Epoch 4/50
    313/313 [==============================] - 478s 2s/step - loss: 3.7009 - accuracy: 0.1073 - val_loss: 3.7083 - val_accuracy: 0.1148
    Epoch 5/50
    313/313 [==============================] - 477s 2s/step - loss: 3.5717 - accuracy: 0.1355 - val_loss: 3.5148 - val_accuracy: 0.1521
    Epoch 6/50
    313/313 [==============================] - 491s 2s/step - loss: 3.4395 - accuracy: 0.1593 - val_loss: 3.3652 - val_accuracy: 0.1762
    Epoch 7/50
    313/313 [==============================] - 505s 2s/step - loss: 3.3284 - accuracy: 0.1838 - val_loss: 3.2734 - val_accuracy: 0.1999
    Epoch 8/50
    313/313 [==============================] - 501s 2s/step - loss: 3.2308 - accuracy: 0.2007 - val_loss: 3.1520 - val_accuracy: 0.2243
    Epoch 9/50
    313/313 [==============================] - 488s 2s/step - loss: 3.1560 - accuracy: 0.2177 - val_loss: 3.0497 - val_accuracy: 0.2403
    Epoch 10/50
    313/313 [==============================] - 509s 2s/step - loss: 3.0800 - accuracy: 0.2312 - val_loss: 3.0303 - val_accuracy: 0.2450
    Epoch 11/50
    313/313 [==============================] - 510s 2s/step - loss: 2.9937 - accuracy: 0.2468 - val_loss: 2.9561 - val_accuracy: 0.2625
    Epoch 12/50
    313/313 [==============================] - 495s 2s/step - loss: 2.9354 - accuracy: 0.2611 - val_loss: 2.9144 - val_accuracy: 0.2750
    Epoch 13/50
    313/313 [==============================] - 472s 2s/step - loss: 2.8829 - accuracy: 0.2676 - val_loss: 2.8727 - val_accuracy: 0.2854
    Epoch 14/50
    313/313 [==============================] - 475s 2s/step - loss: 2.8278 - accuracy: 0.2811 - val_loss: 2.8087 - val_accuracy: 0.2990
    Epoch 15/50
    313/313 [==============================] - 475s 2s/step - loss: 2.7868 - accuracy: 0.2903 - val_loss: 2.7845 - val_accuracy: 0.3041
    Epoch 16/50
    313/313 [==============================] - 473s 2s/step - loss: 2.7498 - accuracy: 0.2957 - val_loss: 2.8147 - val_accuracy: 0.3060
    Epoch 17/50
    313/313 [==============================] - 471s 2s/step - loss: 2.7080 - accuracy: 0.3067 - val_loss: 2.7592 - val_accuracy: 0.3116
    Epoch 18/50
    313/313 [==============================] - 474s 2s/step - loss: 2.6562 - accuracy: 0.3150 - val_loss: 2.6819 - val_accuracy: 0.3244
    Epoch 19/50
    313/313 [==============================] - 475s 2s/step - loss: 2.6134 - accuracy: 0.3237 - val_loss: 2.6807 - val_accuracy: 0.3264
    Epoch 20/50
    313/313 [==============================] - 476s 2s/step - loss: 2.5925 - accuracy: 0.3280 - val_loss: 2.6799 - val_accuracy: 0.3320
    Epoch 21/50
    313/313 [==============================] - 474s 2s/step - loss: 2.5606 - accuracy: 0.3374 - val_loss: 2.6546 - val_accuracy: 0.3381
    Epoch 22/50
    313/313 [==============================] - 473s 2s/step - loss: 2.5204 - accuracy: 0.3442 - val_loss: 2.5883 - val_accuracy: 0.3509
    Epoch 23/50
    313/313 [==============================] - 474s 2s/step - loss: 2.4904 - accuracy: 0.3495 - val_loss: 2.6671 - val_accuracy: 0.3402
    Epoch 24/50
    313/313 [==============================] - 476s 2s/step - loss: 2.4655 - accuracy: 0.3562 - val_loss: 2.6399 - val_accuracy: 0.3451
    Epoch 25/50
    313/313 [==============================] - 474s 2s/step - loss: 2.4383 - accuracy: 0.3617 - val_loss: 2.5866 - val_accuracy: 0.3501
    Epoch 26/50
    313/313 [==============================] - 473s 2s/step - loss: 2.4168 - accuracy: 0.3626 - val_loss: 2.5596 - val_accuracy: 0.3558
    Epoch 27/50
    313/313 [==============================] - 475s 2s/step - loss: 2.3809 - accuracy: 0.3713 - val_loss: 2.5626 - val_accuracy: 0.3580
    Epoch 28/50
    313/313 [==============================] - 476s 2s/step - loss: 2.3708 - accuracy: 0.3725 - val_loss: 2.5981 - val_accuracy: 0.3525
    Epoch 29/50
    313/313 [==============================] - 476s 2s/step - loss: 2.3533 - accuracy: 0.3744 - val_loss: 2.6127 - val_accuracy: 0.3532
    Epoch 30/50
    313/313 [==============================] - 472s 2s/step - loss: 2.3221 - accuracy: 0.3855 - val_loss: 2.5262 - val_accuracy: 0.3676
    Epoch 31/50
    313/313 [==============================] - 475s 2s/step - loss: 2.3111 - accuracy: 0.3909 - val_loss: 2.5110 - val_accuracy: 0.3648
    Epoch 32/50
    313/313 [==============================] - 475s 2s/step - loss: 2.2832 - accuracy: 0.3919 - val_loss: 2.5311 - val_accuracy: 0.3666
    Epoch 33/50
    313/313 [==============================] - 474s 2s/step - loss: 2.2807 - accuracy: 0.3947 - val_loss: 2.5319 - val_accuracy: 0.3695
    Epoch 34/50
    313/313 [==============================] - 475s 2s/step - loss: 2.2552 - accuracy: 0.3992 - val_loss: 2.5067 - val_accuracy: 0.3736
    Epoch 35/50
    313/313 [==============================] - 474s 2s/step - loss: 2.2459 - accuracy: 0.4029 - val_loss: 2.5050 - val_accuracy: 0.3730
    Epoch 36/50
    313/313 [==============================] - 477s 2s/step - loss: 2.2331 - accuracy: 0.4031 - val_loss: 2.4643 - val_accuracy: 0.3818
    Epoch 37/50
    313/313 [==============================] - 475s 2s/step - loss: 2.2082 - accuracy: 0.4109 - val_loss: 2.4976 - val_accuracy: 0.3850
    Epoch 38/50
    313/313 [==============================] - 475s 2s/step - loss: 2.1976 - accuracy: 0.4122 - val_loss: 2.4573 - val_accuracy: 0.3827
    Epoch 39/50
    313/313 [==============================] - 476s 2s/step - loss: 2.1789 - accuracy: 0.4193 - val_loss: 2.5269 - val_accuracy: 0.3779
    Epoch 40/50
    313/313 [==============================] - 475s 2s/step - loss: 2.1665 - accuracy: 0.4199 - val_loss: 2.5343 - val_accuracy: 0.3770
    Epoch 41/50
    313/313 [==============================] - 478s 2s/step - loss: 2.1475 - accuracy: 0.4256 - val_loss: 2.4683 - val_accuracy: 0.3885
    Epoch 42/50
    313/313 [==============================] - 477s 2s/step - loss: 2.1467 - accuracy: 0.4258 - val_loss: 2.4606 - val_accuracy: 0.3900
    Epoch 43/50
    313/313 [==============================] - 475s 2s/step - loss: 2.1232 - accuracy: 0.4268 - val_loss: 2.4765 - val_accuracy: 0.3935
    Epoch 44/50
    313/313 [==============================] - 476s 2s/step - loss: 2.1095 - accuracy: 0.4349 - val_loss: 2.5380 - val_accuracy: 0.3774
    Epoch 45/50
    313/313 [==============================] - 476s 2s/step - loss: 2.1119 - accuracy: 0.4310 - val_loss: 2.4887 - val_accuracy: 0.3884
    Epoch 46/50
    313/313 [==============================] - 475s 2s/step - loss: 2.0905 - accuracy: 0.4365 - val_loss: 2.4897 - val_accuracy: 0.3868
    Epoch 47/50
    313/313 [==============================] - 475s 2s/step - loss: 2.0687 - accuracy: 0.4395 - val_loss: 2.4961 - val_accuracy: 0.3874
    Epoch 48/50
    313/313 [==============================] - 475s 2s/step - loss: 2.0716 - accuracy: 0.4405 - val_loss: 2.5082 - val_accuracy: 0.3846
    Epoch 49/50
    313/313 [==============================] - 476s 2s/step - loss: 2.0641 - accuracy: 0.4411 - val_loss: 2.4566 - val_accuracy: 0.3989
    Epoch 50/50
    313/313 [==============================] - 476s 2s/step - loss: 2.0492 - accuracy: 0.4455 - val_loss: 2.4571 - val_accuracy: 0.3970
    Test loss: 2.420616388320923
    Test accuracy: 0.39879998564720154
    
     
    
    


    
![png](output_180_1.png)
    



    
![png](output_180_2.png)
    



    ---------------------------------------------------------------------------

    NameError                                 Traceback (most recent call last)

    <ipython-input-111-9726e06b69fa> in <module>
         59 confusion(CNN_model_class)
         60 save_format='h5'
    ---> 61 CNN_model1_class.save('CNNmodels/CNN_model1_class.h5')
    

    NameError: name 'CNN_model1_class' is not defined


##### CNN 1 - Model 3


```python
CNN_model3_class = Sequential()

# Create simple CNN model architecture with Pooling for dimensionality reduction 
# and Dropout to reduce overfitting
CNN_model3_class.add(Conv2D(256, kernel_size=(3, 3), activation = 'relu', input_shape = (32,32,3)))
CNN_model3_class.add(MaxPooling2D(pool_size=(2, 2)))
CNN_model3_class.add(Dropout(0.2))

CNN_model3_class.add(Conv2D(512, kernel_size=(3, 3), activation = 'relu'))
CNN_model3_class.add(MaxPooling2D(pool_size=(2, 2)))
CNN_model3_class.add(Dropout(0.2))

CNN_model3_class.add(Conv2D(1024, kernel_size=(3, 3), activation = 'relu'))
CNN_model3_class.add(MaxPooling2D(pool_size=(2, 2)))
CNN_model3_class.add(Dropout(0.2))

# Flatten the output of our convolutional layers
CNN_model3_class.add(Flatten())

# Add dense layers
CNN_model3_class.add(Dense(1024, activation= 'relu'))
CNN_model3_class.add(Dense(512, activation= 'relu'))
CNN_model3_class.add(Dense(len(np.unique(y_train)), activation='softmax'))

# Print out a summary of the network
CNN_model3_class.summary()

# Compile the model with the desired loss function, optimizer, and metric(s) to track
CNN_model3_class.compile(loss = 'sparse_categorical_crossentropy', 
                  optimizer = 'Adam',
                  metrics = ['accuracy'])

# Fit the model on the training data, defining desired batch_size & number of epochs,
# running validation after each batch
CNN3_class = CNN_model3_class.fit(X_train, y_train,
              batch_size = 128,
              epochs = 50,
              verbose = 1,
              validation_split = 0.2)



test_loss_score(CNN_model3_class)
accuracy_loss_plots(CNN3_class)
confusion(CNN_model3_class)
save_format='h5'
CNN_model3_class.save('CNNmodels/CNN_model3_class.h5')
```

    Model: "sequential_36"
    _________________________________________________________________
    Layer (type)                 Output Shape              Param #   
    =================================================================
    conv2d_166 (Conv2D)          (None, 30, 30, 256)       7168      
    _________________________________________________________________
    max_pooling2d_128 (MaxPoolin (None, 15, 15, 256)       0         
    _________________________________________________________________
    dropout_114 (Dropout)        (None, 15, 15, 256)       0         
    _________________________________________________________________
    conv2d_167 (Conv2D)          (None, 13, 13, 512)       1180160   
    _________________________________________________________________
    max_pooling2d_129 (MaxPoolin (None, 6, 6, 512)         0         
    _________________________________________________________________
    dropout_115 (Dropout)        (None, 6, 6, 512)         0         
    _________________________________________________________________
    conv2d_168 (Conv2D)          (None, 4, 4, 1024)        4719616   
    _________________________________________________________________
    max_pooling2d_130 (MaxPoolin (None, 2, 2, 1024)        0         
    _________________________________________________________________
    dropout_116 (Dropout)        (None, 2, 2, 1024)        0         
    _________________________________________________________________
    flatten_32 (Flatten)         (None, 4096)              0         
    _________________________________________________________________
    dense_103 (Dense)            (None, 1024)              4195328   
    _________________________________________________________________
    dense_104 (Dense)            (None, 512)               524800    
    _________________________________________________________________
    dense_105 (Dense)            (None, 100)               51300     
    =================================================================
    Total params: 10,678,372
    Trainable params: 10,678,372
    Non-trainable params: 0
    _________________________________________________________________
    Epoch 1/50
    313/313 [==============================] - 588s 2s/step - loss: 4.2843 - accuracy: 0.0376 - val_loss: 3.9173 - val_accuracy: 0.0885
    Epoch 2/50
    313/313 [==============================] - 611s 2s/step - loss: 3.6635 - accuracy: 0.1328 - val_loss: 3.4714 - val_accuracy: 0.1694
    Epoch 3/50
    313/313 [==============================] - 539s 2s/step - loss: 3.2792 - accuracy: 0.1983 - val_loss: 3.1514 - val_accuracy: 0.2258
    Epoch 4/50
    313/313 [==============================] - 524s 2s/step - loss: 2.9956 - accuracy: 0.2552 - val_loss: 2.9147 - val_accuracy: 0.2775
    Epoch 5/50
    313/313 [==============================] - 532s 2s/step - loss: 2.7741 - accuracy: 0.2994 - val_loss: 2.8080 - val_accuracy: 0.3016
    Epoch 6/50
    313/313 [==============================] - 546s 2s/step - loss: 2.5820 - accuracy: 0.3403 - val_loss: 2.7220 - val_accuracy: 0.3251
    Epoch 7/50
    313/313 [==============================] - 546s 2s/step - loss: 2.4104 - accuracy: 0.3753 - val_loss: 2.5933 - val_accuracy: 0.3435
    Epoch 8/50
    313/313 [==============================] - 545s 2s/step - loss: 2.2578 - accuracy: 0.4062 - val_loss: 2.5278 - val_accuracy: 0.3558
    Epoch 9/50
    313/313 [==============================] - 540s 2s/step - loss: 2.1178 - accuracy: 0.4335 - val_loss: 2.4535 - val_accuracy: 0.3740
    Epoch 10/50
    313/313 [==============================] - 536s 2s/step - loss: 1.9666 - accuracy: 0.4670 - val_loss: 2.4744 - val_accuracy: 0.3789
    Epoch 11/50
    313/313 [==============================] - 537s 2s/step - loss: 1.8416 - accuracy: 0.4949 - val_loss: 2.4867 - val_accuracy: 0.3837
    Epoch 12/50
    313/313 [==============================] - 526s 2s/step - loss: 1.7111 - accuracy: 0.5289 - val_loss: 2.5058 - val_accuracy: 0.3877
    Epoch 13/50
    313/313 [==============================] - 545s 2s/step - loss: 1.6092 - accuracy: 0.5501 - val_loss: 2.4988 - val_accuracy: 0.3977
    Epoch 14/50
    313/313 [==============================] - 564s 2s/step - loss: 1.4953 - accuracy: 0.5762 - val_loss: 2.5700 - val_accuracy: 0.3916
    Epoch 15/50
    313/313 [==============================] - 547s 2s/step - loss: 1.3838 - accuracy: 0.6022 - val_loss: 2.6080 - val_accuracy: 0.3969
    Epoch 16/50
    313/313 [==============================] - 531s 2s/step - loss: 1.2793 - accuracy: 0.6294 - val_loss: 2.6597 - val_accuracy: 0.4010
    Epoch 17/50
    313/313 [==============================] - 524s 2s/step - loss: 1.1891 - accuracy: 0.6510 - val_loss: 2.7214 - val_accuracy: 0.3934
    Epoch 18/50
    313/313 [==============================] - 523s 2s/step - loss: 1.1081 - accuracy: 0.6708 - val_loss: 2.7701 - val_accuracy: 0.3995
    Epoch 19/50
    313/313 [==============================] - 533s 2s/step - loss: 1.0444 - accuracy: 0.6885 - val_loss: 2.8216 - val_accuracy: 0.3992
    Epoch 20/50
    313/313 [==============================] - 553s 2s/step - loss: 0.9747 - accuracy: 0.7069 - val_loss: 2.9474 - val_accuracy: 0.3925
    Epoch 21/50
    313/313 [==============================] - 533s 2s/step - loss: 0.9211 - accuracy: 0.7204 - val_loss: 3.0241 - val_accuracy: 0.3996
    Epoch 22/50
    313/313 [==============================] - 526s 2s/step - loss: 0.8451 - accuracy: 0.7420 - val_loss: 3.1254 - val_accuracy: 0.3868
    Epoch 23/50
    313/313 [==============================] - 561s 2s/step - loss: 0.7986 - accuracy: 0.7534 - val_loss: 3.1821 - val_accuracy: 0.3961
    Epoch 24/50
    313/313 [==============================] - 570s 2s/step - loss: 0.7592 - accuracy: 0.7657 - val_loss: 3.2882 - val_accuracy: 0.3884
    Epoch 25/50
    313/313 [==============================] - 560s 2s/step - loss: 0.7178 - accuracy: 0.7763 - val_loss: 3.2636 - val_accuracy: 0.3890
    Epoch 26/50
    313/313 [==============================] - 528s 2s/step - loss: 0.6947 - accuracy: 0.7872 - val_loss: 3.4078 - val_accuracy: 0.3903
    Epoch 27/50
    313/313 [==============================] - 525s 2s/step - loss: 0.6398 - accuracy: 0.8004 - val_loss: 3.5207 - val_accuracy: 0.3880
    Epoch 28/50
    313/313 [==============================] - 531s 2s/step - loss: 0.6171 - accuracy: 0.8040 - val_loss: 3.5298 - val_accuracy: 0.3894
    Epoch 29/50
    200/313 [==================>...........] - ETA: 3:07 - loss: 0.5774 - accuracy: 0.8200


    ---------------------------------------------------------------------------

    KeyboardInterrupt                         Traceback (most recent call last)

    <ipython-input-112-5a8960b7ffe5> in <module>
         33 # Fit the model on the training data, defining desired batch_size & number of epochs,
         34 # running validation after each batch
    ---> 35 CNN3_class = CNN_model3_class.fit(X_train, y_train,
         36               batch_size = 128,
         37               epochs = 50,
    

    ~\anaconda3\envs\deeplearning\lib\site-packages\tensorflow\python\keras\engine\training.py in _method_wrapper(self, *args, **kwargs)
         64   def _method_wrapper(self, *args, **kwargs):
         65     if not self._in_multi_worker_mode():  # pylint: disable=protected-access
    ---> 66       return method(self, *args, **kwargs)
         67 
         68     # Running inside `run_distribute_coordinator` already.
    

    ~\anaconda3\envs\deeplearning\lib\site-packages\tensorflow\python\keras\engine\training.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)
        846                 batch_size=batch_size):
        847               callbacks.on_train_batch_begin(step)
    --> 848               tmp_logs = train_function(iterator)
        849               # Catch OutOfRangeError for Datasets of unknown size.
        850               # This blocks until the batch has finished executing.
    

    ~\anaconda3\envs\deeplearning\lib\site-packages\tensorflow\python\eager\def_function.py in __call__(self, *args, **kwds)
        578         xla_context.Exit()
        579     else:
    --> 580       result = self._call(*args, **kwds)
        581 
        582     if tracing_count == self._get_tracing_count():
    

    ~\anaconda3\envs\deeplearning\lib\site-packages\tensorflow\python\eager\def_function.py in _call(self, *args, **kwds)
        609       # In this case we have created variables on the first call, so we run the
        610       # defunned version which is guaranteed to never create variables.
    --> 611       return self._stateless_fn(*args, **kwds)  # pylint: disable=not-callable
        612     elif self._stateful_fn is not None:
        613       # Release the lock early so that multiple threads can perform the call
    

    ~\anaconda3\envs\deeplearning\lib\site-packages\tensorflow\python\eager\function.py in __call__(self, *args, **kwargs)
       2418     with self._lock:
       2419       graph_function, args, kwargs = self._maybe_define_function(args, kwargs)
    -> 2420     return graph_function._filtered_call(args, kwargs)  # pylint: disable=protected-access
       2421 
       2422   @property
    

    ~\anaconda3\envs\deeplearning\lib\site-packages\tensorflow\python\eager\function.py in _filtered_call(self, args, kwargs)
       1659       `args` and `kwargs`.
       1660     """
    -> 1661     return self._call_flat(
       1662         (t for t in nest.flatten((args, kwargs), expand_composites=True)
       1663          if isinstance(t, (ops.Tensor,
    

    ~\anaconda3\envs\deeplearning\lib\site-packages\tensorflow\python\eager\function.py in _call_flat(self, args, captured_inputs, cancellation_manager)
       1743         and executing_eagerly):
       1744       # No tape is watching; skip to running the function.
    -> 1745       return self._build_call_outputs(self._inference_function.call(
       1746           ctx, args, cancellation_manager=cancellation_manager))
       1747     forward_backward = self._select_forward_and_backward_functions(
    

    ~\anaconda3\envs\deeplearning\lib\site-packages\tensorflow\python\eager\function.py in call(self, ctx, args, cancellation_manager)
        591       with _InterpolateFunctionError(self):
        592         if cancellation_manager is None:
    --> 593           outputs = execute.execute(
        594               str(self.signature.name),
        595               num_outputs=self._num_outputs,
    

    ~\anaconda3\envs\deeplearning\lib\site-packages\tensorflow\python\eager\execute.py in quick_execute(op_name, num_outputs, inputs, attrs, ctx, name)
         57   try:
         58     ctx.ensure_initialized()
    ---> 59     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,
         60                                         inputs, attrs, num_outputs)
         61   except core._NotOkStatusException as e:
    

    KeyboardInterrupt: 


##### CNN 1 - Model 4


```python

CNN_model4_class = Sequential()

# Create simple CNN model architecture with Pooling for dimensionality reduction 
# and Dropout to reduce overfitting
CNN_model4_class.add(Conv2D(128, kernel_size=(3, 3), activation = 'relu', input_shape = (32,32,3)))
CNN_model4_class.add(MaxPooling2D(pool_size=(2, 2)))
CNN_model4_class.add(Dropout(0.1))

CNN_model4_class.add(Conv2D(256, kernel_size=(3, 3), activation = 'relu'))
CNN_model4_class.add(MaxPooling2D(pool_size=(2, 2)))
CNN_model4_class.add(Dropout(0.2))

CNN_model4_class.add(Conv2D(512, kernel_size=(3, 3), activation = 'relu'))
CNN_model4_class.add(MaxPooling2D(pool_size=(2, 2)))
CNN_model4_class.add(Dropout(0.4))

# Flatten the output of our convolutional layers
CNN_model4_class.add(Flatten())

# Add dense layers
CNN_model4_class.add(Dense(512, activation= 'relu'))
CNN_model4_class.add(Dense(256, activation= 'relu'))
CNN_model4_class.add(Dense(128, activation= 'relu'))
CNN_model4_class.add(Dense(len(np.unique(y_train)), activation='softmax'))

# Print out a summary of the network
CNN_model4_class.summary()

# Compile the model with the desired loss function, optimizer, and metric(s) to track
CNN_model4_class.compile(loss = 'sparse_categorical_crossentropy', 
                  optimizer = 'Adam',
                  metrics = ['accuracy'])

# Fit the model on the training data, defining desired batch_size & number of epochs,
# running validation after each batch
CNN4_class = CNN_model4_class.fit(X_train, y_train,
              batch_size = 128,
              epochs = 50,
              verbose = 1,
              validation_split = 0.2,
              callbacks = ES)

test_loss_score(CNN_model4)
accuracy_loss_plots(CNN4)
confusion(CNN_model4)

save_format='h5'
CNN_model4_class.save('CNNmodels/CNN_model4_class.h5')
```

https://arxiv.org/pdf/1511.07289.pdf

##### CNN 2 - Model 5


```python
CNN_model5_class = Sequential()

# Create simple CNN model architecture with Pooling for dimensionality reduction 
# and Dropout to reduce overfitting
CNN_model5_class.add(Conv2D(192, kernel_size=(5, 5), activation = 'elu', input_shape = (32,32,3), kernel_regularizer=l2(0.0005))) 
CNN_model5_class.add(MaxPooling2D(pool_size=(2, 2), padding='same'))
CNN_model5_class.add(Dropout(0.0))

CNN_model5_class.add(Conv2D(192, kernel_size=(1, 1), activation = 'elu', padding='same', kernel_regularizer=l2(0.0005)))
CNN_model5_class.add(Conv2D(240, kernel_size=(3, 3), activation = 'elu', padding='same', kernel_regularizer=l2(0.0005)))
CNN_model5_class.add(MaxPooling2D(pool_size=(2, 2), padding='same'))
CNN_model5_class.add(Dropout(0.1))

CNN_model5_class.add(Conv2D(240, kernel_size=(1,1), activation = 'elu', padding='same', kernel_regularizer=l2(0.0005)))
CNN_model5_class.add(Conv2D(260, kernel_size=(2,2), activation = 'elu', padding='same', kernel_regularizer=l2(0.0005)))
CNN_model5_class.add(MaxPooling2D(pool_size=(2, 2), padding='same'))
CNN_model5_class.add(Dropout(0.2))

CNN_model5_class.add(Conv2D(260, kernel_size=(1,1), activation = 'elu', padding='same', kernel_regularizer=l2(0.0005)))
CNN_model5_class.add(Conv2D(280, kernel_size=(2,2), activation = 'elu', padding='same', kernel_regularizer=l2(0.0005)))
CNN_model5_class.add(MaxPooling2D(pool_size=(2, 2), padding='same'))
CNN_model5_class.add(Dropout(0.3))

CNN_model5_class.add(Conv2D(280, kernel_size=(1,1), activation = 'elu', padding='same', kernel_regularizer=l2(0.0005)))
CNN_model5_class.add(Conv2D(300, kernel_size=(2,2), activation = 'elu', padding='same', kernel_regularizer=l2(0.0005)))
CNN_model5_class.add(MaxPooling2D(pool_size=(2, 2), padding='same'))
CNN_model5_class.add(Dropout(0.4))

CNN_model5_class.add(Conv2D(300, kernel_size=(2,2), activation = 'elu', padding='same', kernel_regularizer=l2(0.0005)))
CNN_model5_class.add(MaxPooling2D(pool_size=(2, 2), padding='same'))
CNN_model5_class.add(Dropout(0.5))

# Flatten the output of our convolutional layers
CNN_model5_class.add(Flatten())

# Add dense layers
CNN_model5_class.add(Dense(len(np.unique(y_train)), activation='softmax'))

# Print out a summary of the network
CNN_model5_class.summary()

# Compile the model with the desired loss function, optimizer, and metric(s) to track
CNN_model5_class.compile(loss = 'sparse_categorical_crossentropy', #cross entropy is for multi-class classification
                  optimizer = 'Adam',
                  metrics = ['accuracy'])

# Fit the model on the training data, defining desired batch_size & number of epochs,
# running validation after each batch
CNN5_class = CNN_model5_class.fit(X_train, y_train,
              batch_size = 128,
              epochs = 100,
              verbose = 1,
              validation_split = 0.2)

test_loss_score(CNN_model5_class)
accuracy_loss_plots(CNN5_class)
confusion(CNN_model5_class)
CNN_model5_class.save('CNNmodels/CNN_model5_class.h5')
```

    Model: "sequential_30"
    _________________________________________________________________
    Layer (type)                 Output Shape              Param #   
    =================================================================
    conv2d_130 (Conv2D)          (None, 28, 28, 192)       14592     
    _________________________________________________________________
    max_pooling2d_97 (MaxPooling (None, 14, 14, 192)       0         
    _________________________________________________________________
    dropout_84 (Dropout)         (None, 14, 14, 192)       0         
    _________________________________________________________________
    conv2d_131 (Conv2D)          (None, 14, 14, 192)       37056     
    _________________________________________________________________
    conv2d_132 (Conv2D)          (None, 14, 14, 240)       414960    
    _________________________________________________________________
    max_pooling2d_98 (MaxPooling (None, 7, 7, 240)         0         
    _________________________________________________________________
    dropout_85 (Dropout)         (None, 7, 7, 240)         0         
    _________________________________________________________________
    conv2d_133 (Conv2D)          (None, 7, 7, 240)         57840     
    _________________________________________________________________
    conv2d_134 (Conv2D)          (None, 7, 7, 260)         249860    
    _________________________________________________________________
    max_pooling2d_99 (MaxPooling (None, 4, 4, 260)         0         
    _________________________________________________________________
    dropout_86 (Dropout)         (None, 4, 4, 260)         0         
    _________________________________________________________________
    conv2d_135 (Conv2D)          (None, 4, 4, 260)         67860     
    _________________________________________________________________
    conv2d_136 (Conv2D)          (None, 4, 4, 280)         291480    
    _________________________________________________________________
    max_pooling2d_100 (MaxPoolin (None, 2, 2, 280)         0         
    _________________________________________________________________
    dropout_87 (Dropout)         (None, 2, 2, 280)         0         
    _________________________________________________________________
    conv2d_137 (Conv2D)          (None, 2, 2, 280)         78680     
    _________________________________________________________________
    conv2d_138 (Conv2D)          (None, 2, 2, 300)         336300    
    _________________________________________________________________
    max_pooling2d_101 (MaxPoolin (None, 1, 1, 300)         0         
    _________________________________________________________________
    dropout_88 (Dropout)         (None, 1, 1, 300)         0         
    _________________________________________________________________
    conv2d_139 (Conv2D)          (None, 1, 1, 300)         360300    
    _________________________________________________________________
    max_pooling2d_102 (MaxPoolin (None, 1, 1, 300)         0         
    _________________________________________________________________
    dropout_89 (Dropout)         (None, 1, 1, 300)         0         
    _________________________________________________________________
    flatten_28 (Flatten)         (None, 300)               0         
    _________________________________________________________________
    dense_91 (Dense)             (None, 100)               30100     
    =================================================================
    Total params: 1,939,028
    Trainable params: 1,939,028
    Non-trainable params: 0
    _________________________________________________________________
    Epoch 1/100
    313/313 [==============================] - 201s 644ms/step - loss: 4.8807 - accuracy: 0.0507 - val_loss: 4.2914 - val_accuracy: 0.0956
    Epoch 2/100
    313/313 [==============================] - 202s 646ms/step - loss: 4.1388 - accuracy: 0.1101 - val_loss: 3.8411 - val_accuracy: 0.1602
    Epoch 3/100
    313/313 [==============================] - 207s 661ms/step - loss: 3.8664 - accuracy: 0.1482 - val_loss: 3.6264 - val_accuracy: 0.1981
    Epoch 4/100
    313/313 [==============================] - 207s 663ms/step - loss: 3.7054 - accuracy: 0.1758 - val_loss: 3.4695 - val_accuracy: 0.2212
    Epoch 5/100
    313/313 [==============================] - 206s 657ms/step - loss: 3.5844 - accuracy: 0.1998 - val_loss: 3.3724 - val_accuracy: 0.2459
    Epoch 6/100
    313/313 [==============================] - 203s 648ms/step - loss: 3.4950 - accuracy: 0.2137 - val_loss: 3.3068 - val_accuracy: 0.2599
    Epoch 7/100
    313/313 [==============================] - 220s 702ms/step - loss: 3.4153 - accuracy: 0.2333 - val_loss: 3.2509 - val_accuracy: 0.2719
    Epoch 8/100
    313/313 [==============================] - 205s 655ms/step - loss: 3.3433 - accuracy: 0.2484 - val_loss: 3.1000 - val_accuracy: 0.3075
    Epoch 9/100
    313/313 [==============================] - 206s 658ms/step - loss: 3.2747 - accuracy: 0.2664 - val_loss: 3.0778 - val_accuracy: 0.3069
    Epoch 10/100
    313/313 [==============================] - 204s 653ms/step - loss: 3.2044 - accuracy: 0.2811 - val_loss: 3.0640 - val_accuracy: 0.3114
    Epoch 11/100
    313/313 [==============================] - 206s 659ms/step - loss: 3.1589 - accuracy: 0.2887 - val_loss: 3.0292 - val_accuracy: 0.3210
    Epoch 12/100
    313/313 [==============================] - 207s 661ms/step - loss: 3.1219 - accuracy: 0.3043 - val_loss: 2.9484 - val_accuracy: 0.3493
    Epoch 13/100
    313/313 [==============================] - 204s 650ms/step - loss: 3.0818 - accuracy: 0.3096 - val_loss: 2.9047 - val_accuracy: 0.3481
    Epoch 14/100
    313/313 [==============================] - 204s 653ms/step - loss: 3.0270 - accuracy: 0.3198 - val_loss: 2.8627 - val_accuracy: 0.3628
    Epoch 15/100
    313/313 [==============================] - 203s 647ms/step - loss: 2.9953 - accuracy: 0.3300 - val_loss: 2.8517 - val_accuracy: 0.3635
    Epoch 16/100
    313/313 [==============================] - 207s 662ms/step - loss: 2.9742 - accuracy: 0.3377 - val_loss: 2.8126 - val_accuracy: 0.3728
    Epoch 17/100
    313/313 [==============================] - 208s 663ms/step - loss: 2.9478 - accuracy: 0.3408 - val_loss: 2.7982 - val_accuracy: 0.3769
    Epoch 18/100
    313/313 [==============================] - 203s 648ms/step - loss: 2.9102 - accuracy: 0.3519 - val_loss: 2.7659 - val_accuracy: 0.3915
    Epoch 19/100
    313/313 [==============================] - 208s 664ms/step - loss: 2.8944 - accuracy: 0.3558 - val_loss: 2.7923 - val_accuracy: 0.3854
    Epoch 20/100
    313/313 [==============================] - 205s 656ms/step - loss: 2.8781 - accuracy: 0.3618 - val_loss: 2.7508 - val_accuracy: 0.4017
    Epoch 21/100
    313/313 [==============================] - 206s 657ms/step - loss: 2.8471 - accuracy: 0.3704 - val_loss: 2.7199 - val_accuracy: 0.3999
    Epoch 22/100
    313/313 [==============================] - 207s 660ms/step - loss: 2.8385 - accuracy: 0.3742 - val_loss: 2.7290 - val_accuracy: 0.4029
    Epoch 23/100
    313/313 [==============================] - 209s 668ms/step - loss: 2.8200 - accuracy: 0.3767 - val_loss: 2.7517 - val_accuracy: 0.3993
    Epoch 24/100
    313/313 [==============================] - 209s 667ms/step - loss: 2.7902 - accuracy: 0.3893 - val_loss: 2.6844 - val_accuracy: 0.4175
    Epoch 25/100
    313/313 [==============================] - 215s 686ms/step - loss: 2.7860 - accuracy: 0.3887 - val_loss: 2.6685 - val_accuracy: 0.4177
    Epoch 26/100
    313/313 [==============================] - 216s 690ms/step - loss: 2.7671 - accuracy: 0.3982 - val_loss: 2.7279 - val_accuracy: 0.4093
    Epoch 27/100
    313/313 [==============================] - 212s 677ms/step - loss: 2.7506 - accuracy: 0.3998 - val_loss: 2.6413 - val_accuracy: 0.4335
    Epoch 28/100
    313/313 [==============================] - 209s 669ms/step - loss: 2.7313 - accuracy: 0.4049 - val_loss: 2.6824 - val_accuracy: 0.4230
    Epoch 29/100
    313/313 [==============================] - 207s 662ms/step - loss: 2.7295 - accuracy: 0.4061 - val_loss: 2.6596 - val_accuracy: 0.4306
    Epoch 30/100
    313/313 [==============================] - 206s 657ms/step - loss: 2.7216 - accuracy: 0.4094 - val_loss: 2.6233 - val_accuracy: 0.4387
    Epoch 31/100
    313/313 [==============================] - 206s 659ms/step - loss: 2.6900 - accuracy: 0.4180 - val_loss: 2.6645 - val_accuracy: 0.4285
    Epoch 32/100
    313/313 [==============================] - 208s 665ms/step - loss: 2.6889 - accuracy: 0.4209 - val_loss: 2.6517 - val_accuracy: 0.4375
    Epoch 33/100
    313/313 [==============================] - 208s 663ms/step - loss: 2.6753 - accuracy: 0.4250 - val_loss: 2.6290 - val_accuracy: 0.4412
    Epoch 34/100
    313/313 [==============================] - 207s 661ms/step - loss: 2.6633 - accuracy: 0.4258 - val_loss: 2.6775 - val_accuracy: 0.4343
    Epoch 35/100
    313/313 [==============================] - 206s 659ms/step - loss: 2.6590 - accuracy: 0.4294 - val_loss: 2.6186 - val_accuracy: 0.4476
    Epoch 36/100
    313/313 [==============================] - 203s 648ms/step - loss: 2.6499 - accuracy: 0.4333 - val_loss: 2.6863 - val_accuracy: 0.4331
    Epoch 37/100
    313/313 [==============================] - 203s 650ms/step - loss: 2.6330 - accuracy: 0.4353 - val_loss: 2.6558 - val_accuracy: 0.4371
    Epoch 38/100
    313/313 [==============================] - 215s 687ms/step - loss: 2.6423 - accuracy: 0.4360 - val_loss: 2.6549 - val_accuracy: 0.4440
    Epoch 39/100
    313/313 [==============================] - 209s 667ms/step - loss: 2.6335 - accuracy: 0.4376 - val_loss: 2.6252 - val_accuracy: 0.4500
    Epoch 40/100
    313/313 [==============================] - 210s 670ms/step - loss: 2.6087 - accuracy: 0.4435 - val_loss: 2.6231 - val_accuracy: 0.4509
    Epoch 41/100
    313/313 [==============================] - 212s 678ms/step - loss: 2.6159 - accuracy: 0.4438 - val_loss: 2.5850 - val_accuracy: 0.4593
    Epoch 42/100
    313/313 [==============================] - 212s 676ms/step - loss: 2.6072 - accuracy: 0.4462 - val_loss: 2.6499 - val_accuracy: 0.4525
    Epoch 43/100
    313/313 [==============================] - 214s 683ms/step - loss: 2.5924 - accuracy: 0.4494 - val_loss: 2.5875 - val_accuracy: 0.4626
    Epoch 44/100
    313/313 [==============================] - 221s 708ms/step - loss: 2.5913 - accuracy: 0.4536 - val_loss: 2.5980 - val_accuracy: 0.4629
    Epoch 45/100
    313/313 [==============================] - 217s 694ms/step - loss: 2.5888 - accuracy: 0.4536 - val_loss: 2.6493 - val_accuracy: 0.4509
    Epoch 46/100
    313/313 [==============================] - 208s 666ms/step - loss: 2.5755 - accuracy: 0.4574 - val_loss: 2.5705 - val_accuracy: 0.4664
    Epoch 47/100
    313/313 [==============================] - 208s 664ms/step - loss: 2.5606 - accuracy: 0.4619 - val_loss: 2.5949 - val_accuracy: 0.4680
    Epoch 48/100
    313/313 [==============================] - 207s 661ms/step - loss: 2.5575 - accuracy: 0.4625 - val_loss: 2.5751 - val_accuracy: 0.4675
    Epoch 49/100
    313/313 [==============================] - 208s 666ms/step - loss: 2.5490 - accuracy: 0.4664 - val_loss: 2.5789 - val_accuracy: 0.4688
    Epoch 50/100
    313/313 [==============================] - 214s 684ms/step - loss: 2.5450 - accuracy: 0.4681 - val_loss: 2.5829 - val_accuracy: 0.4710
    Epoch 51/100
    313/313 [==============================] - 210s 672ms/step - loss: 2.5516 - accuracy: 0.4679 - val_loss: 2.6019 - val_accuracy: 0.4646
    Epoch 52/100
    313/313 [==============================] - 208s 665ms/step - loss: 2.5342 - accuracy: 0.4722 - val_loss: 2.5803 - val_accuracy: 0.4711
    Epoch 53/100
    313/313 [==============================] - 210s 670ms/step - loss: 2.5240 - accuracy: 0.4769 - val_loss: 2.6094 - val_accuracy: 0.4671
    Epoch 54/100
    313/313 [==============================] - 216s 690ms/step - loss: 2.5329 - accuracy: 0.4773 - val_loss: 2.5970 - val_accuracy: 0.4669
    Epoch 55/100
    313/313 [==============================] - 205s 654ms/step - loss: 2.5151 - accuracy: 0.4758 - val_loss: 2.5773 - val_accuracy: 0.4738
    Epoch 56/100
    313/313 [==============================] - 205s 655ms/step - loss: 2.5101 - accuracy: 0.4802 - val_loss: 2.5739 - val_accuracy: 0.4814
    Epoch 57/100
    313/313 [==============================] - 209s 667ms/step - loss: 2.5243 - accuracy: 0.4805 - val_loss: 2.6056 - val_accuracy: 0.4748
    Epoch 58/100
    313/313 [==============================] - 206s 658ms/step - loss: 2.5112 - accuracy: 0.4836 - val_loss: 2.5718 - val_accuracy: 0.4793
    Epoch 59/100
    313/313 [==============================] - 211s 674ms/step - loss: 2.5108 - accuracy: 0.4819 - val_loss: 2.5729 - val_accuracy: 0.4833
    Epoch 60/100
    313/313 [==============================] - 210s 672ms/step - loss: 2.4873 - accuracy: 0.4931 - val_loss: 2.5855 - val_accuracy: 0.4808
    Epoch 61/100
    313/313 [==============================] - 203s 647ms/step - loss: 2.5049 - accuracy: 0.4864 - val_loss: 2.6091 - val_accuracy: 0.4752
    Epoch 62/100
    313/313 [==============================] - 202s 645ms/step - loss: 2.5051 - accuracy: 0.4881 - val_loss: 2.6188 - val_accuracy: 0.4805
    Epoch 63/100
    313/313 [==============================] - 202s 645ms/step - loss: 2.4867 - accuracy: 0.4925 - val_loss: 2.6077 - val_accuracy: 0.4800
    Epoch 64/100
    313/313 [==============================] - 202s 645ms/step - loss: 2.4722 - accuracy: 0.4954 - val_loss: 2.5745 - val_accuracy: 0.4873
    Epoch 65/100
    313/313 [==============================] - 202s 647ms/step - loss: 2.4758 - accuracy: 0.4932 - val_loss: 2.5739 - val_accuracy: 0.4837
    Epoch 66/100
    313/313 [==============================] - 202s 645ms/step - loss: 2.4853 - accuracy: 0.4948 - val_loss: 2.6288 - val_accuracy: 0.4796
    Epoch 67/100
    313/313 [==============================] - 203s 647ms/step - loss: 2.4716 - accuracy: 0.5003 - val_loss: 2.6097 - val_accuracy: 0.4849
    Epoch 68/100
    313/313 [==============================] - 202s 645ms/step - loss: 2.4611 - accuracy: 0.4993 - val_loss: 2.6464 - val_accuracy: 0.4698
    Epoch 69/100
    313/313 [==============================] - 202s 646ms/step - loss: 2.4929 - accuracy: 0.4951 - val_loss: 2.5970 - val_accuracy: 0.4902
    Epoch 70/100
    313/313 [==============================] - 202s 645ms/step - loss: 2.4579 - accuracy: 0.5038 - val_loss: 2.6003 - val_accuracy: 0.4866
    Epoch 71/100
    313/313 [==============================] - 202s 645ms/step - loss: 2.4561 - accuracy: 0.5056 - val_loss: 2.5892 - val_accuracy: 0.4887
    Epoch 72/100
    313/313 [==============================] - 203s 647ms/step - loss: 2.4521 - accuracy: 0.5072 - val_loss: 2.6144 - val_accuracy: 0.4834
    Epoch 73/100
    313/313 [==============================] - 202s 646ms/step - loss: 2.4607 - accuracy: 0.5084 - val_loss: 2.5972 - val_accuracy: 0.4858
    Epoch 74/100
    313/313 [==============================] - 202s 647ms/step - loss: 2.4365 - accuracy: 0.5130 - val_loss: 2.5956 - val_accuracy: 0.4910
    Epoch 75/100
    313/313 [==============================] - 203s 647ms/step - loss: 2.4572 - accuracy: 0.5073 - val_loss: 2.6183 - val_accuracy: 0.4880
    Epoch 76/100
    313/313 [==============================] - 202s 645ms/step - loss: 2.4454 - accuracy: 0.5088 - val_loss: 2.5793 - val_accuracy: 0.4909
    Epoch 77/100
    313/313 [==============================] - 201s 643ms/step - loss: 2.4402 - accuracy: 0.5122 - val_loss: 2.6346 - val_accuracy: 0.4807
    Epoch 78/100
    313/313 [==============================] - 202s 645ms/step - loss: 2.4421 - accuracy: 0.5113 - val_loss: 2.6290 - val_accuracy: 0.4882
    Epoch 79/100
    313/313 [==============================] - 203s 647ms/step - loss: 2.4386 - accuracy: 0.5151 - val_loss: 2.5984 - val_accuracy: 0.4930
    Epoch 80/100
    313/313 [==============================] - 202s 644ms/step - loss: 2.4197 - accuracy: 0.5204 - val_loss: 2.5778 - val_accuracy: 0.4973
    Epoch 81/100
    313/313 [==============================] - 202s 645ms/step - loss: 2.4183 - accuracy: 0.5196 - val_loss: 2.5941 - val_accuracy: 0.4935
    Epoch 82/100
    313/313 [==============================] - 202s 645ms/step - loss: 2.4381 - accuracy: 0.5149 - val_loss: 2.6002 - val_accuracy: 0.4960
    Epoch 83/100
    313/313 [==============================] - 202s 646ms/step - loss: 2.4195 - accuracy: 0.5260 - val_loss: 2.6008 - val_accuracy: 0.4945
    Epoch 84/100
    313/313 [==============================] - 201s 644ms/step - loss: 2.4186 - accuracy: 0.5192 - val_loss: 2.5996 - val_accuracy: 0.4955
    Epoch 85/100
    313/313 [==============================] - 202s 646ms/step - loss: 2.4186 - accuracy: 0.5235 - val_loss: 2.6538 - val_accuracy: 0.4845
    Epoch 86/100
    313/313 [==============================] - 202s 647ms/step - loss: 2.4179 - accuracy: 0.5238 - val_loss: 2.6019 - val_accuracy: 0.4939
    Epoch 87/100
    313/313 [==============================] - 202s 644ms/step - loss: 2.4227 - accuracy: 0.5259 - val_loss: 2.6252 - val_accuracy: 0.4970
    Epoch 88/100
    313/313 [==============================] - 201s 643ms/step - loss: 2.4054 - accuracy: 0.5278 - val_loss: 2.6444 - val_accuracy: 0.4856
    Epoch 89/100
    313/313 [==============================] - 205s 656ms/step - loss: 2.4065 - accuracy: 0.5268 - val_loss: 2.6172 - val_accuracy: 0.4920
    Epoch 90/100
    313/313 [==============================] - 210s 671ms/step - loss: 2.4085 - accuracy: 0.5268 - val_loss: 2.6249 - val_accuracy: 0.4942
    Epoch 91/100
    313/313 [==============================] - 206s 659ms/step - loss: 2.3973 - accuracy: 0.5322 - val_loss: 2.6720 - val_accuracy: 0.4857
    Epoch 92/100
    313/313 [==============================] - 209s 666ms/step - loss: 2.4248 - accuracy: 0.5225 - val_loss: 2.6643 - val_accuracy: 0.4908
    Epoch 93/100
    313/313 [==============================] - 209s 666ms/step - loss: 2.4049 - accuracy: 0.5253 - val_loss: 2.6322 - val_accuracy: 0.4939
    Epoch 94/100
    313/313 [==============================] - 207s 662ms/step - loss: 2.3933 - accuracy: 0.5325 - val_loss: 2.6374 - val_accuracy: 0.4966
    Epoch 95/100
    313/313 [==============================] - 208s 666ms/step - loss: 2.4094 - accuracy: 0.5298 - val_loss: 2.6712 - val_accuracy: 0.4921
    Epoch 96/100
    313/313 [==============================] - 207s 663ms/step - loss: 2.3957 - accuracy: 0.5317 - val_loss: 2.6753 - val_accuracy: 0.4919
    Epoch 97/100
    313/313 [==============================] - 207s 661ms/step - loss: 2.3925 - accuracy: 0.5299 - val_loss: 2.6183 - val_accuracy: 0.5014
    Epoch 98/100
    313/313 [==============================] - 209s 667ms/step - loss: 2.3924 - accuracy: 0.5358 - val_loss: 2.6331 - val_accuracy: 0.5045
    Epoch 99/100
    313/313 [==============================] - 207s 661ms/step - loss: 2.3932 - accuracy: 0.5358 - val_loss: 2.6120 - val_accuracy: 0.5012
    Epoch 100/100
    313/313 [==============================] - 206s 657ms/step - loss: 2.3927 - accuracy: 0.5350 - val_loss: 2.6284 - val_accuracy: 0.4970
    Test loss: 2.5880990028381348
    Test accuracy: 0.5027999877929688
    
     
    
    


    
![png](output_187_1.png)
    



    
![png](output_187_2.png)
    


##### CNN 2 - Model 6


```python
CNN_model6_class = Sequential()

# Create simple CNN model architecture with Pooling for dimensionality reduction 
# and Dropout to reduce overfitting
CNN_model6_class.add(Conv2D(32, kernel_size=(3,3), activation = 'elu', input_shape = (32,32,3), kernel_regularizer=l2(0.0005))) 
CNN_model6_class.add(MaxPooling2D(pool_size=(2, 2), padding='same'))

CNN_model6_class.add(Conv2D(64, kernel_size=(3,3), activation = 'elu', padding='same', kernel_regularizer=l2(0.0005)))
CNN_model6_class.add(Conv2D(128, kernel_size=(3,3), activation = 'elu', padding='same', kernel_regularizer=l2(0.0005)))
CNN_model6_class.add(MaxPooling2D(pool_size=(2, 2), padding='same'))
CNN_model6_class.add(Dropout(0.1))

CNN_model6_class.add(Conv2D(128, kernel_size=(2,2), activation = 'elu', padding='same', kernel_regularizer=l2(0.0005)))
CNN_model6_class.add(Conv2D(256, kernel_size=(2,2), activation = 'elu', padding='same', kernel_regularizer=l2(0.0005)))
CNN_model6_class.add(MaxPooling2D(pool_size=(2, 2), padding='same'))
CNN_model6_class.add(Dropout(0.2))

CNN_model6_class.add(Conv2D(256, kernel_size=(1,1), activation = 'elu', padding='same', kernel_regularizer=l2(0.0005)))
CNN_model6_class.add(Conv2D(512, kernel_size=(1,1), activation = 'elu', padding='same', kernel_regularizer=l2(0.0005)))
CNN_model6_class.add(MaxPooling2D(pool_size=(2, 2), padding='same'))
CNN_model6_class.add(Dropout(0.3))

# Flatten the output of our convolutional layers
CNN_model6_class.add(Flatten())

# Add dense layers
CNN_model6_class.add(Dense(512, activation = 'elu'))
CNN_model6_class.add(Dense(256, activation = 'elu'))
CNN_model6_class.add(Dense(len(np.unique(y_train)), activation='softmax'))

# Print out a summary of the network
CNN_model6_class.summary()

# Compile the model with the desired loss function, optimizer, and metric(s) to track
CNN_model6_class.compile(loss = 'sparse_categorical_crossentropy', #cross entropy is for multi-class classification
                  optimizer = 'Adam',
                  metrics = ['accuracy'])

# Fit the model on the training data, defining desired batch_size & number of epochs,
# running validation after each batch
CNN6_class = CNN_model6_class.fit(X_train, y_train,
              batch_size = 128,
              epochs = 100,
              verbose = 1,
              validation_split = 0.2)

test_loss_score(CNN_model6_class)
accuracy_loss_plots(CNN6_class)
confusion(CNN_model6_class)

save_format='h5'
CNN_model6_class.save('CNNmodels/CNN_model6_class.h5')
```

    Model: "sequential_29"
    _________________________________________________________________
    Layer (type)                 Output Shape              Param #   
    =================================================================
    conv2d_123 (Conv2D)          (None, 30, 30, 32)        896       
    _________________________________________________________________
    max_pooling2d_93 (MaxPooling (None, 15, 15, 32)        0         
    _________________________________________________________________
    conv2d_124 (Conv2D)          (None, 15, 15, 64)        18496     
    _________________________________________________________________
    conv2d_125 (Conv2D)          (None, 15, 15, 128)       73856     
    _________________________________________________________________
    max_pooling2d_94 (MaxPooling (None, 8, 8, 128)         0         
    _________________________________________________________________
    dropout_81 (Dropout)         (None, 8, 8, 128)         0         
    _________________________________________________________________
    conv2d_126 (Conv2D)          (None, 8, 8, 128)         65664     
    _________________________________________________________________
    conv2d_127 (Conv2D)          (None, 8, 8, 256)         131328    
    _________________________________________________________________
    max_pooling2d_95 (MaxPooling (None, 4, 4, 256)         0         
    _________________________________________________________________
    dropout_82 (Dropout)         (None, 4, 4, 256)         0         
    _________________________________________________________________
    conv2d_128 (Conv2D)          (None, 4, 4, 256)         65792     
    _________________________________________________________________
    conv2d_129 (Conv2D)          (None, 4, 4, 512)         131584    
    _________________________________________________________________
    max_pooling2d_96 (MaxPooling (None, 2, 2, 512)         0         
    _________________________________________________________________
    dropout_83 (Dropout)         (None, 2, 2, 512)         0         
    _________________________________________________________________
    flatten_27 (Flatten)         (None, 2048)              0         
    _________________________________________________________________
    dense_88 (Dense)             (None, 512)               1049088   
    _________________________________________________________________
    dense_89 (Dense)             (None, 256)               131328    
    _________________________________________________________________
    dense_90 (Dense)             (None, 100)               25700     
    =================================================================
    Total params: 1,693,732
    Trainable params: 1,693,732
    Non-trainable params: 0
    _________________________________________________________________
    Epoch 1/100
    313/313 [==============================] - 68s 216ms/step - loss: 4.0971 - accuracy: 0.1376 - val_loss: 3.5643 - val_accuracy: 0.2136
    Epoch 2/100
    313/313 [==============================] - 72s 230ms/step - loss: 3.2878 - accuracy: 0.2626 - val_loss: 3.0593 - val_accuracy: 0.2991
    Epoch 3/100
    313/313 [==============================] - 71s 228ms/step - loss: 2.9311 - accuracy: 0.3224 - val_loss: 2.8823 - val_accuracy: 0.3396
    Epoch 4/100
    313/313 [==============================] - 70s 224ms/step - loss: 2.6839 - accuracy: 0.3722 - val_loss: 2.7384 - val_accuracy: 0.3669
    Epoch 5/100
    313/313 [==============================] - 73s 233ms/step - loss: 2.5201 - accuracy: 0.4067 - val_loss: 2.6549 - val_accuracy: 0.3851
    Epoch 6/100
    313/313 [==============================] - 72s 231ms/step - loss: 2.3845 - accuracy: 0.4331 - val_loss: 2.5712 - val_accuracy: 0.4015
    Epoch 7/100
    313/313 [==============================] - 72s 230ms/step - loss: 2.2518 - accuracy: 0.4622 - val_loss: 2.5549 - val_accuracy: 0.4110
    Epoch 8/100
    313/313 [==============================] - 70s 225ms/step - loss: 2.1345 - accuracy: 0.4889 - val_loss: 2.5037 - val_accuracy: 0.4301
    Epoch 9/100
    313/313 [==============================] - 70s 224ms/step - loss: 2.0303 - accuracy: 0.5171 - val_loss: 2.4739 - val_accuracy: 0.4369
    Epoch 10/100
    313/313 [==============================] - 71s 226ms/step - loss: 1.9324 - accuracy: 0.5405 - val_loss: 2.4761 - val_accuracy: 0.4470
    Epoch 11/100
    313/313 [==============================] - 70s 224ms/step - loss: 1.8183 - accuracy: 0.5688 - val_loss: 2.5539 - val_accuracy: 0.4385
    Epoch 12/100
    313/313 [==============================] - 71s 226ms/step - loss: 1.7457 - accuracy: 0.5851 - val_loss: 2.5024 - val_accuracy: 0.4555
    Epoch 13/100
    313/313 [==============================] - 71s 227ms/step - loss: 1.6327 - accuracy: 0.6150 - val_loss: 2.5542 - val_accuracy: 0.4496
    Epoch 14/100
    313/313 [==============================] - 71s 225ms/step - loss: 1.5547 - accuracy: 0.6334 - val_loss: 2.6178 - val_accuracy: 0.4513
    Epoch 15/100
    313/313 [==============================] - 71s 226ms/step - loss: 1.4839 - accuracy: 0.6506 - val_loss: 2.7212 - val_accuracy: 0.4503
    Epoch 16/100
    313/313 [==============================] - 70s 225ms/step - loss: 1.4039 - accuracy: 0.6754 - val_loss: 2.7733 - val_accuracy: 0.4418
    Epoch 17/100
    313/313 [==============================] - 71s 226ms/step - loss: 1.3348 - accuracy: 0.6928 - val_loss: 2.7462 - val_accuracy: 0.4558
    Epoch 18/100
    313/313 [==============================] - 70s 223ms/step - loss: 1.2722 - accuracy: 0.7079 - val_loss: 2.8851 - val_accuracy: 0.4519
    Epoch 19/100
    313/313 [==============================] - 71s 225ms/step - loss: 1.2025 - accuracy: 0.7319 - val_loss: 2.8823 - val_accuracy: 0.4565
    Epoch 20/100
    313/313 [==============================] - 71s 228ms/step - loss: 1.1454 - accuracy: 0.7460 - val_loss: 2.9561 - val_accuracy: 0.4596
    Epoch 21/100
    313/313 [==============================] - 69s 222ms/step - loss: 1.1031 - accuracy: 0.7596 - val_loss: 3.0291 - val_accuracy: 0.4531
    Epoch 22/100
    313/313 [==============================] - 71s 228ms/step - loss: 1.0625 - accuracy: 0.7695 - val_loss: 3.0708 - val_accuracy: 0.4534
    Epoch 23/100
    313/313 [==============================] - 72s 228ms/step - loss: 1.0338 - accuracy: 0.7791 - val_loss: 3.2489 - val_accuracy: 0.4331
    Epoch 24/100
    313/313 [==============================] - 72s 231ms/step - loss: 1.0057 - accuracy: 0.7886 - val_loss: 3.2109 - val_accuracy: 0.4461
    Epoch 25/100
    313/313 [==============================] - 72s 229ms/step - loss: 0.9590 - accuracy: 0.8014 - val_loss: 3.3319 - val_accuracy: 0.4427
    Epoch 26/100
    313/313 [==============================] - 70s 223ms/step - loss: 0.9367 - accuracy: 0.8074 - val_loss: 3.4676 - val_accuracy: 0.4350
    Epoch 27/100
    313/313 [==============================] - 70s 224ms/step - loss: 0.9044 - accuracy: 0.8180 - val_loss: 3.3543 - val_accuracy: 0.4444
    Epoch 28/100
    313/313 [==============================] - 71s 226ms/step - loss: 0.8934 - accuracy: 0.8216 - val_loss: 3.4633 - val_accuracy: 0.4407
    Epoch 29/100
    313/313 [==============================] - 72s 230ms/step - loss: 0.8679 - accuracy: 0.8272 - val_loss: 3.4792 - val_accuracy: 0.4440
    Epoch 30/100
    313/313 [==============================] - 72s 229ms/step - loss: 0.8467 - accuracy: 0.8341 - val_loss: 3.5221 - val_accuracy: 0.4501
    Epoch 31/100
    313/313 [==============================] - 70s 225ms/step - loss: 0.8307 - accuracy: 0.8400 - val_loss: 3.6061 - val_accuracy: 0.4388
    Epoch 32/100
    313/313 [==============================] - 70s 225ms/step - loss: 0.8297 - accuracy: 0.8393 - val_loss: 3.6143 - val_accuracy: 0.4493
    Epoch 33/100
    313/313 [==============================] - 70s 223ms/step - loss: 0.8034 - accuracy: 0.8480 - val_loss: 3.6439 - val_accuracy: 0.4397
    Epoch 34/100
    313/313 [==============================] - 71s 227ms/step - loss: 0.7937 - accuracy: 0.8504 - val_loss: 3.7125 - val_accuracy: 0.4395
    Epoch 35/100
    313/313 [==============================] - 70s 224ms/step - loss: 0.7938 - accuracy: 0.8499 - val_loss: 3.7005 - val_accuracy: 0.4457
    Epoch 36/100
    313/313 [==============================] - 69s 222ms/step - loss: 0.7712 - accuracy: 0.8587 - val_loss: 3.8340 - val_accuracy: 0.4448
    Epoch 37/100
    313/313 [==============================] - 71s 225ms/step - loss: 0.7840 - accuracy: 0.8515 - val_loss: 3.7844 - val_accuracy: 0.4318
    Epoch 38/100
    313/313 [==============================] - 71s 226ms/step - loss: 0.7558 - accuracy: 0.8618 - val_loss: 3.9590 - val_accuracy: 0.4414
    Epoch 39/100
    313/313 [==============================] - 70s 225ms/step - loss: 0.7403 - accuracy: 0.8664 - val_loss: 3.8908 - val_accuracy: 0.4438
    Epoch 40/100
    313/313 [==============================] - 72s 229ms/step - loss: 0.7582 - accuracy: 0.8592 - val_loss: 3.9513 - val_accuracy: 0.4409
    Epoch 41/100
    313/313 [==============================] - 70s 223ms/step - loss: 0.7399 - accuracy: 0.8646 - val_loss: 3.9114 - val_accuracy: 0.4499
    Epoch 42/100
    313/313 [==============================] - 71s 228ms/step - loss: 0.7392 - accuracy: 0.8644 - val_loss: 4.0242 - val_accuracy: 0.4401
    Epoch 43/100
    313/313 [==============================] - 71s 228ms/step - loss: 0.7208 - accuracy: 0.8708 - val_loss: 3.9849 - val_accuracy: 0.4432
    Epoch 44/100
    313/313 [==============================] - 70s 224ms/step - loss: 0.7231 - accuracy: 0.8698 - val_loss: 4.0686 - val_accuracy: 0.4456
    Epoch 45/100
    313/313 [==============================] - 71s 227ms/step - loss: 0.7161 - accuracy: 0.8738 - val_loss: 3.9256 - val_accuracy: 0.4418
    Epoch 46/100
    313/313 [==============================] - 73s 234ms/step - loss: 0.7053 - accuracy: 0.8754 - val_loss: 4.0024 - val_accuracy: 0.4411
    Epoch 47/100
    313/313 [==============================] - 71s 225ms/step - loss: 0.7047 - accuracy: 0.8755 - val_loss: 4.1359 - val_accuracy: 0.4478
    Epoch 48/100
    313/313 [==============================] - 71s 226ms/step - loss: 0.6805 - accuracy: 0.8832 - val_loss: 4.1087 - val_accuracy: 0.4456
    Epoch 49/100
    313/313 [==============================] - 67s 215ms/step - loss: 0.6885 - accuracy: 0.8812 - val_loss: 4.1382 - val_accuracy: 0.4398
    Epoch 50/100
    313/313 [==============================] - 68s 218ms/step - loss: 0.7007 - accuracy: 0.8767 - val_loss: 4.1533 - val_accuracy: 0.4392
    Epoch 51/100
    313/313 [==============================] - 68s 216ms/step - loss: 0.6850 - accuracy: 0.8812 - val_loss: 4.3169 - val_accuracy: 0.4317
    Epoch 52/100
    313/313 [==============================] - 67s 215ms/step - loss: 0.7029 - accuracy: 0.8761 - val_loss: 4.2951 - val_accuracy: 0.4375
    Epoch 53/100
    313/313 [==============================] - 68s 217ms/step - loss: 0.6974 - accuracy: 0.8798 - val_loss: 4.1738 - val_accuracy: 0.4462
    Epoch 54/100
    313/313 [==============================] - 68s 216ms/step - loss: 0.6526 - accuracy: 0.8902 - val_loss: 4.3311 - val_accuracy: 0.4324
    Epoch 55/100
    313/313 [==============================] - 67s 216ms/step - loss: 0.6460 - accuracy: 0.8939 - val_loss: 4.3340 - val_accuracy: 0.4347
    Epoch 56/100
    313/313 [==============================] - 68s 218ms/step - loss: 0.6798 - accuracy: 0.8831 - val_loss: 4.3743 - val_accuracy: 0.4338
    Epoch 57/100
    313/313 [==============================] - 68s 217ms/step - loss: 0.6861 - accuracy: 0.8816 - val_loss: 4.3331 - val_accuracy: 0.4279
    Epoch 58/100
    313/313 [==============================] - 68s 218ms/step - loss: 0.6813 - accuracy: 0.8827 - val_loss: 4.3271 - val_accuracy: 0.4333
    Epoch 59/100
    313/313 [==============================] - 68s 218ms/step - loss: 0.6681 - accuracy: 0.8860 - val_loss: 4.3331 - val_accuracy: 0.4375
    Epoch 60/100
    313/313 [==============================] - 70s 225ms/step - loss: 0.6408 - accuracy: 0.8955 - val_loss: 4.2299 - val_accuracy: 0.4432
    Epoch 61/100
    313/313 [==============================] - 71s 225ms/step - loss: 0.6462 - accuracy: 0.8932 - val_loss: 4.3705 - val_accuracy: 0.4425
    Epoch 62/100
    313/313 [==============================] - 70s 225ms/step - loss: 0.6747 - accuracy: 0.8863 - val_loss: 4.3318 - val_accuracy: 0.4345
    Epoch 63/100
    313/313 [==============================] - 72s 230ms/step - loss: 0.6290 - accuracy: 0.8972 - val_loss: 4.4795 - val_accuracy: 0.4396
    Epoch 64/100
    313/313 [==============================] - 70s 225ms/step - loss: 0.6638 - accuracy: 0.8882 - val_loss: 4.4653 - val_accuracy: 0.4331
    Epoch 65/100
    313/313 [==============================] - 73s 234ms/step - loss: 0.6564 - accuracy: 0.8906 - val_loss: 4.4120 - val_accuracy: 0.4335
    Epoch 66/100
    313/313 [==============================] - 71s 227ms/step - loss: 0.6206 - accuracy: 0.8985 - val_loss: 4.6692 - val_accuracy: 0.4417
    Epoch 67/100
    313/313 [==============================] - 71s 226ms/step - loss: 0.6293 - accuracy: 0.8978 - val_loss: 4.4038 - val_accuracy: 0.4338
    Epoch 68/100
    313/313 [==============================] - 70s 223ms/step - loss: 0.6224 - accuracy: 0.8981 - val_loss: 4.4906 - val_accuracy: 0.4414
    Epoch 69/100
    313/313 [==============================] - 69s 219ms/step - loss: 0.6298 - accuracy: 0.8971 - val_loss: 4.4970 - val_accuracy: 0.4368
    Epoch 70/100
    313/313 [==============================] - 69s 221ms/step - loss: 0.6484 - accuracy: 0.8905 - val_loss: 4.4635 - val_accuracy: 0.4409
    Epoch 71/100
    313/313 [==============================] - 70s 223ms/step - loss: 0.6347 - accuracy: 0.8938 - val_loss: 4.6525 - val_accuracy: 0.4333
    Epoch 72/100
    313/313 [==============================] - 70s 225ms/step - loss: 0.6459 - accuracy: 0.8933 - val_loss: 4.4017 - val_accuracy: 0.4420
    Epoch 73/100
    313/313 [==============================] - 71s 227ms/step - loss: 0.6210 - accuracy: 0.9004 - val_loss: 4.4677 - val_accuracy: 0.4264
    Epoch 74/100
    313/313 [==============================] - 70s 224ms/step - loss: 0.6037 - accuracy: 0.9047 - val_loss: 4.7555 - val_accuracy: 0.4365
    Epoch 75/100
    313/313 [==============================] - 71s 226ms/step - loss: 0.6191 - accuracy: 0.9013 - val_loss: 4.6327 - val_accuracy: 0.4383
    Epoch 76/100
    313/313 [==============================] - 70s 225ms/step - loss: 0.6219 - accuracy: 0.8975 - val_loss: 4.4789 - val_accuracy: 0.4421
    Epoch 77/100
    313/313 [==============================] - 71s 227ms/step - loss: 0.6196 - accuracy: 0.8984 - val_loss: 4.7107 - val_accuracy: 0.4312
    Epoch 78/100
    313/313 [==============================] - 71s 228ms/step - loss: 0.6131 - accuracy: 0.8995 - val_loss: 4.6926 - val_accuracy: 0.4294
    Epoch 79/100
    313/313 [==============================] - 70s 225ms/step - loss: 0.6206 - accuracy: 0.8994 - val_loss: 4.8034 - val_accuracy: 0.4286
    Epoch 80/100
    313/313 [==============================] - 72s 229ms/step - loss: 0.6295 - accuracy: 0.8969 - val_loss: 4.7847 - val_accuracy: 0.4332
    Epoch 81/100
    313/313 [==============================] - 70s 223ms/step - loss: 0.6141 - accuracy: 0.9023 - val_loss: 4.7077 - val_accuracy: 0.4358
    Epoch 82/100
    313/313 [==============================] - 69s 220ms/step - loss: 0.6137 - accuracy: 0.9024 - val_loss: 4.7064 - val_accuracy: 0.4359
    Epoch 83/100
    313/313 [==============================] - 71s 227ms/step - loss: 0.5971 - accuracy: 0.9063 - val_loss: 4.8075 - val_accuracy: 0.4345
    Epoch 84/100
    313/313 [==============================] - 72s 229ms/step - loss: 0.6224 - accuracy: 0.8995 - val_loss: 4.8352 - val_accuracy: 0.4370
    Epoch 85/100
    313/313 [==============================] - 72s 230ms/step - loss: 0.6095 - accuracy: 0.9043 - val_loss: 4.6860 - val_accuracy: 0.4365
    Epoch 86/100
    313/313 [==============================] - 70s 224ms/step - loss: 0.6076 - accuracy: 0.9035 - val_loss: 4.7063 - val_accuracy: 0.4350
    Epoch 87/100
    313/313 [==============================] - 71s 227ms/step - loss: 0.6232 - accuracy: 0.9004 - val_loss: 4.7827 - val_accuracy: 0.4333
    Epoch 88/100
    313/313 [==============================] - 71s 227ms/step - loss: 0.6100 - accuracy: 0.9031 - val_loss: 4.7959 - val_accuracy: 0.4321
    Epoch 89/100
    313/313 [==============================] - 72s 231ms/step - loss: 0.6110 - accuracy: 0.9051 - val_loss: 4.6300 - val_accuracy: 0.4268
    Epoch 90/100
    313/313 [==============================] - 71s 228ms/step - loss: 0.6137 - accuracy: 0.9021 - val_loss: 4.7417 - val_accuracy: 0.4400
    Epoch 91/100
    313/313 [==============================] - 70s 223ms/step - loss: 0.5990 - accuracy: 0.9066 - val_loss: 4.8018 - val_accuracy: 0.4407
    Epoch 92/100
    313/313 [==============================] - 72s 231ms/step - loss: 0.5978 - accuracy: 0.9071 - val_loss: 4.7216 - val_accuracy: 0.4309
    Epoch 93/100
    313/313 [==============================] - 72s 231ms/step - loss: 0.5891 - accuracy: 0.9097 - val_loss: 4.7095 - val_accuracy: 0.4380
    Epoch 94/100
    313/313 [==============================] - 72s 232ms/step - loss: 0.6002 - accuracy: 0.9049 - val_loss: 4.9650 - val_accuracy: 0.4295
    Epoch 95/100
    313/313 [==============================] - 71s 227ms/step - loss: 0.5914 - accuracy: 0.9073 - val_loss: 5.0054 - val_accuracy: 0.4285
    Epoch 96/100
    313/313 [==============================] - 71s 228ms/step - loss: 0.6167 - accuracy: 0.9024 - val_loss: 4.8723 - val_accuracy: 0.4249
    Epoch 97/100
    313/313 [==============================] - 71s 226ms/step - loss: 0.6216 - accuracy: 0.9011 - val_loss: 4.9801 - val_accuracy: 0.4387
    Epoch 98/100
    313/313 [==============================] - 70s 225ms/step - loss: 0.6162 - accuracy: 0.9026 - val_loss: 5.0224 - val_accuracy: 0.4293
    Epoch 99/100
    313/313 [==============================] - 69s 221ms/step - loss: 0.6084 - accuracy: 0.9050 - val_loss: 4.9644 - val_accuracy: 0.4348
    Epoch 100/100
    313/313 [==============================] - 69s 220ms/step - loss: 0.5851 - accuracy: 0.9115 - val_loss: 5.0359 - val_accuracy: 0.4310
    Test loss: 4.913743495941162
    Test accuracy: 0.43869999051094055
    
     
    
    


    
![png](output_189_1.png)
    



    
![png](output_189_2.png)
    


### Transfer Learning

##### ResNet - Model 1


```python
model = ResNet50V2(weights='imagenet',
                   include_top=False,
                   pooling='max',
                   input_shape=(32,32,3))

for layer in model.layers:
    layer.trainable = False
    
model.summary()

```

    Model: "resnet50v2"
    __________________________________________________________________________________________________
    Layer (type)                    Output Shape         Param #     Connected to                     
    ==================================================================================================
    input_1 (InputLayer)            [(None, 32, 32, 3)]  0                                            
    __________________________________________________________________________________________________
    conv1_pad (ZeroPadding2D)       (None, 38, 38, 3)    0           input_1[0][0]                    
    __________________________________________________________________________________________________
    conv1_conv (Conv2D)             (None, 16, 16, 64)   9472        conv1_pad[0][0]                  
    __________________________________________________________________________________________________
    pool1_pad (ZeroPadding2D)       (None, 18, 18, 64)   0           conv1_conv[0][0]                 
    __________________________________________________________________________________________________
    pool1_pool (MaxPooling2D)       (None, 8, 8, 64)     0           pool1_pad[0][0]                  
    __________________________________________________________________________________________________
    conv2_block1_preact_bn (BatchNo (None, 8, 8, 64)     256         pool1_pool[0][0]                 
    __________________________________________________________________________________________________
    conv2_block1_preact_relu (Activ (None, 8, 8, 64)     0           conv2_block1_preact_bn[0][0]     
    __________________________________________________________________________________________________
    conv2_block1_1_conv (Conv2D)    (None, 8, 8, 64)     4096        conv2_block1_preact_relu[0][0]   
    __________________________________________________________________________________________________
    conv2_block1_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block1_1_conv[0][0]        
    __________________________________________________________________________________________________
    conv2_block1_1_relu (Activation (None, 8, 8, 64)     0           conv2_block1_1_bn[0][0]          
    __________________________________________________________________________________________________
    conv2_block1_2_pad (ZeroPadding (None, 10, 10, 64)   0           conv2_block1_1_relu[0][0]        
    __________________________________________________________________________________________________
    conv2_block1_2_conv (Conv2D)    (None, 8, 8, 64)     36864       conv2_block1_2_pad[0][0]         
    __________________________________________________________________________________________________
    conv2_block1_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block1_2_conv[0][0]        
    __________________________________________________________________________________________________
    conv2_block1_2_relu (Activation (None, 8, 8, 64)     0           conv2_block1_2_bn[0][0]          
    __________________________________________________________________________________________________
    conv2_block1_0_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block1_preact_relu[0][0]   
    __________________________________________________________________________________________________
    conv2_block1_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block1_2_relu[0][0]        
    __________________________________________________________________________________________________
    conv2_block1_out (Add)          (None, 8, 8, 256)    0           conv2_block1_0_conv[0][0]        
                                                                     conv2_block1_3_conv[0][0]        
    __________________________________________________________________________________________________
    conv2_block2_preact_bn (BatchNo (None, 8, 8, 256)    1024        conv2_block1_out[0][0]           
    __________________________________________________________________________________________________
    conv2_block2_preact_relu (Activ (None, 8, 8, 256)    0           conv2_block2_preact_bn[0][0]     
    __________________________________________________________________________________________________
    conv2_block2_1_conv (Conv2D)    (None, 8, 8, 64)     16384       conv2_block2_preact_relu[0][0]   
    __________________________________________________________________________________________________
    conv2_block2_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block2_1_conv[0][0]        
    __________________________________________________________________________________________________
    conv2_block2_1_relu (Activation (None, 8, 8, 64)     0           conv2_block2_1_bn[0][0]          
    __________________________________________________________________________________________________
    conv2_block2_2_pad (ZeroPadding (None, 10, 10, 64)   0           conv2_block2_1_relu[0][0]        
    __________________________________________________________________________________________________
    conv2_block2_2_conv (Conv2D)    (None, 8, 8, 64)     36864       conv2_block2_2_pad[0][0]         
    __________________________________________________________________________________________________
    conv2_block2_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block2_2_conv[0][0]        
    __________________________________________________________________________________________________
    conv2_block2_2_relu (Activation (None, 8, 8, 64)     0           conv2_block2_2_bn[0][0]          
    __________________________________________________________________________________________________
    conv2_block2_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block2_2_relu[0][0]        
    __________________________________________________________________________________________________
    conv2_block2_out (Add)          (None, 8, 8, 256)    0           conv2_block1_out[0][0]           
                                                                     conv2_block2_3_conv[0][0]        
    __________________________________________________________________________________________________
    conv2_block3_preact_bn (BatchNo (None, 8, 8, 256)    1024        conv2_block2_out[0][0]           
    __________________________________________________________________________________________________
    conv2_block3_preact_relu (Activ (None, 8, 8, 256)    0           conv2_block3_preact_bn[0][0]     
    __________________________________________________________________________________________________
    conv2_block3_1_conv (Conv2D)    (None, 8, 8, 64)     16384       conv2_block3_preact_relu[0][0]   
    __________________________________________________________________________________________________
    conv2_block3_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block3_1_conv[0][0]        
    __________________________________________________________________________________________________
    conv2_block3_1_relu (Activation (None, 8, 8, 64)     0           conv2_block3_1_bn[0][0]          
    __________________________________________________________________________________________________
    conv2_block3_2_pad (ZeroPadding (None, 10, 10, 64)   0           conv2_block3_1_relu[0][0]        
    __________________________________________________________________________________________________
    conv2_block3_2_conv (Conv2D)    (None, 4, 4, 64)     36864       conv2_block3_2_pad[0][0]         
    __________________________________________________________________________________________________
    conv2_block3_2_bn (BatchNormali (None, 4, 4, 64)     256         conv2_block3_2_conv[0][0]        
    __________________________________________________________________________________________________
    conv2_block3_2_relu (Activation (None, 4, 4, 64)     0           conv2_block3_2_bn[0][0]          
    __________________________________________________________________________________________________
    max_pooling2d_107 (MaxPooling2D (None, 4, 4, 256)    0           conv2_block2_out[0][0]           
    __________________________________________________________________________________________________
    conv2_block3_3_conv (Conv2D)    (None, 4, 4, 256)    16640       conv2_block3_2_relu[0][0]        
    __________________________________________________________________________________________________
    conv2_block3_out (Add)          (None, 4, 4, 256)    0           max_pooling2d_107[0][0]          
                                                                     conv2_block3_3_conv[0][0]        
    __________________________________________________________________________________________________
    conv3_block1_preact_bn (BatchNo (None, 4, 4, 256)    1024        conv2_block3_out[0][0]           
    __________________________________________________________________________________________________
    conv3_block1_preact_relu (Activ (None, 4, 4, 256)    0           conv3_block1_preact_bn[0][0]     
    __________________________________________________________________________________________________
    conv3_block1_1_conv (Conv2D)    (None, 4, 4, 128)    32768       conv3_block1_preact_relu[0][0]   
    __________________________________________________________________________________________________
    conv3_block1_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block1_1_conv[0][0]        
    __________________________________________________________________________________________________
    conv3_block1_1_relu (Activation (None, 4, 4, 128)    0           conv3_block1_1_bn[0][0]          
    __________________________________________________________________________________________________
    conv3_block1_2_pad (ZeroPadding (None, 6, 6, 128)    0           conv3_block1_1_relu[0][0]        
    __________________________________________________________________________________________________
    conv3_block1_2_conv (Conv2D)    (None, 4, 4, 128)    147456      conv3_block1_2_pad[0][0]         
    __________________________________________________________________________________________________
    conv3_block1_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block1_2_conv[0][0]        
    __________________________________________________________________________________________________
    conv3_block1_2_relu (Activation (None, 4, 4, 128)    0           conv3_block1_2_bn[0][0]          
    __________________________________________________________________________________________________
    conv3_block1_0_conv (Conv2D)    (None, 4, 4, 512)    131584      conv3_block1_preact_relu[0][0]   
    __________________________________________________________________________________________________
    conv3_block1_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block1_2_relu[0][0]        
    __________________________________________________________________________________________________
    conv3_block1_out (Add)          (None, 4, 4, 512)    0           conv3_block1_0_conv[0][0]        
                                                                     conv3_block1_3_conv[0][0]        
    __________________________________________________________________________________________________
    conv3_block2_preact_bn (BatchNo (None, 4, 4, 512)    2048        conv3_block1_out[0][0]           
    __________________________________________________________________________________________________
    conv3_block2_preact_relu (Activ (None, 4, 4, 512)    0           conv3_block2_preact_bn[0][0]     
    __________________________________________________________________________________________________
    conv3_block2_1_conv (Conv2D)    (None, 4, 4, 128)    65536       conv3_block2_preact_relu[0][0]   
    __________________________________________________________________________________________________
    conv3_block2_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block2_1_conv[0][0]        
    __________________________________________________________________________________________________
    conv3_block2_1_relu (Activation (None, 4, 4, 128)    0           conv3_block2_1_bn[0][0]          
    __________________________________________________________________________________________________
    conv3_block2_2_pad (ZeroPadding (None, 6, 6, 128)    0           conv3_block2_1_relu[0][0]        
    __________________________________________________________________________________________________
    conv3_block2_2_conv (Conv2D)    (None, 4, 4, 128)    147456      conv3_block2_2_pad[0][0]         
    __________________________________________________________________________________________________
    conv3_block2_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block2_2_conv[0][0]        
    __________________________________________________________________________________________________
    conv3_block2_2_relu (Activation (None, 4, 4, 128)    0           conv3_block2_2_bn[0][0]          
    __________________________________________________________________________________________________
    conv3_block2_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block2_2_relu[0][0]        
    __________________________________________________________________________________________________
    conv3_block2_out (Add)          (None, 4, 4, 512)    0           conv3_block1_out[0][0]           
                                                                     conv3_block2_3_conv[0][0]        
    __________________________________________________________________________________________________
    conv3_block3_preact_bn (BatchNo (None, 4, 4, 512)    2048        conv3_block2_out[0][0]           
    __________________________________________________________________________________________________
    conv3_block3_preact_relu (Activ (None, 4, 4, 512)    0           conv3_block3_preact_bn[0][0]     
    __________________________________________________________________________________________________
    conv3_block3_1_conv (Conv2D)    (None, 4, 4, 128)    65536       conv3_block3_preact_relu[0][0]   
    __________________________________________________________________________________________________
    conv3_block3_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block3_1_conv[0][0]        
    __________________________________________________________________________________________________
    conv3_block3_1_relu (Activation (None, 4, 4, 128)    0           conv3_block3_1_bn[0][0]          
    __________________________________________________________________________________________________
    conv3_block3_2_pad (ZeroPadding (None, 6, 6, 128)    0           conv3_block3_1_relu[0][0]        
    __________________________________________________________________________________________________
    conv3_block3_2_conv (Conv2D)    (None, 4, 4, 128)    147456      conv3_block3_2_pad[0][0]         
    __________________________________________________________________________________________________
    conv3_block3_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block3_2_conv[0][0]        
    __________________________________________________________________________________________________
    conv3_block3_2_relu (Activation (None, 4, 4, 128)    0           conv3_block3_2_bn[0][0]          
    __________________________________________________________________________________________________
    conv3_block3_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block3_2_relu[0][0]        
    __________________________________________________________________________________________________
    conv3_block3_out (Add)          (None, 4, 4, 512)    0           conv3_block2_out[0][0]           
                                                                     conv3_block3_3_conv[0][0]        
    __________________________________________________________________________________________________
    conv3_block4_preact_bn (BatchNo (None, 4, 4, 512)    2048        conv3_block3_out[0][0]           
    __________________________________________________________________________________________________
    conv3_block4_preact_relu (Activ (None, 4, 4, 512)    0           conv3_block4_preact_bn[0][0]     
    __________________________________________________________________________________________________
    conv3_block4_1_conv (Conv2D)    (None, 4, 4, 128)    65536       conv3_block4_preact_relu[0][0]   
    __________________________________________________________________________________________________
    conv3_block4_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block4_1_conv[0][0]        
    __________________________________________________________________________________________________
    conv3_block4_1_relu (Activation (None, 4, 4, 128)    0           conv3_block4_1_bn[0][0]          
    __________________________________________________________________________________________________
    conv3_block4_2_pad (ZeroPadding (None, 6, 6, 128)    0           conv3_block4_1_relu[0][0]        
    __________________________________________________________________________________________________
    conv3_block4_2_conv (Conv2D)    (None, 2, 2, 128)    147456      conv3_block4_2_pad[0][0]         
    __________________________________________________________________________________________________
    conv3_block4_2_bn (BatchNormali (None, 2, 2, 128)    512         conv3_block4_2_conv[0][0]        
    __________________________________________________________________________________________________
    conv3_block4_2_relu (Activation (None, 2, 2, 128)    0           conv3_block4_2_bn[0][0]          
    __________________________________________________________________________________________________
    max_pooling2d_108 (MaxPooling2D (None, 2, 2, 512)    0           conv3_block3_out[0][0]           
    __________________________________________________________________________________________________
    conv3_block4_3_conv (Conv2D)    (None, 2, 2, 512)    66048       conv3_block4_2_relu[0][0]        
    __________________________________________________________________________________________________
    conv3_block4_out (Add)          (None, 2, 2, 512)    0           max_pooling2d_108[0][0]          
                                                                     conv3_block4_3_conv[0][0]        
    __________________________________________________________________________________________________
    conv4_block1_preact_bn (BatchNo (None, 2, 2, 512)    2048        conv3_block4_out[0][0]           
    __________________________________________________________________________________________________
    conv4_block1_preact_relu (Activ (None, 2, 2, 512)    0           conv4_block1_preact_bn[0][0]     
    __________________________________________________________________________________________________
    conv4_block1_1_conv (Conv2D)    (None, 2, 2, 256)    131072      conv4_block1_preact_relu[0][0]   
    __________________________________________________________________________________________________
    conv4_block1_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block1_1_conv[0][0]        
    __________________________________________________________________________________________________
    conv4_block1_1_relu (Activation (None, 2, 2, 256)    0           conv4_block1_1_bn[0][0]          
    __________________________________________________________________________________________________
    conv4_block1_2_pad (ZeroPadding (None, 4, 4, 256)    0           conv4_block1_1_relu[0][0]        
    __________________________________________________________________________________________________
    conv4_block1_2_conv (Conv2D)    (None, 2, 2, 256)    589824      conv4_block1_2_pad[0][0]         
    __________________________________________________________________________________________________
    conv4_block1_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block1_2_conv[0][0]        
    __________________________________________________________________________________________________
    conv4_block1_2_relu (Activation (None, 2, 2, 256)    0           conv4_block1_2_bn[0][0]          
    __________________________________________________________________________________________________
    conv4_block1_0_conv (Conv2D)    (None, 2, 2, 1024)   525312      conv4_block1_preact_relu[0][0]   
    __________________________________________________________________________________________________
    conv4_block1_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block1_2_relu[0][0]        
    __________________________________________________________________________________________________
    conv4_block1_out (Add)          (None, 2, 2, 1024)   0           conv4_block1_0_conv[0][0]        
                                                                     conv4_block1_3_conv[0][0]        
    __________________________________________________________________________________________________
    conv4_block2_preact_bn (BatchNo (None, 2, 2, 1024)   4096        conv4_block1_out[0][0]           
    __________________________________________________________________________________________________
    conv4_block2_preact_relu (Activ (None, 2, 2, 1024)   0           conv4_block2_preact_bn[0][0]     
    __________________________________________________________________________________________________
    conv4_block2_1_conv (Conv2D)    (None, 2, 2, 256)    262144      conv4_block2_preact_relu[0][0]   
    __________________________________________________________________________________________________
    conv4_block2_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block2_1_conv[0][0]        
    __________________________________________________________________________________________________
    conv4_block2_1_relu (Activation (None, 2, 2, 256)    0           conv4_block2_1_bn[0][0]          
    __________________________________________________________________________________________________
    conv4_block2_2_pad (ZeroPadding (None, 4, 4, 256)    0           conv4_block2_1_relu[0][0]        
    __________________________________________________________________________________________________
    conv4_block2_2_conv (Conv2D)    (None, 2, 2, 256)    589824      conv4_block2_2_pad[0][0]         
    __________________________________________________________________________________________________
    conv4_block2_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block2_2_conv[0][0]        
    __________________________________________________________________________________________________
    conv4_block2_2_relu (Activation (None, 2, 2, 256)    0           conv4_block2_2_bn[0][0]          
    __________________________________________________________________________________________________
    conv4_block2_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block2_2_relu[0][0]        
    __________________________________________________________________________________________________
    conv4_block2_out (Add)          (None, 2, 2, 1024)   0           conv4_block1_out[0][0]           
                                                                     conv4_block2_3_conv[0][0]        
    __________________________________________________________________________________________________
    conv4_block3_preact_bn (BatchNo (None, 2, 2, 1024)   4096        conv4_block2_out[0][0]           
    __________________________________________________________________________________________________
    conv4_block3_preact_relu (Activ (None, 2, 2, 1024)   0           conv4_block3_preact_bn[0][0]     
    __________________________________________________________________________________________________
    conv4_block3_1_conv (Conv2D)    (None, 2, 2, 256)    262144      conv4_block3_preact_relu[0][0]   
    __________________________________________________________________________________________________
    conv4_block3_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block3_1_conv[0][0]        
    __________________________________________________________________________________________________
    conv4_block3_1_relu (Activation (None, 2, 2, 256)    0           conv4_block3_1_bn[0][0]          
    __________________________________________________________________________________________________
    conv4_block3_2_pad (ZeroPadding (None, 4, 4, 256)    0           conv4_block3_1_relu[0][0]        
    __________________________________________________________________________________________________
    conv4_block3_2_conv (Conv2D)    (None, 2, 2, 256)    589824      conv4_block3_2_pad[0][0]         
    __________________________________________________________________________________________________
    conv4_block3_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block3_2_conv[0][0]        
    __________________________________________________________________________________________________
    conv4_block3_2_relu (Activation (None, 2, 2, 256)    0           conv4_block3_2_bn[0][0]          
    __________________________________________________________________________________________________
    conv4_block3_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block3_2_relu[0][0]        
    __________________________________________________________________________________________________
    conv4_block3_out (Add)          (None, 2, 2, 1024)   0           conv4_block2_out[0][0]           
                                                                     conv4_block3_3_conv[0][0]        
    __________________________________________________________________________________________________
    conv4_block4_preact_bn (BatchNo (None, 2, 2, 1024)   4096        conv4_block3_out[0][0]           
    __________________________________________________________________________________________________
    conv4_block4_preact_relu (Activ (None, 2, 2, 1024)   0           conv4_block4_preact_bn[0][0]     
    __________________________________________________________________________________________________
    conv4_block4_1_conv (Conv2D)    (None, 2, 2, 256)    262144      conv4_block4_preact_relu[0][0]   
    __________________________________________________________________________________________________
    conv4_block4_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block4_1_conv[0][0]        
    __________________________________________________________________________________________________
    conv4_block4_1_relu (Activation (None, 2, 2, 256)    0           conv4_block4_1_bn[0][0]          
    __________________________________________________________________________________________________
    conv4_block4_2_pad (ZeroPadding (None, 4, 4, 256)    0           conv4_block4_1_relu[0][0]        
    __________________________________________________________________________________________________
    conv4_block4_2_conv (Conv2D)    (None, 2, 2, 256)    589824      conv4_block4_2_pad[0][0]         
    __________________________________________________________________________________________________
    conv4_block4_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block4_2_conv[0][0]        
    __________________________________________________________________________________________________
    conv4_block4_2_relu (Activation (None, 2, 2, 256)    0           conv4_block4_2_bn[0][0]          
    __________________________________________________________________________________________________
    conv4_block4_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block4_2_relu[0][0]        
    __________________________________________________________________________________________________
    conv4_block4_out (Add)          (None, 2, 2, 1024)   0           conv4_block3_out[0][0]           
                                                                     conv4_block4_3_conv[0][0]        
    __________________________________________________________________________________________________
    conv4_block5_preact_bn (BatchNo (None, 2, 2, 1024)   4096        conv4_block4_out[0][0]           
    __________________________________________________________________________________________________
    conv4_block5_preact_relu (Activ (None, 2, 2, 1024)   0           conv4_block5_preact_bn[0][0]     
    __________________________________________________________________________________________________
    conv4_block5_1_conv (Conv2D)    (None, 2, 2, 256)    262144      conv4_block5_preact_relu[0][0]   
    __________________________________________________________________________________________________
    conv4_block5_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block5_1_conv[0][0]        
    __________________________________________________________________________________________________
    conv4_block5_1_relu (Activation (None, 2, 2, 256)    0           conv4_block5_1_bn[0][0]          
    __________________________________________________________________________________________________
    conv4_block5_2_pad (ZeroPadding (None, 4, 4, 256)    0           conv4_block5_1_relu[0][0]        
    __________________________________________________________________________________________________
    conv4_block5_2_conv (Conv2D)    (None, 2, 2, 256)    589824      conv4_block5_2_pad[0][0]         
    __________________________________________________________________________________________________
    conv4_block5_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block5_2_conv[0][0]        
    __________________________________________________________________________________________________
    conv4_block5_2_relu (Activation (None, 2, 2, 256)    0           conv4_block5_2_bn[0][0]          
    __________________________________________________________________________________________________
    conv4_block5_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block5_2_relu[0][0]        
    __________________________________________________________________________________________________
    conv4_block5_out (Add)          (None, 2, 2, 1024)   0           conv4_block4_out[0][0]           
                                                                     conv4_block5_3_conv[0][0]        
    __________________________________________________________________________________________________
    conv4_block6_preact_bn (BatchNo (None, 2, 2, 1024)   4096        conv4_block5_out[0][0]           
    __________________________________________________________________________________________________
    conv4_block6_preact_relu (Activ (None, 2, 2, 1024)   0           conv4_block6_preact_bn[0][0]     
    __________________________________________________________________________________________________
    conv4_block6_1_conv (Conv2D)    (None, 2, 2, 256)    262144      conv4_block6_preact_relu[0][0]   
    __________________________________________________________________________________________________
    conv4_block6_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block6_1_conv[0][0]        
    __________________________________________________________________________________________________
    conv4_block6_1_relu (Activation (None, 2, 2, 256)    0           conv4_block6_1_bn[0][0]          
    __________________________________________________________________________________________________
    conv4_block6_2_pad (ZeroPadding (None, 4, 4, 256)    0           conv4_block6_1_relu[0][0]        
    __________________________________________________________________________________________________
    conv4_block6_2_conv (Conv2D)    (None, 1, 1, 256)    589824      conv4_block6_2_pad[0][0]         
    __________________________________________________________________________________________________
    conv4_block6_2_bn (BatchNormali (None, 1, 1, 256)    1024        conv4_block6_2_conv[0][0]        
    __________________________________________________________________________________________________
    conv4_block6_2_relu (Activation (None, 1, 1, 256)    0           conv4_block6_2_bn[0][0]          
    __________________________________________________________________________________________________
    max_pooling2d_109 (MaxPooling2D (None, 1, 1, 1024)   0           conv4_block5_out[0][0]           
    __________________________________________________________________________________________________
    conv4_block6_3_conv (Conv2D)    (None, 1, 1, 1024)   263168      conv4_block6_2_relu[0][0]        
    __________________________________________________________________________________________________
    conv4_block6_out (Add)          (None, 1, 1, 1024)   0           max_pooling2d_109[0][0]          
                                                                     conv4_block6_3_conv[0][0]        
    __________________________________________________________________________________________________
    conv5_block1_preact_bn (BatchNo (None, 1, 1, 1024)   4096        conv4_block6_out[0][0]           
    __________________________________________________________________________________________________
    conv5_block1_preact_relu (Activ (None, 1, 1, 1024)   0           conv5_block1_preact_bn[0][0]     
    __________________________________________________________________________________________________
    conv5_block1_1_conv (Conv2D)    (None, 1, 1, 512)    524288      conv5_block1_preact_relu[0][0]   
    __________________________________________________________________________________________________
    conv5_block1_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block1_1_conv[0][0]        
    __________________________________________________________________________________________________
    conv5_block1_1_relu (Activation (None, 1, 1, 512)    0           conv5_block1_1_bn[0][0]          
    __________________________________________________________________________________________________
    conv5_block1_2_pad (ZeroPadding (None, 3, 3, 512)    0           conv5_block1_1_relu[0][0]        
    __________________________________________________________________________________________________
    conv5_block1_2_conv (Conv2D)    (None, 1, 1, 512)    2359296     conv5_block1_2_pad[0][0]         
    __________________________________________________________________________________________________
    conv5_block1_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block1_2_conv[0][0]        
    __________________________________________________________________________________________________
    conv5_block1_2_relu (Activation (None, 1, 1, 512)    0           conv5_block1_2_bn[0][0]          
    __________________________________________________________________________________________________
    conv5_block1_0_conv (Conv2D)    (None, 1, 1, 2048)   2099200     conv5_block1_preact_relu[0][0]   
    __________________________________________________________________________________________________
    conv5_block1_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block1_2_relu[0][0]        
    __________________________________________________________________________________________________
    conv5_block1_out (Add)          (None, 1, 1, 2048)   0           conv5_block1_0_conv[0][0]        
                                                                     conv5_block1_3_conv[0][0]        
    __________________________________________________________________________________________________
    conv5_block2_preact_bn (BatchNo (None, 1, 1, 2048)   8192        conv5_block1_out[0][0]           
    __________________________________________________________________________________________________
    conv5_block2_preact_relu (Activ (None, 1, 1, 2048)   0           conv5_block2_preact_bn[0][0]     
    __________________________________________________________________________________________________
    conv5_block2_1_conv (Conv2D)    (None, 1, 1, 512)    1048576     conv5_block2_preact_relu[0][0]   
    __________________________________________________________________________________________________
    conv5_block2_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block2_1_conv[0][0]        
    __________________________________________________________________________________________________
    conv5_block2_1_relu (Activation (None, 1, 1, 512)    0           conv5_block2_1_bn[0][0]          
    __________________________________________________________________________________________________
    conv5_block2_2_pad (ZeroPadding (None, 3, 3, 512)    0           conv5_block2_1_relu[0][0]        
    __________________________________________________________________________________________________
    conv5_block2_2_conv (Conv2D)    (None, 1, 1, 512)    2359296     conv5_block2_2_pad[0][0]         
    __________________________________________________________________________________________________
    conv5_block2_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block2_2_conv[0][0]        
    __________________________________________________________________________________________________
    conv5_block2_2_relu (Activation (None, 1, 1, 512)    0           conv5_block2_2_bn[0][0]          
    __________________________________________________________________________________________________
    conv5_block2_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block2_2_relu[0][0]        
    __________________________________________________________________________________________________
    conv5_block2_out (Add)          (None, 1, 1, 2048)   0           conv5_block1_out[0][0]           
                                                                     conv5_block2_3_conv[0][0]        
    __________________________________________________________________________________________________
    conv5_block3_preact_bn (BatchNo (None, 1, 1, 2048)   8192        conv5_block2_out[0][0]           
    __________________________________________________________________________________________________
    conv5_block3_preact_relu (Activ (None, 1, 1, 2048)   0           conv5_block3_preact_bn[0][0]     
    __________________________________________________________________________________________________
    conv5_block3_1_conv (Conv2D)    (None, 1, 1, 512)    1048576     conv5_block3_preact_relu[0][0]   
    __________________________________________________________________________________________________
    conv5_block3_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block3_1_conv[0][0]        
    __________________________________________________________________________________________________
    conv5_block3_1_relu (Activation (None, 1, 1, 512)    0           conv5_block3_1_bn[0][0]          
    __________________________________________________________________________________________________
    conv5_block3_2_pad (ZeroPadding (None, 3, 3, 512)    0           conv5_block3_1_relu[0][0]        
    __________________________________________________________________________________________________
    conv5_block3_2_conv (Conv2D)    (None, 1, 1, 512)    2359296     conv5_block3_2_pad[0][0]         
    __________________________________________________________________________________________________
    conv5_block3_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block3_2_conv[0][0]        
    __________________________________________________________________________________________________
    conv5_block3_2_relu (Activation (None, 1, 1, 512)    0           conv5_block3_2_bn[0][0]          
    __________________________________________________________________________________________________
    conv5_block3_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block3_2_relu[0][0]        
    __________________________________________________________________________________________________
    conv5_block3_out (Add)          (None, 1, 1, 2048)   0           conv5_block2_out[0][0]           
                                                                     conv5_block3_3_conv[0][0]        
    __________________________________________________________________________________________________
    post_bn (BatchNormalization)    (None, 1, 1, 2048)   8192        conv5_block3_out[0][0]           
    __________________________________________________________________________________________________
    post_relu (Activation)          (None, 1, 1, 2048)   0           post_bn[0][0]                    
    __________________________________________________________________________________________________
    max_pool (GlobalMaxPooling2D)   (None, 2048)         0           post_relu[0][0]                  
    ==================================================================================================
    Total params: 23,564,800
    Trainable params: 0
    Non-trainable params: 23,564,800
    __________________________________________________________________________________________________
    


```python
model = ResNet50V2(weights='imagenet',
                   include_top=False,
                   pooling='max',
                   input_shape=(32,32,3))
for layer in model.layers:
    layer.trainable = False

    
RNmodel1 = Sequential()

RNmodel1.add(model)
RNmodel1.add(Flatten())
RNmodel1.add(Dense(2048, activation= 'relu'))
RNmodel1.add(Dense(1024, activation= 'relu'))
RNmodel1.add(Dense(512, activation= 'relu'))
RNmodel1.add(Dense(len(np.unique(y_train)), activation='softmax'))

RNmodel1.compile(optimizer='Adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

RN1 = RNmodel1.fit(X_train, y_train,
        batch_size = 128,
          epochs=50,
          validation_split=0.2,
         callbacks=ES)

test_loss_score(RNmodel1)
accuracy_loss_plots(RN1)
confusion(RNmodel1)
save_format='h5'
RNmodel1.save('CNNmodels/RNmodel1.h5')
```

    Epoch 1/50
    313/313 [==============================] - 63s 201ms/step - loss: 2.5359 - accuracy: 0.2256 - val_loss: 2.4325 - val_accuracy: 0.2582
    Epoch 2/50
    313/313 [==============================] - 65s 208ms/step - loss: 2.2364 - accuracy: 0.3076 - val_loss: 2.3891 - val_accuracy: 0.2762
    Epoch 3/50
    313/313 [==============================] - 64s 205ms/step - loss: 1.9908 - accuracy: 0.3817 - val_loss: 2.4434 - val_accuracy: 0.2719
    Epoch 4/50
    313/313 [==============================] - 64s 205ms/step - loss: 1.7066 - accuracy: 0.4631 - val_loss: 2.6170 - val_accuracy: 0.2724
    Epoch 5/50
    313/313 [==============================] - 67s 213ms/step - loss: 1.3866 - accuracy: 0.5649 - val_loss: 2.9649 - val_accuracy: 0.2688
    Epoch 6/50
    313/313 [==============================] - 66s 212ms/step - loss: 1.0867 - accuracy: 0.6614 - val_loss: 3.4140 - val_accuracy: 0.2578
    Epoch 7/50
    313/313 [==============================] - 65s 207ms/step - loss: 0.8133 - accuracy: 0.7469 - val_loss: 4.0021 - val_accuracy: 0.2582
    Epoch 00007: early stopping
    Test loss: 3.9391226768493652
    Test accuracy: 0.259799987077713
    
     
    
    


    
![png](output_193_1.png)
    



    
![png](output_193_2.png)
    



    ---------------------------------------------------------------------------

    NameError                                 Traceback (most recent call last)

    <ipython-input-203-ffddd202676b> in <module>
         30 confusion(RNmodel1)
         31 save_format='h5'
    ---> 32 RN_model1.save('CNNmodels/RN_model1.h5')
    

    NameError: name 'RN_model1' is not defined


##### ResNet - Model 2


```python
RNmodel2 = Sequential()

RNmodel2.add(model)
RNmodel2.add(Flatten())
RNmodel2.add(Dense(2048, activation= 'relu'))
RNmodel2.add(Dense(1024, activation= 'relu'))
RNmodel2.add(Dense(len(np.unique(y_train)), activation='softmax'))

RNmodel2.compile(optimizer='Adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

RN2 = RNmodel2.fit(X_train, y_train,
        batch_size = 128,
          epochs=50,
          validation_split=0.2,
            callbacks = ES)

test_loss_score(RNmodel2)
accuracy_loss_plots(RN2)
confusion(RNmodel2)
save_format='h5'
RNmodel2.save('CNNmodels/RNmodel2.h5')
```

    Epoch 1/50
    313/313 [==============================] - 61s 194ms/step - loss: 2.5131 - accuracy: 0.2344 - val_loss: 2.3996 - val_accuracy: 0.2622
    Epoch 2/50
    313/313 [==============================] - 63s 202ms/step - loss: 2.1947 - accuracy: 0.3185 - val_loss: 2.3780 - val_accuracy: 0.2717
    Epoch 3/50
    313/313 [==============================] - 65s 209ms/step - loss: 1.9339 - accuracy: 0.3975 - val_loss: 2.4178 - val_accuracy: 0.2771
    Epoch 4/50
    313/313 [==============================] - 64s 206ms/step - loss: 1.6310 - accuracy: 0.4903 - val_loss: 2.6389 - val_accuracy: 0.2796
    Epoch 5/50
    313/313 [==============================] - 64s 205ms/step - loss: 1.3183 - accuracy: 0.5877 - val_loss: 2.9479 - val_accuracy: 0.2761
    Epoch 6/50
    313/313 [==============================] - 65s 206ms/step - loss: 1.0249 - accuracy: 0.6821 - val_loss: 3.4199 - val_accuracy: 0.2650
    Epoch 7/50
    313/313 [==============================] - 64s 205ms/step - loss: 0.7925 - accuracy: 0.7581 - val_loss: 3.8239 - val_accuracy: 0.2628
    Epoch 8/50
    313/313 [==============================] - 64s 205ms/step - loss: 0.6136 - accuracy: 0.8173 - val_loss: 4.2884 - val_accuracy: 0.2623
    Epoch 9/50
    313/313 [==============================] - 65s 206ms/step - loss: 0.4706 - accuracy: 0.8606 - val_loss: 4.7897 - val_accuracy: 0.2596
    Epoch 00009: early stopping
    Test loss: 4.826961517333984
    Test accuracy: 0.25360000133514404
    
     
    
    


    
![png](output_195_1.png)
    



    
![png](output_195_2.png)
    


##### VGG16 - Model 1


```python
model = VGG16(weights='imagenet',
                   include_top=False,
                   pooling='max',
                   input_shape=(32,32,3))

for layer in model.layers:
    layer.trainable = False
    
model.summary()
```

    Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5
    58892288/58889256 [==============================] - 2s 0us/step
    Model: "vgg16"
    _________________________________________________________________
    Layer (type)                 Output Shape              Param #   
    =================================================================
    input_4 (InputLayer)         [(None, 32, 32, 3)]       0         
    _________________________________________________________________
    block1_conv1 (Conv2D)        (None, 32, 32, 64)        1792      
    _________________________________________________________________
    block1_conv2 (Conv2D)        (None, 32, 32, 64)        36928     
    _________________________________________________________________
    block1_pool (MaxPooling2D)   (None, 16, 16, 64)        0         
    _________________________________________________________________
    block2_conv1 (Conv2D)        (None, 16, 16, 128)       73856     
    _________________________________________________________________
    block2_conv2 (Conv2D)        (None, 16, 16, 128)       147584    
    _________________________________________________________________
    block2_pool (MaxPooling2D)   (None, 8, 8, 128)         0         
    _________________________________________________________________
    block3_conv1 (Conv2D)        (None, 8, 8, 256)         295168    
    _________________________________________________________________
    block3_conv2 (Conv2D)        (None, 8, 8, 256)         590080    
    _________________________________________________________________
    block3_conv3 (Conv2D)        (None, 8, 8, 256)         590080    
    _________________________________________________________________
    block3_pool (MaxPooling2D)   (None, 4, 4, 256)         0         
    _________________________________________________________________
    block4_conv1 (Conv2D)        (None, 4, 4, 512)         1180160   
    _________________________________________________________________
    block4_conv2 (Conv2D)        (None, 4, 4, 512)         2359808   
    _________________________________________________________________
    block4_conv3 (Conv2D)        (None, 4, 4, 512)         2359808   
    _________________________________________________________________
    block4_pool (MaxPooling2D)   (None, 2, 2, 512)         0         
    _________________________________________________________________
    block5_conv1 (Conv2D)        (None, 2, 2, 512)         2359808   
    _________________________________________________________________
    block5_conv2 (Conv2D)        (None, 2, 2, 512)         2359808   
    _________________________________________________________________
    block5_conv3 (Conv2D)        (None, 2, 2, 512)         2359808   
    _________________________________________________________________
    block5_pool (MaxPooling2D)   (None, 1, 1, 512)         0         
    _________________________________________________________________
    global_max_pooling2d (Global (None, 512)               0         
    =================================================================
    Total params: 14,714,688
    Trainable params: 0
    Non-trainable params: 14,714,688
    _________________________________________________________________
    


```python
model = VGG16(weights='imagenet',
                   include_top=False,
                   pooling='max',
                   input_shape=(32,32,3))

for layer in model.layers:
    layer.trainable = False
    
VGmodel1 = Sequential()

VGmodel1.add(model)
VGmodel1.add(Flatten())
VGmodel1.add(Dense(512, activation= 'relu'))
VGmodel1.add(Dense(256, activation= 'relu'))
VGmodel1.add(Dense(128, activation= 'relu'))
VGmodel1.add(Dense(len(np.unique(y_train)), activation='softmax'))

VGmodel1.compile(optimizer='Adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

VG1 = VGmodel1.fit(X_train, y_train,
        batch_size = 128,
          epochs=50,
          validation_split=0.2,
            callbacks = ES)

test_loss_score(VGmodel1)
accuracy_loss_plots(VG1)
confusion(VGmodel1)
save_format='h5'
VGmodel1.save('CNNmodels/VGmodel1.h5')
```

    Epoch 1/50
    313/313 [==============================] - 152s 485ms/step - loss: 2.0465 - accuracy: 0.3598 - val_loss: 1.8821 - val_accuracy: 0.4154
    Epoch 2/50
    313/313 [==============================] - 155s 495ms/step - loss: 1.7461 - accuracy: 0.4503 - val_loss: 1.7512 - val_accuracy: 0.4533
    Epoch 3/50
    313/313 [==============================] - 153s 490ms/step - loss: 1.6060 - accuracy: 0.4917 - val_loss: 1.7070 - val_accuracy: 0.4632
    Epoch 4/50
    313/313 [==============================] - 153s 487ms/step - loss: 1.4906 - accuracy: 0.5256 - val_loss: 1.6900 - val_accuracy: 0.4751
    Epoch 5/50
    313/313 [==============================] - 153s 489ms/step - loss: 1.3745 - accuracy: 0.5602 - val_loss: 1.6951 - val_accuracy: 0.4833
    Epoch 6/50
    313/313 [==============================] - 155s 494ms/step - loss: 1.2677 - accuracy: 0.5899 - val_loss: 1.7566 - val_accuracy: 0.4779
    Epoch 7/50
    313/313 [==============================] - 154s 493ms/step - loss: 1.1493 - accuracy: 0.6279 - val_loss: 1.7975 - val_accuracy: 0.4856
    Epoch 8/50
    313/313 [==============================] - 154s 492ms/step - loss: 1.0273 - accuracy: 0.6650 - val_loss: 1.8225 - val_accuracy: 0.4815
    Epoch 9/50
    313/313 [==============================] - 158s 505ms/step - loss: 0.9024 - accuracy: 0.7037 - val_loss: 1.9007 - val_accuracy: 0.4835
    Epoch 10/50
    313/313 [==============================] - 153s 489ms/step - loss: 0.7858 - accuracy: 0.7386 - val_loss: 2.1056 - val_accuracy: 0.4806
    Epoch 11/50
    313/313 [==============================] - 154s 491ms/step - loss: 0.6705 - accuracy: 0.7777 - val_loss: 2.2055 - val_accuracy: 0.4742
    Epoch 12/50
    313/313 [==============================] - 160s 510ms/step - loss: 0.5498 - accuracy: 0.8157 - val_loss: 2.4390 - val_accuracy: 0.4710
    Epoch 00012: early stopping
    Test loss: 2.465879440307617
    Test accuracy: 0.47209998965263367
    
     
    
    


    
![png](output_198_1.png)
    



    
![png](output_198_2.png)
    


##### VGG16 - Model 2


```python
model = VGG16(weights='imagenet',
                   include_top=False,
                   pooling='max',
                   input_shape=(32,32,3))

for layer in model.layers:
    layer.trainable = False
    
VGmodel2 = Sequential()

VGmodel2.add(model)
VGmodel2.add(Flatten())
VGmodel2.add(Dense(512, activation= 'relu'))
VGmodel2.add(Dense(256, activation= 'relu')) 
VGmodel2.add(Dense(len(np.unique(y_train)), activation='softmax'))

VGmodel2.compile(optimizer='Adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

VG2 = VGmodel2.fit(X_train, y_train,
        batch_size = 128,
          epochs=50,
          validation_split=0.2,
            callbacks=ES)

test_loss_score(VGmodel2)
accuracy_loss_plots(VG2)
confusion(VGmodel2)
save_format='h5'
VGmodel2.save('CNNmodels/VGmodel2.h5')
```

    Epoch 1/50
    313/313 [==============================] - 129s 411ms/step - loss: 2.0610 - accuracy: 0.3608 - val_loss: 1.8460 - val_accuracy: 0.4225
    Epoch 2/50
    313/313 [==============================] - 128s 409ms/step - loss: 1.7715 - accuracy: 0.4451 - val_loss: 1.7822 - val_accuracy: 0.4421
    Epoch 3/50
    313/313 [==============================] - 129s 412ms/step - loss: 1.6624 - accuracy: 0.4753 - val_loss: 1.7272 - val_accuracy: 0.4591
    Epoch 4/50
    313/313 [==============================] - 130s 414ms/step - loss: 1.5699 - accuracy: 0.5035 - val_loss: 1.7158 - val_accuracy: 0.4674
    Epoch 5/50
    313/313 [==============================] - 130s 414ms/step - loss: 1.4885 - accuracy: 0.5277 - val_loss: 1.6857 - val_accuracy: 0.4721
    Epoch 6/50
    313/313 [==============================] - 135s 430ms/step - loss: 1.4149 - accuracy: 0.5498 - val_loss: 1.7089 - val_accuracy: 0.4733
    Epoch 7/50
    313/313 [==============================] - 148s 472ms/step - loss: 1.3425 - accuracy: 0.5726 - val_loss: 1.6849 - val_accuracy: 0.4764
    Epoch 8/50
    313/313 [==============================] - 137s 437ms/step - loss: 1.2736 - accuracy: 0.5926 - val_loss: 1.6924 - val_accuracy: 0.4789
    Epoch 9/50
    313/313 [==============================] - 139s 445ms/step - loss: 1.2045 - accuracy: 0.6144 - val_loss: 1.7087 - val_accuracy: 0.4879
    Epoch 10/50
    313/313 [==============================] - 135s 430ms/step - loss: 1.1373 - accuracy: 0.6353 - val_loss: 1.7374 - val_accuracy: 0.4797
    Epoch 11/50
    313/313 [==============================] - 135s 431ms/step - loss: 1.0717 - accuracy: 0.6549 - val_loss: 1.7815 - val_accuracy: 0.4858
    Epoch 12/50
    313/313 [==============================] - 137s 439ms/step - loss: 1.0011 - accuracy: 0.6794 - val_loss: 1.8132 - val_accuracy: 0.4855
    Epoch 13/50
    313/313 [==============================] - 129s 412ms/step - loss: 0.9436 - accuracy: 0.6981 - val_loss: 1.8303 - val_accuracy: 0.4880
    Epoch 14/50
    313/313 [==============================] - 129s 413ms/step - loss: 0.8805 - accuracy: 0.7181 - val_loss: 1.8936 - val_accuracy: 0.4799
    Epoch 15/50
    313/313 [==============================] - 129s 413ms/step - loss: 0.8129 - accuracy: 0.7385 - val_loss: 1.9728 - val_accuracy: 0.4799
    Epoch 16/50
    313/313 [==============================] - 129s 412ms/step - loss: 0.7594 - accuracy: 0.7568 - val_loss: 2.0334 - val_accuracy: 0.4849
    Epoch 17/50
    313/313 [==============================] - 129s 412ms/step - loss: 0.6967 - accuracy: 0.7768 - val_loss: 2.1336 - val_accuracy: 0.4780
    Epoch 18/50
    313/313 [==============================] - 128s 410ms/step - loss: 0.6458 - accuracy: 0.7934 - val_loss: 2.1765 - val_accuracy: 0.4752
    Epoch 00018: early stopping
    Test loss: 2.2008650302886963
    Test accuracy: 0.4683000147342682
    
     
    
    


    
![png](output_200_1.png)
    



    
![png](output_200_2.png)
    


## Color -  Superclass (Augmented)

### Set up Data Augmentation

##### ACNN 1 - Model 2


```python
ACNN_model2 = Sequential()

# Create simple CNN model architecture with Pooling for dimensionality reduction 
# and Dropout to reduce overfitting
ACNN_model2.add(Conv2D(32, kernel_size=(3, 3), activation = 'relu', input_shape = (32,32,3)))
ACNN_model2.add(MaxPooling2D(pool_size=(2, 2)))
ACNN_model2.add(Dropout(0.1))

ACNN_model2.add(Conv2D(64, kernel_size=(3, 3), activation = 'relu'))
ACNN_model2.add(MaxPooling2D(pool_size=(2, 2)))
ACNN_model2.add(Dropout(0.2))

ACNN_model2.add(Conv2D(256, kernel_size=(3, 3), activation = 'relu'))
ACNN_model2.add(MaxPooling2D(pool_size=(2, 2)))
ACNN_model2.add(Dropout(0.4))

# Flatten the output of our convolutional layers
ACNN_model2.add(Flatten())

# Add dense layers
ACNN_model2.add(Dense(256, activation= 'relu'))
ACNN_model2.add(Dense(64, activation= 'relu'))
ACNN_model2.add(Dense(32, activation= 'relu'))
ACNN_model2.add(Dense(len(np.unique(y_train)), activation='softmax'))

# Print out a summary of the network
ACNN_model2.summary()

# Compile the model with the desired loss function, optimizer, and metric(s) to track
ACNN_model2.compile(loss = 'sparse_categorical_crossentropy', 
                  optimizer = 'Adam',
                  metrics = ['accuracy'])

# Fit the model on the training data, defining desired batch_size & number of epochs,
# running validation after each batch
ACNN2 = ACNN_model2.fit(train_generator,
                          epochs = 50,
                          verbose = 1,
                          validation_data = validation_generator,
                            callbacks = ES)



test_loss_score(ACNN_model2)
accuracy_loss_plots(ACNN2)
confusion(ACNN_model2)

save_format='h5'
ACNN_model2.save('CNNmodels/ACNN_model2.h5')
```

    Model: "sequential_4"
    _________________________________________________________________
    Layer (type)                 Output Shape              Param #   
    =================================================================
    conv2d_12 (Conv2D)           (None, 30, 30, 32)        896       
    _________________________________________________________________
    max_pooling2d_12 (MaxPooling (None, 15, 15, 32)        0         
    _________________________________________________________________
    dropout_12 (Dropout)         (None, 15, 15, 32)        0         
    _________________________________________________________________
    conv2d_13 (Conv2D)           (None, 13, 13, 64)        18496     
    _________________________________________________________________
    max_pooling2d_13 (MaxPooling (None, 6, 6, 64)          0         
    _________________________________________________________________
    dropout_13 (Dropout)         (None, 6, 6, 64)          0         
    _________________________________________________________________
    conv2d_14 (Conv2D)           (None, 4, 4, 256)         147712    
    _________________________________________________________________
    max_pooling2d_14 (MaxPooling (None, 2, 2, 256)         0         
    _________________________________________________________________
    dropout_14 (Dropout)         (None, 2, 2, 256)         0         
    _________________________________________________________________
    flatten_4 (Flatten)          (None, 1024)              0         
    _________________________________________________________________
    dense_16 (Dense)             (None, 256)               262400    
    _________________________________________________________________
    dense_17 (Dense)             (None, 64)                16448     
    _________________________________________________________________
    dense_18 (Dense)             (None, 32)                2080      
    _________________________________________________________________
    dense_19 (Dense)             (None, 20)                660       
    =================================================================
    Total params: 448,692
    Trainable params: 448,692
    Non-trainable params: 0
    _________________________________________________________________
    Epoch 1/50
    313/313 [==============================] - 27s 85ms/step - loss: 2.7427 - accuracy: 0.0494 - val_loss: 2.5468 - val_accuracy: 0.0440
    Epoch 2/50
    313/313 [==============================] - 30s 96ms/step - loss: 2.4323 - accuracy: 0.0487 - val_loss: 2.3345 - val_accuracy: 0.0417
    Epoch 3/50
    313/313 [==============================] - 31s 98ms/step - loss: 2.2531 - accuracy: 0.0532 - val_loss: 2.1819 - val_accuracy: 0.1096
    Epoch 4/50
    313/313 [==============================] - 29s 94ms/step - loss: 2.1456 - accuracy: 0.0542 - val_loss: 2.0628 - val_accuracy: 0.0896
    Epoch 5/50
    313/313 [==============================] - 30s 96ms/step - loss: 2.0678 - accuracy: 0.0509 - val_loss: 2.0392 - val_accuracy: 0.0775
    Epoch 6/50
    313/313 [==============================] - 29s 93ms/step - loss: 2.0004 - accuracy: 0.0520 - val_loss: 1.9294 - val_accuracy: 0.0312
    Epoch 7/50
    313/313 [==============================] - 29s 93ms/step - loss: 1.9466 - accuracy: 0.0516 - val_loss: 1.8776 - val_accuracy: 0.0412
    Epoch 8/50
    313/313 [==============================] - 29s 93ms/step - loss: 1.9019 - accuracy: 0.0484 - val_loss: 1.8359 - val_accuracy: 0.0756
    Epoch 00008: early stopping
    Test loss: 384.8875427246094
    Test accuracy: 0.004600000102072954
    
     
    
    


    
![png](output_204_1.png)
    



    
![png](output_204_2.png)
    


##### ACNN 1 - Model 4


```python

ACNN_model4 = Sequential()

# Create simple CNN model architecture with Pooling for dimensionality reduction 
# and Dropout to reduce overfitting
ACNN_model4.add(Conv2D(128, kernel_size=(3, 3), activation = 'relu', input_shape = (32,32,3)))
ACNN_model4.add(MaxPooling2D(pool_size=(2, 2)))
ACNN_model4.add(Dropout(0.1))

ACNN_model4.add(Conv2D(256, kernel_size=(3, 3), activation = 'relu'))
ACNN_model4.add(MaxPooling2D(pool_size=(2, 2)))
ACNN_model4.add(Dropout(0.2))

ACNN_model4.add(Conv2D(512, kernel_size=(3, 3), activation = 'relu'))
ACNN_model4.add(MaxPooling2D(pool_size=(2, 2)))
ACNN_model4.add(Dropout(0.4))

# Flatten the output of our convolutional layers
ACNN_model4.add(Flatten())

# Add dense layers
ACNN_model4.add(Dense(512, activation= 'relu'))
ACNN_model4.add(Dense(256, activation= 'relu'))
ACNN_model4.add(Dense(128, activation= 'relu'))
ACNN_model4.add(Dense(len(np.unique(y_train)), activation='softmax'))

# Print out a summary of the network
ACNN_model4.summary()

# Compile the model with the desired loss function, optimizer, and metric(s) to track
ACNN_model4.compile(loss = 'sparse_categorical_crossentropy', 
                  optimizer = 'Adam',
                  metrics = ['accuracy'])

# Fit the model on the training data, defining desired batch_size & number of epochs,
# running validation after each batch
ACNN4 = ACNN_model4.fit(train_generator,
                          epochs = 50,
                          verbose = 1,
                          validation_data = validation_generator,
                            callbacks = ES)



test_loss_score(ACNN_model4)
accuracy_loss_plots(ACNN4)
confusion(ACNN_model4)

save_format='h5'
ACNN_model4.save('CNNmodels/ACNN_model4.h5')
```

    Model: "sequential_6"
    _________________________________________________________________
    Layer (type)                 Output Shape              Param #   
    =================================================================
    conv2d_18 (Conv2D)           (None, 30, 30, 128)       3584      
    _________________________________________________________________
    max_pooling2d_18 (MaxPooling (None, 15, 15, 128)       0         
    _________________________________________________________________
    dropout_18 (Dropout)         (None, 15, 15, 128)       0         
    _________________________________________________________________
    conv2d_19 (Conv2D)           (None, 13, 13, 256)       295168    
    _________________________________________________________________
    max_pooling2d_19 (MaxPooling (None, 6, 6, 256)         0         
    _________________________________________________________________
    dropout_19 (Dropout)         (None, 6, 6, 256)         0         
    _________________________________________________________________
    conv2d_20 (Conv2D)           (None, 4, 4, 512)         1180160   
    _________________________________________________________________
    max_pooling2d_20 (MaxPooling (None, 2, 2, 512)         0         
    _________________________________________________________________
    dropout_20 (Dropout)         (None, 2, 2, 512)         0         
    _________________________________________________________________
    flatten_6 (Flatten)          (None, 2048)              0         
    _________________________________________________________________
    dense_24 (Dense)             (None, 512)               1049088   
    _________________________________________________________________
    dense_25 (Dense)             (None, 256)               131328    
    _________________________________________________________________
    dense_26 (Dense)             (None, 128)               32896     
    _________________________________________________________________
    dense_27 (Dense)             (None, 20)                2580      
    =================================================================
    Total params: 2,694,804
    Trainable params: 2,694,804
    Non-trainable params: 0
    _________________________________________________________________
    Epoch 1/50
    313/313 [==============================] - 138s 441ms/step - loss: 2.6754 - accuracy: 0.0424 - val_loss: 2.4698 - val_accuracy: 0.0736
    Epoch 2/50
    313/313 [==============================] - 138s 441ms/step - loss: 2.3570 - accuracy: 0.0593 - val_loss: 2.2514 - val_accuracy: 0.0886
    Epoch 3/50
    313/313 [==============================] - 139s 443ms/step - loss: 2.1880 - accuracy: 0.0512 - val_loss: 2.0857 - val_accuracy: 0.0701
    Epoch 4/50
    313/313 [==============================] - 137s 439ms/step - loss: 2.0611 - accuracy: 0.0482 - val_loss: 1.9729 - val_accuracy: 0.0760
    Epoch 5/50
    313/313 [==============================] - 138s 440ms/step - loss: 1.9789 - accuracy: 0.0463 - val_loss: 1.9272 - val_accuracy: 0.0648
    Epoch 6/50
    313/313 [==============================] - 141s 452ms/step - loss: 1.8999 - accuracy: 0.0445 - val_loss: 1.8307 - val_accuracy: 0.0433
    Epoch 7/50
    313/313 [==============================] - 148s 472ms/step - loss: 1.8398 - accuracy: 0.0458 - val_loss: 1.7949 - val_accuracy: 0.0512
    Epoch 00007: early stopping
    Test loss: 356.78375244140625
    Test accuracy: 0.001500000013038516
    
     
    
    


    
![png](output_206_1.png)
    



    
![png](output_206_2.png)
    


https://arxiv.org/pdf/1511.07289.pdf

##### ACNN 2 - Model 5


```python

ACNN_model5 = Sequential()

# Create simple CNN model architecture with Pooling for dimensionality reduction 
# and Dropout to reduce overfitting
ACNN_model5.add(Conv2D(192, kernel_size=(5, 5), activation = 'elu', input_shape = (32,32,3), kernel_regularizer=l2(0.0005))) 
ACNN_model5.add(MaxPooling2D(pool_size=(2, 2), padding='same'))
ACNN_model5.add(Dropout(0.0))

ACNN_model5.add(Conv2D(192, kernel_size=(1, 1), activation = 'elu', padding='same', kernel_regularizer=l2(0.0005)))
ACNN_model5.add(Conv2D(240, kernel_size=(3, 3), activation = 'elu', padding='same', kernel_regularizer=l2(0.0005)))
ACNN_model5.add(MaxPooling2D(pool_size=(2, 2), padding='same'))
ACNN_model5.add(Dropout(0.1))

ACNN_model5.add(Conv2D(240, kernel_size=(1,1), activation = 'elu', padding='same', kernel_regularizer=l2(0.0005)))
ACNN_model5.add(Conv2D(260, kernel_size=(2,2), activation = 'elu', padding='same', kernel_regularizer=l2(0.0005)))
ACNN_model5.add(MaxPooling2D(pool_size=(2, 2), padding='same'))
ACNN_model5.add(Dropout(0.2))

ACNN_model5.add(Conv2D(260, kernel_size=(1,1), activation = 'elu', padding='same', kernel_regularizer=l2(0.0005)))
ACNN_model5.add(Conv2D(280, kernel_size=(2,2), activation = 'elu', padding='same', kernel_regularizer=l2(0.0005)))
ACNN_model5.add(MaxPooling2D(pool_size=(2, 2), padding='same'))
ACNN_model5.add(Dropout(0.3))

ACNN_model5.add(Conv2D(280, kernel_size=(1,1), activation = 'elu', padding='same', kernel_regularizer=l2(0.0005)))
ACNN_model5.add(Conv2D(300, kernel_size=(2,2), activation = 'elu', padding='same', kernel_regularizer=l2(0.0005)))
ACNN_model5.add(MaxPooling2D(pool_size=(2, 2), padding='same'))
ACNN_model5.add(Dropout(0.4))

ACNN_model5.add(Conv2D(300, kernel_size=(2,2), activation = 'elu', padding='same', kernel_regularizer=l2(0.0005)))
ACNN_model5.add(MaxPooling2D(pool_size=(2, 2), padding='same'))
ACNN_model5.add(Dropout(0.5))

# Flatten the output of our convolutional layers
ACNN_model5.add(Flatten())

# Add dense layers
ACNN_model5.add(Dense(len(np.unique(y_train)), activation='softmax'))

# Print out a summary of the network
ACNN_model5.summary()

# Compile the model with the desired loss function, optimizer, and metric(s) to track
ACNN_model5.compile(loss = 'sparse_categorical_crossentropy', #cross entropy is for multi-class classification
                  optimizer = 'Adam',
                  metrics = ['accuracy'])

# Fit the model on the training data, defining desired batch_size & number of epochs,
# running validation after each batch
ACNN5 = ACNN_model5.fit(train_generator,
                          epochs = 100,
                          verbose = 1,
                          validation_data = validation_generator,
                            callbacks = ES)
test_loss_score(ACNN_model5)
accuracy_loss_plots(ACNN5)
confusion(ACNN_model5)

save_format='h5'
ACNN_model5.save('CNNmodels/ACNN_model5.h5')
```

    Model: "sequential_7"
    _________________________________________________________________
    Layer (type)                 Output Shape              Param #   
    =================================================================
    conv2d_21 (Conv2D)           (None, 28, 28, 192)       14592     
    _________________________________________________________________
    max_pooling2d_21 (MaxPooling (None, 14, 14, 192)       0         
    _________________________________________________________________
    dropout_21 (Dropout)         (None, 14, 14, 192)       0         
    _________________________________________________________________
    conv2d_22 (Conv2D)           (None, 14, 14, 192)       37056     
    _________________________________________________________________
    conv2d_23 (Conv2D)           (None, 14, 14, 240)       414960    
    _________________________________________________________________
    max_pooling2d_22 (MaxPooling (None, 7, 7, 240)         0         
    _________________________________________________________________
    dropout_22 (Dropout)         (None, 7, 7, 240)         0         
    _________________________________________________________________
    conv2d_24 (Conv2D)           (None, 7, 7, 240)         57840     
    _________________________________________________________________
    conv2d_25 (Conv2D)           (None, 7, 7, 260)         249860    
    _________________________________________________________________
    max_pooling2d_23 (MaxPooling (None, 4, 4, 260)         0         
    _________________________________________________________________
    dropout_23 (Dropout)         (None, 4, 4, 260)         0         
    _________________________________________________________________
    conv2d_26 (Conv2D)           (None, 4, 4, 260)         67860     
    _________________________________________________________________
    conv2d_27 (Conv2D)           (None, 4, 4, 280)         291480    
    _________________________________________________________________
    max_pooling2d_24 (MaxPooling (None, 2, 2, 280)         0         
    _________________________________________________________________
    dropout_24 (Dropout)         (None, 2, 2, 280)         0         
    _________________________________________________________________
    conv2d_28 (Conv2D)           (None, 2, 2, 280)         78680     
    _________________________________________________________________
    conv2d_29 (Conv2D)           (None, 2, 2, 300)         336300    
    _________________________________________________________________
    max_pooling2d_25 (MaxPooling (None, 1, 1, 300)         0         
    _________________________________________________________________
    dropout_25 (Dropout)         (None, 1, 1, 300)         0         
    _________________________________________________________________
    conv2d_30 (Conv2D)           (None, 1, 1, 300)         360300    
    _________________________________________________________________
    max_pooling2d_26 (MaxPooling (None, 1, 1, 300)         0         
    _________________________________________________________________
    dropout_26 (Dropout)         (None, 1, 1, 300)         0         
    _________________________________________________________________
    flatten_7 (Flatten)          (None, 300)               0         
    _________________________________________________________________
    dense_28 (Dense)             (None, 20)                6020      
    =================================================================
    Total params: 1,914,948
    Trainable params: 1,914,948
    Non-trainable params: 0
    _________________________________________________________________
    Epoch 1/100
    313/313 [==============================] - 211s 675ms/step - loss: 3.3901 - accuracy: 0.0546 - val_loss: 2.9219 - val_accuracy: 0.1118
    Epoch 2/100
    313/313 [==============================] - 211s 673ms/step - loss: 2.8080 - accuracy: 0.0514 - val_loss: 2.5764 - val_accuracy: 0.0387
    Epoch 3/100
    313/313 [==============================] - 206s 659ms/step - loss: 2.6347 - accuracy: 0.0483 - val_loss: 2.4541 - val_accuracy: 0.1091
    Epoch 4/100
    313/313 [==============================] - 205s 654ms/step - loss: 2.5247 - accuracy: 0.0494 - val_loss: 2.3811 - val_accuracy: 0.0361
    Epoch 5/100
    313/313 [==============================] - 204s 652ms/step - loss: 2.4501 - accuracy: 0.0501 - val_loss: 2.3433 - val_accuracy: 0.0510
    Epoch 6/100
    313/313 [==============================] - 204s 652ms/step - loss: 2.4222 - accuracy: 0.0493 - val_loss: 2.2909 - val_accuracy: 0.0484
    Epoch 00006: early stopping
    Test loss: 17.973800659179688
    Test accuracy: 0.0
    
     
    
    


    
![png](output_209_1.png)
    



    
![png](output_209_2.png)
    


##### ACNN 2 - Model 6


```python
ACNN_model6 = Sequential()

# Create simple CNN model architecture with Pooling for dimensionality reduction 
# and Dropout to reduce overfitting
ACNN_model6.add(Conv2D(32, kernel_size=(3,3), activation = 'elu', input_shape = (32,32,3), kernel_regularizer=l2(0.0005))) 
ACNN_model6.add(MaxPooling2D(pool_size=(2, 2), padding='same'))

ACNN_model6.add(Conv2D(64, kernel_size=(3,3), activation = 'elu', padding='same', kernel_regularizer=l2(0.0005)))
ACNN_model6.add(Conv2D(128, kernel_size=(3,3), activation = 'elu', padding='same', kernel_regularizer=l2(0.0005)))
ACNN_model6.add(MaxPooling2D(pool_size=(2, 2), padding='same'))
ACNN_model6.add(Dropout(0.1))

ACNN_model6.add(Conv2D(128, kernel_size=(2,2), activation = 'elu', padding='same', kernel_regularizer=l2(0.0005)))
ACNN_model6.add(Conv2D(256, kernel_size=(2,2), activation = 'elu', padding='same', kernel_regularizer=l2(0.0005)))
ACNN_model6.add(MaxPooling2D(pool_size=(2, 2), padding='same'))
ACNN_model6.add(Dropout(0.2))

ACNN_model6.add(Conv2D(256, kernel_size=(1,1), activation = 'elu', padding='same', kernel_regularizer=l2(0.0005)))
ACNN_model6.add(Conv2D(512, kernel_size=(1,1), activation = 'elu', padding='same', kernel_regularizer=l2(0.0005)))
ACNN_model6.add(MaxPooling2D(pool_size=(2, 2), padding='same'))
ACNN_model6.add(Dropout(0.3))

# Flatten the output of our convolutional layers
ACNN_model6.add(Flatten())

# Add dense layers
ACNN_model6.add(Dense(512, activation = 'elu'))
ACNN_model6.add(Dense(256, activation = 'elu'))
ACNN_model6.add(Dense(len(np.unique(y_train)), activation='softmax'))

# Print out a summary of the network
ACNN_model6.summary()

# Compile the model with the desired loss function, optimizer, and metric(s) to track
ACNN_model6.compile(loss = 'sparse_categorical_crossentropy', #cross entropy is for multi-class classification
                  optimizer = 'Adam',
                  metrics = ['accuracy'])

# Fit the model on the training data, defining desired batch_size & number of epochs,
# running validation after each batch
ACNN6 = ACNN_model6.fit(train_generator,
                              epochs = 100,
                              verbose = 1,
                              validation_data = validation_generator,
                                callbacks = ES)

test_loss_score(ACNN_model6)
accuracy_loss_plots(ACNN6)
confusion(ACNN_model6)

ACNN_model6.save('CNNmodels/ACNN_model6.h5')
```

    Model: "sequential_8"
    _________________________________________________________________
    Layer (type)                 Output Shape              Param #   
    =================================================================
    conv2d_31 (Conv2D)           (None, 30, 30, 32)        896       
    _________________________________________________________________
    max_pooling2d_27 (MaxPooling (None, 15, 15, 32)        0         
    _________________________________________________________________
    conv2d_32 (Conv2D)           (None, 15, 15, 64)        18496     
    _________________________________________________________________
    conv2d_33 (Conv2D)           (None, 15, 15, 128)       73856     
    _________________________________________________________________
    max_pooling2d_28 (MaxPooling (None, 8, 8, 128)         0         
    _________________________________________________________________
    dropout_27 (Dropout)         (None, 8, 8, 128)         0         
    _________________________________________________________________
    conv2d_34 (Conv2D)           (None, 8, 8, 128)         65664     
    _________________________________________________________________
    conv2d_35 (Conv2D)           (None, 8, 8, 256)         131328    
    _________________________________________________________________
    max_pooling2d_29 (MaxPooling (None, 4, 4, 256)         0         
    _________________________________________________________________
    dropout_28 (Dropout)         (None, 4, 4, 256)         0         
    _________________________________________________________________
    conv2d_36 (Conv2D)           (None, 4, 4, 256)         65792     
    _________________________________________________________________
    conv2d_37 (Conv2D)           (None, 4, 4, 512)         131584    
    _________________________________________________________________
    max_pooling2d_30 (MaxPooling (None, 2, 2, 512)         0         
    _________________________________________________________________
    dropout_29 (Dropout)         (None, 2, 2, 512)         0         
    _________________________________________________________________
    flatten_8 (Flatten)          (None, 2048)              0         
    _________________________________________________________________
    dense_29 (Dense)             (None, 512)               1049088   
    _________________________________________________________________
    dense_30 (Dense)             (None, 256)               131328    
    _________________________________________________________________
    dense_31 (Dense)             (None, 20)                5140      
    =================================================================
    Total params: 1,673,172
    Trainable params: 1,673,172
    Non-trainable params: 0
    _________________________________________________________________
    Epoch 1/100
    313/313 [==============================] - 73s 232ms/step - loss: 2.8711 - accuracy: 0.0481 - val_loss: 2.5972 - val_accuracy: 0.1236
    Epoch 2/100
    313/313 [==============================] - 73s 232ms/step - loss: 2.4574 - accuracy: 0.0511 - val_loss: 2.3205 - val_accuracy: 0.0870
    Epoch 3/100
    313/313 [==============================] - 73s 232ms/step - loss: 2.2418 - accuracy: 0.0506 - val_loss: 2.1603 - val_accuracy: 0.0478
    Epoch 4/100
    313/313 [==============================] - 73s 233ms/step - loss: 2.1194 - accuracy: 0.0504 - val_loss: 2.0772 - val_accuracy: 0.0172
    Epoch 5/100
    313/313 [==============================] - 73s 233ms/step - loss: 2.0244 - accuracy: 0.0520 - val_loss: 1.9405 - val_accuracy: 0.0374
    Epoch 6/100
    313/313 [==============================] - 73s 232ms/step - loss: 1.9433 - accuracy: 0.0498 - val_loss: 1.9686 - val_accuracy: 0.0726
    Epoch 00006: early stopping
    Test loss: 23.75376319885254
    Test accuracy: 0.0
    
     
    
    


    
![png](output_211_1.png)
    



    
![png](output_211_2.png)
    


##### AResNet - Model 1


```python
model = ResNet50V2(weights='imagenet',
                   include_top=False,
                   pooling='max',
                   input_shape=(32,32,3))
for layer in model.layers:
    layer.trainable = False

    
ARNmodel1 = Sequential()

ARNmodel1.add(model)
ARNmodel1.add(Flatten())
ARNmodel1.add(Dense(2048, activation= 'relu'))
ARNmodel1.add(Dense(1024, activation= 'relu'))
ARNmodel1.add(Dense(512, activation= 'relu'))
ARNmodel1.add(Dense(len(np.unique(y_train)), activation='softmax'))

ARNmodel1.compile(optimizer='Adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

ARN1 = ARNmodel1.fit(train_generator,
                      epochs = 50,
                      verbose = 1,
                      validation_data = validation_generator,
                        callbacks = ES)

test_loss_score(ARNmodel1)
accuracy_loss_plots(ARN1)
confusion(ARNmodel1)
save_format='h5'
ARNmodel1.save('CNNmodels/ARNmodel1.h5')
```

    Epoch 1/50
    313/313 [==============================] - 65s 207ms/step - loss: 2.5799 - accuracy: 0.0329 - val_loss: 2.4589 - val_accuracy: 0.0137
    Epoch 2/50
    313/313 [==============================] - 64s 204ms/step - loss: 2.4115 - accuracy: 0.0353 - val_loss: 2.4021 - val_accuracy: 0.0156
    Epoch 3/50
    313/313 [==============================] - 64s 206ms/step - loss: 2.3441 - accuracy: 0.0344 - val_loss: 2.3891 - val_accuracy: 0.0634
    Epoch 4/50
    313/313 [==============================] - 66s 210ms/step - loss: 2.3100 - accuracy: 0.0328 - val_loss: 2.3572 - val_accuracy: 0.0264
    Epoch 5/50
    313/313 [==============================] - 66s 211ms/step - loss: 2.2672 - accuracy: 0.0360 - val_loss: 2.3383 - val_accuracy: 0.0344
    Epoch 6/50
    313/313 [==============================] - 65s 208ms/step - loss: 2.2414 - accuracy: 0.0379 - val_loss: 2.3234 - val_accuracy: 0.0279
    Epoch 7/50
    313/313 [==============================] - 65s 208ms/step - loss: 2.2092 - accuracy: 0.0360 - val_loss: 2.3325 - val_accuracy: 0.0558
    Epoch 8/50
    313/313 [==============================] - 66s 212ms/step - loss: 2.1886 - accuracy: 0.0362 - val_loss: 2.3265 - val_accuracy: 0.0472
    Epoch 00008: early stopping
    Test loss: 582.4730834960938
    Test accuracy: 0.0
    
     
    
    


    
![png](output_213_1.png)
    



    
![png](output_213_2.png)
    


##### AVGG16 - Model 2


```python
model = VGG16(weights='imagenet',
                   include_top=False,
                   pooling='max',
                   input_shape=(32,32,3))

for layer in model.layers:
    layer.trainable = False
    
AVGmodel2 = Sequential()

AVGmodel2.add(model)
AVGmodel2.add(Flatten())
AVGmodel2.add(Dense(512, activation= 'relu'))
AVGmodel2.add(Dense(256, activation= 'relu')) 
AVGmodel2.add(Dense(len(np.unique(y_train)), activation='softmax'))

AVGmodel2.compile(optimizer='Adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

AVG2 = VGmodel2.fit(train_generator,
                      epochs = 50,
                      verbose = 1,
                      validation_data = validation_generator,
                        callbacks = ES)

test_loss_score(AVGmodel2)
accuracy_loss_plots(AVG2)
confusion(AVGmodel2)
save_format='h5'
AVGmodel2.save('CNNmodels/AVGmodel2.h5')
```

    Epoch 1/50
    313/313 [==============================] - 123s 393ms/step - loss: 1.9644 - accuracy: 0.0492 - val_loss: 1.9076 - val_accuracy: 0.0488
    Epoch 2/50
    313/313 [==============================] - 121s 388ms/step - loss: 1.8415 - accuracy: 0.0452 - val_loss: 1.8584 - val_accuracy: 0.0470
    Epoch 3/50
    313/313 [==============================] - 123s 391ms/step - loss: 1.7666 - accuracy: 0.0448 - val_loss: 1.8199 - val_accuracy: 0.0691
    Epoch 4/50
    313/313 [==============================] - 121s 388ms/step - loss: 1.7154 - accuracy: 0.0458 - val_loss: 1.7895 - val_accuracy: 0.0334
    Epoch 5/50
    313/313 [==============================] - 122s 390ms/step - loss: 1.6552 - accuracy: 0.0457 - val_loss: 1.7850 - val_accuracy: 0.0362
    Epoch 6/50
    313/313 [==============================] - 122s 391ms/step - loss: 1.6156 - accuracy: 0.0443 - val_loss: 1.7553 - val_accuracy: 0.0680
    Epoch 7/50
    313/313 [==============================] - 122s 389ms/step - loss: 1.5810 - accuracy: 0.0439 - val_loss: 1.7390 - val_accuracy: 0.0448
    Epoch 8/50
    313/313 [==============================] - 122s 389ms/step - loss: 1.5348 - accuracy: 0.0443 - val_loss: 1.7364 - val_accuracy: 0.0409
    Epoch 00008: early stopping
    Test loss: 22.116456985473633
    Test accuracy: 0.051600001752376556
    
     
    
    


    
![png](output_215_1.png)
    



    
![png](output_215_2.png)
    


## Grayscale - Superclass

### Basic Models - Logistic Regression

We will try out the basic model and see how the accuracy scores are.


```python
# Set our X_train, y_train and X_test, y_test

X_train_flat = Train_flat_data_gray
y_train = np.array(train[b'coarse_labels']) #set coarse/superclass as our classification target

X_test_flat = Test_flat_data_gray
y_test = np.array(test[b'coarse_labels'])
```


```python
from sklearn.linear_model import LogisticRegression

LR = LogisticRegression(random_state=1, n_jobs=-1)
LR.fit(X_train_flat, y_train)
print('Train score: ', LR.score(X_train_flat, y_train))
print('Test score: ', LR.score(X_test_flat, y_test))
```

    Train score:  0.19532
    Test score:  0.1635
    


```python
from sklearn.metrics import confusion_matrix
import seaborn as sns
# Make classifications based on the test features, and assign the classifications to a variable
LR_y_pred = LR.predict(X_test_flat)

# Build the confusion matrix as a dataframe
confusion_df = pd.DataFrame(confusion_matrix(y_test, LR_y_pred))
confusion_df.index = [f'Actually {i}' for i in Superclass_label['Superclass_label']]
confusion_df.columns = [f'Predicted {i}' for i in Superclass_label['Superclass_label']]


plt.figure(figsize = (12,12))
sns.heatmap(confusion_df,
            annot=True,
            cbar=False,
            cmap="rocket_r",
            linewidths=0.5
           )
plt.title('Confusion Matrix',size = 25,y=1.01)
plt.xlabel("Predicted Label", size = 20)
plt.ylabel("True Label", size = 20)
plt.show()
```


    
![png](output_221_0.png)
    


##### GCNN 1 - Model 2


```python
# Set our X_train, y_train and X_test, y_test

X_train = Train_data_gray
y_train = Train_coarse #set coarse/superclass as our classification target

X_test = Test_data_gray
y_test = Test_coarse
```


```python
X_train.shape, y_train.shape, X_test.shape, y_test.shape
```




    ((50000, 32, 32, 1), (50000, 1), (10000, 32, 32, 1), (10000, 1))




```python
GCNN_model2 = Sequential()

# Create simple CNN model architecture with Pooling for dimensionality reduction 
# and Dropout to reduce overfitting
GCNN_model2.add(Conv2D(32, kernel_size=(3, 3), activation = 'relu', input_shape = X_train[0].shape))
GCNN_model2.add(MaxPooling2D(pool_size=(2, 2)))
GCNN_model2.add(Dropout(0.1))

GCNN_model2.add(Conv2D(64, kernel_size=(3, 3), activation = 'relu'))
GCNN_model2.add(MaxPooling2D(pool_size=(2, 2)))
GCNN_model2.add(Dropout(0.2))

GCNN_model2.add(Conv2D(256, kernel_size=(3, 3), activation = 'relu'))
GCNN_model2.add(MaxPooling2D(pool_size=(2, 2)))
GCNN_model2.add(Dropout(0.4))

# Flatten the output of our convolutional layers
GCNN_model2.add(Flatten())

# Add dense layers
GCNN_model2.add(Dense(256, activation= 'relu'))
GCNN_model2.add(Dense(64, activation= 'relu'))
GCNN_model2.add(Dense(32, activation= 'relu'))
GCNN_model2.add(Dense(len(np.unique(y_train)), activation='softmax'))

# Print out a summary of the network
GCNN_model2.summary()

# Compile the model with the desired loss function, optimizer, and metric(s) to track
GCNN_model2.compile(loss = 'sparse_categorical_crossentropy', 
                  optimizer = 'Adam',
                  metrics = ['accuracy'])

# Fit the model on the training data, defining desired batch_size & number of epochs,
# running validation after each batch
GCNN2 = GCNN_model2.fit(X_train, y_train,
                          epochs = 50,
                          verbose = 1,
                          validation_split=0.2,
                            callbacks = ES)



test_loss_score(GCNN_model2)
accuracy_loss_plots(GCNN2)
confusion(GCNN_model2)

save_format='h5'
GCNN_model2.save('CNNmodels/GCNN_model2.h5')
```

    Model: "sequential_15"
    _________________________________________________________________
    Layer (type)                 Output Shape              Param #   
    =================================================================
    conv2d_43 (Conv2D)           (None, 30, 30, 32)        320       
    _________________________________________________________________
    max_pooling2d_37 (MaxPooling (None, 15, 15, 32)        0         
    _________________________________________________________________
    dropout_33 (Dropout)         (None, 15, 15, 32)        0         
    _________________________________________________________________
    conv2d_44 (Conv2D)           (None, 13, 13, 64)        18496     
    _________________________________________________________________
    max_pooling2d_38 (MaxPooling (None, 6, 6, 64)          0         
    _________________________________________________________________
    dropout_34 (Dropout)         (None, 6, 6, 64)          0         
    _________________________________________________________________
    conv2d_45 (Conv2D)           (None, 4, 4, 256)         147712    
    _________________________________________________________________
    max_pooling2d_39 (MaxPooling (None, 2, 2, 256)         0         
    _________________________________________________________________
    dropout_35 (Dropout)         (None, 2, 2, 256)         0         
    _________________________________________________________________
    flatten_13 (Flatten)         (None, 1024)              0         
    _________________________________________________________________
    dense_46 (Dense)             (None, 256)               262400    
    _________________________________________________________________
    dense_47 (Dense)             (None, 64)                16448     
    _________________________________________________________________
    dense_48 (Dense)             (None, 32)                2080      
    _________________________________________________________________
    dense_49 (Dense)             (None, 20)                660       
    =================================================================
    Total params: 448,116
    Trainable params: 448,116
    Non-trainable params: 0
    _________________________________________________________________
    Epoch 1/50
    1250/1250 [==============================] - 20s 16ms/step - loss: 3.0112 - accuracy: 0.0714 - val_loss: 2.9290 - val_accuracy: 0.1002
    Epoch 2/50
    1250/1250 [==============================] - 23s 18ms/step - loss: 2.8173 - accuracy: 0.1391 - val_loss: 2.6854 - val_accuracy: 0.1853
    Epoch 3/50
    1250/1250 [==============================] - 23s 19ms/step - loss: 2.6518 - accuracy: 0.1893 - val_loss: 2.5503 - val_accuracy: 0.2205
    Epoch 4/50
    1250/1250 [==============================] - 21s 17ms/step - loss: 2.5305 - accuracy: 0.2289 - val_loss: 2.4521 - val_accuracy: 0.2680
    Epoch 5/50
    1250/1250 [==============================] - 21s 17ms/step - loss: 2.4286 - accuracy: 0.2574 - val_loss: 2.3657 - val_accuracy: 0.2951
    Epoch 6/50
    1250/1250 [==============================] - 22s 17ms/step - loss: 2.3395 - accuracy: 0.2839 - val_loss: 2.3118 - val_accuracy: 0.2951
    Epoch 7/50
    1250/1250 [==============================] - 21s 17ms/step - loss: 2.2783 - accuracy: 0.2997 - val_loss: 2.2246 - val_accuracy: 0.3281
    Epoch 8/50
    1250/1250 [==============================] - 22s 18ms/step - loss: 2.2312 - accuracy: 0.3160 - val_loss: 2.2325 - val_accuracy: 0.3251
    Epoch 9/50
    1250/1250 [==============================] - 23s 18ms/step - loss: 2.1840 - accuracy: 0.3308 - val_loss: 2.1661 - val_accuracy: 0.3388
    Epoch 10/50
    1250/1250 [==============================] - 23s 19ms/step - loss: 2.1466 - accuracy: 0.3410 - val_loss: 2.1064 - val_accuracy: 0.3615
    Epoch 11/50
    1250/1250 [==============================] - 23s 18ms/step - loss: 2.1124 - accuracy: 0.3504 - val_loss: 2.1151 - val_accuracy: 0.3636
    Epoch 12/50
    1250/1250 [==============================] - 23s 19ms/step - loss: 2.0805 - accuracy: 0.3618 - val_loss: 2.0732 - val_accuracy: 0.3704
    Epoch 13/50
    1250/1250 [==============================] - 23s 19ms/step - loss: 2.0545 - accuracy: 0.3712 - val_loss: 2.0604 - val_accuracy: 0.3795
    Epoch 14/50
    1250/1250 [==============================] - 23s 19ms/step - loss: 2.0301 - accuracy: 0.3776 - val_loss: 2.0768 - val_accuracy: 0.3632
    Epoch 15/50
    1250/1250 [==============================] - 23s 18ms/step - loss: 2.0065 - accuracy: 0.3877 - val_loss: 2.0115 - val_accuracy: 0.3870
    Epoch 16/50
    1250/1250 [==============================] - 23s 19ms/step - loss: 1.9812 - accuracy: 0.3905 - val_loss: 1.9925 - val_accuracy: 0.3963
    Epoch 17/50
    1250/1250 [==============================] - 23s 18ms/step - loss: 1.9659 - accuracy: 0.3984 - val_loss: 2.0322 - val_accuracy: 0.3860
    Epoch 18/50
    1250/1250 [==============================] - 23s 18ms/step - loss: 1.9433 - accuracy: 0.4052 - val_loss: 1.9737 - val_accuracy: 0.4007
    Epoch 19/50
    1250/1250 [==============================] - 25s 20ms/step - loss: 1.9168 - accuracy: 0.4117 - val_loss: 2.0243 - val_accuracy: 0.3874
    Epoch 20/50
    1250/1250 [==============================] - 24s 19ms/step - loss: 1.9053 - accuracy: 0.4150 - val_loss: 1.9438 - val_accuracy: 0.4126
    Epoch 21/50
    1250/1250 [==============================] - 23s 18ms/step - loss: 1.8914 - accuracy: 0.4204 - val_loss: 1.9247 - val_accuracy: 0.4178
    Epoch 22/50
    1250/1250 [==============================] - 24s 19ms/step - loss: 1.8682 - accuracy: 0.4254 - val_loss: 1.9304 - val_accuracy: 0.4174
    Epoch 23/50
    1250/1250 [==============================] - 24s 19ms/step - loss: 1.8464 - accuracy: 0.4322 - val_loss: 1.9530 - val_accuracy: 0.4120
    Epoch 24/50
    1250/1250 [==============================] - 24s 19ms/step - loss: 1.8347 - accuracy: 0.4379 - val_loss: 1.9503 - val_accuracy: 0.4149
    Epoch 25/50
    1250/1250 [==============================] - 23s 19ms/step - loss: 1.8124 - accuracy: 0.4430 - val_loss: 1.9541 - val_accuracy: 0.4119
    Epoch 26/50
    1250/1250 [==============================] - 24s 20ms/step - loss: 1.8090 - accuracy: 0.4441 - val_loss: 1.9671 - val_accuracy: 0.4116
    Epoch 00026: early stopping
    Test loss: 1.9598146677017212
    Test accuracy: 0.4124000072479248
    
     
    
    


    
![png](output_225_1.png)
    



    
![png](output_225_2.png)
    


##### GCNN 1 - Model 4


```python

GCNN_model4 = Sequential()

# Create simple CNN model architecture with Pooling for dimensionality reduction 
# and Dropout to reduce overfitting
GCNN_model4.add(Conv2D(128, kernel_size=(3, 3), activation = 'relu',input_shape = X_train[0].shape))
GCNN_model4.add(MaxPooling2D(pool_size=(2, 2)))
GCNN_model4.add(Dropout(0.1))

GCNN_model4.add(Conv2D(256, kernel_size=(3, 3), activation = 'relu'))
GCNN_model4.add(MaxPooling2D(pool_size=(2, 2)))
GCNN_model4.add(Dropout(0.2))

GCNN_model4.add(Conv2D(512, kernel_size=(3, 3), activation = 'relu'))
GCNN_model4.add(MaxPooling2D(pool_size=(2, 2)))
GCNN_model4.add(Dropout(0.4))

# Flatten the output of our convolutional layers
GCNN_model4.add(Flatten())

# Add dense layers
GCNN_model4.add(Dense(512, activation= 'relu'))
GCNN_model4.add(Dense(256, activation= 'relu'))
GCNN_model4.add(Dense(128, activation= 'relu'))
GCNN_model4.add(Dense(len(np.unique(y_train)), activation='softmax'))

# Print out a summary of the network
GCNN_model4.summary()

# Compile the model with the desired loss function, optimizer, and metric(s) to track
GCNN_model4.compile(loss = 'sparse_categorical_crossentropy', 
                  optimizer = 'Adam',
                  metrics = ['accuracy'])

# Fit the model on the training data, defining desired batch_size & number of epochs,
# running validation after each batch
GCNN4 = GCNN_model4.fit(X_train, y_train,
                          epochs = 50,
                          verbose = 1,
                          validation_split=0.2,
                            callbacks = ES)


test_loss_score(GCNN_model4)
accuracy_loss_plots(GCNN4)
confusion(GCNN_model4)

save_format='h5'
GCNN_model4.save('CNNmodels/GCNN_model4.h5')
```

    Model: "sequential_16"
    _________________________________________________________________
    Layer (type)                 Output Shape              Param #   
    =================================================================
    conv2d_46 (Conv2D)           (None, 30, 30, 128)       1280      
    _________________________________________________________________
    max_pooling2d_40 (MaxPooling (None, 15, 15, 128)       0         
    _________________________________________________________________
    dropout_36 (Dropout)         (None, 15, 15, 128)       0         
    _________________________________________________________________
    conv2d_47 (Conv2D)           (None, 13, 13, 256)       295168    
    _________________________________________________________________
    max_pooling2d_41 (MaxPooling (None, 6, 6, 256)         0         
    _________________________________________________________________
    dropout_37 (Dropout)         (None, 6, 6, 256)         0         
    _________________________________________________________________
    conv2d_48 (Conv2D)           (None, 4, 4, 512)         1180160   
    _________________________________________________________________
    max_pooling2d_42 (MaxPooling (None, 2, 2, 512)         0         
    _________________________________________________________________
    dropout_38 (Dropout)         (None, 2, 2, 512)         0         
    _________________________________________________________________
    flatten_14 (Flatten)         (None, 2048)              0         
    _________________________________________________________________
    dense_50 (Dense)             (None, 512)               1049088   
    _________________________________________________________________
    dense_51 (Dense)             (None, 256)               131328    
    _________________________________________________________________
    dense_52 (Dense)             (None, 128)               32896     
    _________________________________________________________________
    dense_53 (Dense)             (None, 20)                2580      
    =================================================================
    Total params: 2,692,500
    Trainable params: 2,692,500
    Non-trainable params: 0
    _________________________________________________________________
    Epoch 1/50
    1250/1250 [==============================] - 157s 126ms/step - loss: 2.9839 - accuracy: 0.1008 - val_loss: 2.8046 - val_accuracy: 0.1410
    Epoch 2/50
    1250/1250 [==============================] - 153s 123ms/step - loss: 2.7661 - accuracy: 0.1578 - val_loss: 2.6267 - val_accuracy: 0.2047
    Epoch 3/50
    1250/1250 [==============================] - 155s 124ms/step - loss: 2.5552 - accuracy: 0.2211 - val_loss: 2.5186 - val_accuracy: 0.2397
    Epoch 4/50
    1250/1250 [==============================] - 156s 125ms/step - loss: 2.4099 - accuracy: 0.2618 - val_loss: 2.3868 - val_accuracy: 0.2774
    Epoch 5/50
    1250/1250 [==============================] - 154s 123ms/step - loss: 2.3133 - accuracy: 0.2926 - val_loss: 2.2672 - val_accuracy: 0.3139
    Epoch 6/50
    1250/1250 [==============================] - 158s 126ms/step - loss: 2.2280 - accuracy: 0.3178 - val_loss: 2.2041 - val_accuracy: 0.3336
    Epoch 7/50
    1250/1250 [==============================] - 162s 130ms/step - loss: 2.1573 - accuracy: 0.3388 - val_loss: 2.2190 - val_accuracy: 0.3280
    Epoch 8/50
    1250/1250 [==============================] - 153s 122ms/step - loss: 2.1028 - accuracy: 0.3558 - val_loss: 2.1340 - val_accuracy: 0.3596
    Epoch 9/50
    1250/1250 [==============================] - 155s 124ms/step - loss: 2.0515 - accuracy: 0.3738 - val_loss: 2.0824 - val_accuracy: 0.3741
    Epoch 10/50
    1250/1250 [==============================] - 155s 124ms/step - loss: 2.0180 - accuracy: 0.3817 - val_loss: 2.0772 - val_accuracy: 0.3758
    Epoch 11/50
    1250/1250 [==============================] - 149s 119ms/step - loss: 1.9690 - accuracy: 0.3992 - val_loss: 2.0534 - val_accuracy: 0.3843
    Epoch 12/50
    1250/1250 [==============================] - 149s 119ms/step - loss: 1.9312 - accuracy: 0.4104 - val_loss: 2.0479 - val_accuracy: 0.3835
    Epoch 13/50
    1250/1250 [==============================] - 149s 119ms/step - loss: 1.8992 - accuracy: 0.4188 - val_loss: 1.9876 - val_accuracy: 0.3974
    Epoch 14/50
    1250/1250 [==============================] - 155s 124ms/step - loss: 1.8722 - accuracy: 0.4279 - val_loss: 1.9912 - val_accuracy: 0.4050
    Epoch 15/50
    1250/1250 [==============================] - 156s 125ms/step - loss: 1.8302 - accuracy: 0.4401 - val_loss: 1.9355 - val_accuracy: 0.4187
    Epoch 16/50
    1250/1250 [==============================] - 156s 124ms/step - loss: 1.8002 - accuracy: 0.4509 - val_loss: 1.9383 - val_accuracy: 0.4127
    Epoch 17/50
    1250/1250 [==============================] - 155s 124ms/step - loss: 1.7692 - accuracy: 0.4631 - val_loss: 2.0340 - val_accuracy: 0.3953
    Epoch 18/50
    1250/1250 [==============================] - 156s 125ms/step - loss: 1.7402 - accuracy: 0.4679 - val_loss: 1.9727 - val_accuracy: 0.4178
    Epoch 19/50
    1250/1250 [==============================] - 158s 127ms/step - loss: 1.7197 - accuracy: 0.4732 - val_loss: 1.9672 - val_accuracy: 0.4143
    Epoch 20/50
    1250/1250 [==============================] - 154s 123ms/step - loss: 1.7010 - accuracy: 0.4836 - val_loss: 1.9187 - val_accuracy: 0.4232
    Epoch 21/50
    1250/1250 [==============================] - 153s 122ms/step - loss: 1.6688 - accuracy: 0.4921 - val_loss: 1.9424 - val_accuracy: 0.4245
    Epoch 22/50
    1250/1250 [==============================] - 153s 123ms/step - loss: 1.6459 - accuracy: 0.4978 - val_loss: 1.9236 - val_accuracy: 0.4286
    Epoch 23/50
    1250/1250 [==============================] - 153s 123ms/step - loss: 1.6265 - accuracy: 0.5037 - val_loss: 1.9114 - val_accuracy: 0.4317
    Epoch 24/50
    1250/1250 [==============================] - 153s 122ms/step - loss: 1.6064 - accuracy: 0.5114 - val_loss: 1.8984 - val_accuracy: 0.4340
    Epoch 25/50
    1250/1250 [==============================] - 153s 122ms/step - loss: 1.5745 - accuracy: 0.5226 - val_loss: 1.9041 - val_accuracy: 0.4362
    Epoch 26/50
    1250/1250 [==============================] - 151s 121ms/step - loss: 1.5524 - accuracy: 0.5266 - val_loss: 1.9294 - val_accuracy: 0.4227
    Epoch 27/50
    1250/1250 [==============================] - 152s 122ms/step - loss: 1.5317 - accuracy: 0.5344 - val_loss: 1.9193 - val_accuracy: 0.4378
    Epoch 28/50
    1250/1250 [==============================] - 152s 122ms/step - loss: 1.4956 - accuracy: 0.5463 - val_loss: 1.9353 - val_accuracy: 0.4301
    Epoch 29/50
    1250/1250 [==============================] - 151s 121ms/step - loss: 1.5059 - accuracy: 0.5428 - val_loss: 1.8752 - val_accuracy: 0.4398
    Epoch 30/50
    1250/1250 [==============================] - 151s 121ms/step - loss: 1.4681 - accuracy: 0.5537 - val_loss: 1.9621 - val_accuracy: 0.4222
    Epoch 31/50
    1250/1250 [==============================] - 151s 121ms/step - loss: 1.4479 - accuracy: 0.5601 - val_loss: 1.8981 - val_accuracy: 0.4517
    Epoch 32/50
    1250/1250 [==============================] - 152s 121ms/step - loss: 1.4267 - accuracy: 0.5678 - val_loss: 1.8982 - val_accuracy: 0.4482
    Epoch 33/50
    1250/1250 [==============================] - 151s 121ms/step - loss: 1.4192 - accuracy: 0.5689 - val_loss: 1.9043 - val_accuracy: 0.4501
    Epoch 34/50
    1250/1250 [==============================] - 148s 118ms/step - loss: 1.3903 - accuracy: 0.5802 - val_loss: 1.9520 - val_accuracy: 0.4358
    Epoch 35/50
    1250/1250 [==============================] - 146s 117ms/step - loss: 1.3892 - accuracy: 0.5823 - val_loss: 1.9294 - val_accuracy: 0.4513
    Epoch 36/50
    1250/1250 [==============================] - 145s 116ms/step - loss: 1.3519 - accuracy: 0.5901 - val_loss: 1.9231 - val_accuracy: 0.4416
    Epoch 00036: early stopping
    Test loss: 1.9213827848434448
    Test accuracy: 0.44110000133514404
    
     
    
    


    
![png](output_227_1.png)
    



    
![png](output_227_2.png)
    


https://arxiv.org/pdf/1511.07289.pdf

##### GCNN 2 - Model 5


```python

GCNN_model5 = Sequential()

# Create simple CNN model architecture with Pooling for dimensionality reduction 
# and Dropout to reduce overfitting
GCNN_model5.add(Conv2D(192, kernel_size=(5, 5), activation = 'elu', input_shape = X_train[0].shape, kernel_regularizer=l2(0.0005))) 
GCNN_model5.add(MaxPooling2D(pool_size=(2, 2), padding='same'))
GCNN_model5.add(Dropout(0.0))

GCNN_model5.add(Conv2D(192, kernel_size=(1, 1), activation = 'elu', padding='same', kernel_regularizer=l2(0.0005)))
GCNN_model5.add(Conv2D(240, kernel_size=(3, 3), activation = 'elu', padding='same', kernel_regularizer=l2(0.0005)))
GCNN_model5.add(MaxPooling2D(pool_size=(2, 2), padding='same'))
GCNN_model5.add(Dropout(0.1))

GCNN_model5.add(Conv2D(240, kernel_size=(1,1), activation = 'elu', padding='same', kernel_regularizer=l2(0.0005)))
GCNN_model5.add(Conv2D(260, kernel_size=(2,2), activation = 'elu', padding='same', kernel_regularizer=l2(0.0005)))
GCNN_model5.add(MaxPooling2D(pool_size=(2, 2), padding='same'))
GCNN_model5.add(Dropout(0.2))

GCNN_model5.add(Conv2D(260, kernel_size=(1,1), activation = 'elu', padding='same', kernel_regularizer=l2(0.0005)))
GCNN_model5.add(Conv2D(280, kernel_size=(2,2), activation = 'elu', padding='same', kernel_regularizer=l2(0.0005)))
GCNN_model5.add(MaxPooling2D(pool_size=(2, 2), padding='same'))
GCNN_model5.add(Dropout(0.3))

GCNN_model5.add(Conv2D(280, kernel_size=(1,1), activation = 'elu', padding='same', kernel_regularizer=l2(0.0005)))
GCNN_model5.add(Conv2D(300, kernel_size=(2,2), activation = 'elu', padding='same', kernel_regularizer=l2(0.0005)))
GCNN_model5.add(MaxPooling2D(pool_size=(2, 2), padding='same'))
GCNN_model5.add(Dropout(0.4))

GCNN_model5.add(Conv2D(300, kernel_size=(2,2), activation = 'elu', padding='same', kernel_regularizer=l2(0.0005)))
GCNN_model5.add(MaxPooling2D(pool_size=(2, 2), padding='same'))
GCNN_model5.add(Dropout(0.5))

# Flatten the output of our convolutional layers
GCNN_model5.add(Flatten())

# Add dense layers
GCNN_model5.add(Dense(len(np.unique(y_train)), activation='softmax'))

# Print out a summary of the network
GCNN_model5.summary()

# Compile the model with the desired loss function, optimizer, and metric(s) to track
GCNN_model5.compile(loss = 'sparse_categorical_crossentropy', #cross entropy is for multi-class classification
                  optimizer = 'Adam',
                  metrics = ['accuracy'])

# Fit the model on the training data, defining desired batch_size & number of epochs,
# running validation after each batch
GCNN5 = GCNN_model5.fit(X_train, y_train,
                          epochs = 100,
                          verbose = 1,
                          validation_split = 0.2,
                            callbacks = ES)
test_loss_score(GCNN_model5)
accuracy_loss_plots(GCNN5)
confusion(GCNN_model5)

save_format='h5'
GCNN_model5.save('CNNmodels/GCNN_model5.h5')
```

    Model: "sequential_23"
    _________________________________________________________________
    Layer (type)                 Output Shape              Param #   
    =================================================================
    conv2d_94 (Conv2D)           (None, 28, 28, 192)       4992      
    _________________________________________________________________
    max_pooling2d_69 (MaxPooling (None, 14, 14, 192)       0         
    _________________________________________________________________
    dropout_60 (Dropout)         (None, 14, 14, 192)       0         
    _________________________________________________________________
    conv2d_95 (Conv2D)           (None, 14, 14, 192)       37056     
    _________________________________________________________________
    conv2d_96 (Conv2D)           (None, 14, 14, 240)       414960    
    _________________________________________________________________
    max_pooling2d_70 (MaxPooling (None, 7, 7, 240)         0         
    _________________________________________________________________
    dropout_61 (Dropout)         (None, 7, 7, 240)         0         
    _________________________________________________________________
    conv2d_97 (Conv2D)           (None, 7, 7, 240)         57840     
    _________________________________________________________________
    conv2d_98 (Conv2D)           (None, 7, 7, 260)         249860    
    _________________________________________________________________
    max_pooling2d_71 (MaxPooling (None, 4, 4, 260)         0         
    _________________________________________________________________
    dropout_62 (Dropout)         (None, 4, 4, 260)         0         
    _________________________________________________________________
    conv2d_99 (Conv2D)           (None, 4, 4, 260)         67860     
    _________________________________________________________________
    conv2d_100 (Conv2D)          (None, 4, 4, 280)         291480    
    _________________________________________________________________
    max_pooling2d_72 (MaxPooling (None, 2, 2, 280)         0         
    _________________________________________________________________
    dropout_63 (Dropout)         (None, 2, 2, 280)         0         
    _________________________________________________________________
    conv2d_101 (Conv2D)          (None, 2, 2, 280)         78680     
    _________________________________________________________________
    conv2d_102 (Conv2D)          (None, 2, 2, 300)         336300    
    _________________________________________________________________
    max_pooling2d_73 (MaxPooling (None, 1, 1, 300)         0         
    _________________________________________________________________
    dropout_64 (Dropout)         (None, 1, 1, 300)         0         
    _________________________________________________________________
    conv2d_103 (Conv2D)          (None, 1, 1, 300)         360300    
    _________________________________________________________________
    max_pooling2d_74 (MaxPooling (None, 1, 1, 300)         0         
    _________________________________________________________________
    dropout_65 (Dropout)         (None, 1, 1, 300)         0         
    _________________________________________________________________
    flatten_21 (Flatten)         (None, 300)               0         
    _________________________________________________________________
    dense_70 (Dense)             (None, 20)                6020      
    =================================================================
    Total params: 1,905,348
    Trainable params: 1,905,348
    Non-trainable params: 0
    _________________________________________________________________
    Epoch 1/100
    1250/1250 [==============================] - 210s 168ms/step - loss: 3.7320 - accuracy: 0.0696 - val_loss: 3.3296 - val_accuracy: 0.0945
    Epoch 2/100
    1250/1250 [==============================] - 208s 167ms/step - loss: 3.1848 - accuracy: 0.1112 - val_loss: 3.0089 - val_accuracy: 0.1410
    Epoch 3/100
    1250/1250 [==============================] - 214s 171ms/step - loss: 2.9958 - accuracy: 0.1379 - val_loss: 2.9325 - val_accuracy: 0.1531
    Epoch 4/100
    1250/1250 [==============================] - 208s 166ms/step - loss: 2.9391 - accuracy: 0.1621 - val_loss: 2.9276 - val_accuracy: 0.1854
    Epoch 5/100
    1250/1250 [==============================] - 207s 166ms/step - loss: 2.9135 - accuracy: 0.1829 - val_loss: 2.8625 - val_accuracy: 0.1951
    Epoch 6/100
    1250/1250 [==============================] - 211s 169ms/step - loss: 2.8897 - accuracy: 0.1992 - val_loss: 2.8497 - val_accuracy: 0.2147
    Epoch 7/100
    1250/1250 [==============================] - 244s 195ms/step - loss: 2.8723 - accuracy: 0.2155 - val_loss: 2.7329 - val_accuracy: 0.2579
    Epoch 8/100
    1250/1250 [==============================] - 220s 176ms/step - loss: 2.8495 - accuracy: 0.2275 - val_loss: 2.7369 - val_accuracy: 0.2611
    Epoch 9/100
    1250/1250 [==============================] - 225s 180ms/step - loss: 2.8466 - accuracy: 0.2361 - val_loss: 2.7326 - val_accuracy: 0.2719
    Epoch 10/100
    1250/1250 [==============================] - 223s 178ms/step - loss: 2.8297 - accuracy: 0.2469 - val_loss: 2.6376 - val_accuracy: 0.3063
    Epoch 11/100
    1250/1250 [==============================] - 221s 177ms/step - loss: 2.8280 - accuracy: 0.2552 - val_loss: 2.8233 - val_accuracy: 0.2473
    Epoch 12/100
    1250/1250 [==============================] - 211s 169ms/step - loss: 2.8170 - accuracy: 0.2597 - val_loss: 2.6854 - val_accuracy: 0.2974
    Epoch 13/100
    1250/1250 [==============================] - 211s 169ms/step - loss: 2.8194 - accuracy: 0.2654 - val_loss: 2.7368 - val_accuracy: 0.2943
    Epoch 14/100
    1250/1250 [==============================] - 211s 169ms/step - loss: 2.8050 - accuracy: 0.2726 - val_loss: 2.6539 - val_accuracy: 0.3147
    Epoch 15/100
    1250/1250 [==============================] - 211s 169ms/step - loss: 2.8034 - accuracy: 0.2799 - val_loss: 2.7515 - val_accuracy: 0.3028
    Epoch 16/100
    1250/1250 [==============================] - 212s 170ms/step - loss: 2.7964 - accuracy: 0.2836 - val_loss: 2.6700 - val_accuracy: 0.3093
    Epoch 17/100
    1250/1250 [==============================] - 211s 169ms/step - loss: 2.7922 - accuracy: 0.2862 - val_loss: 2.7312 - val_accuracy: 0.3025
    Epoch 18/100
    1250/1250 [==============================] - 216s 173ms/step - loss: 2.7840 - accuracy: 0.2910 - val_loss: 2.6146 - val_accuracy: 0.3371
    Epoch 19/100
    1250/1250 [==============================] - 211s 169ms/step - loss: 2.7831 - accuracy: 0.2951 - val_loss: 2.7266 - val_accuracy: 0.3106
    Epoch 20/100
    1250/1250 [==============================] - 211s 169ms/step - loss: 2.7735 - accuracy: 0.3027 - val_loss: 2.6324 - val_accuracy: 0.3393
    Epoch 21/100
    1250/1250 [==============================] - 211s 169ms/step - loss: 2.7700 - accuracy: 0.3036 - val_loss: 2.6471 - val_accuracy: 0.3337
    Epoch 22/100
    1250/1250 [==============================] - 211s 169ms/step - loss: 2.7726 - accuracy: 0.3080 - val_loss: 2.6452 - val_accuracy: 0.3450
    Epoch 23/100
    1250/1250 [==============================] - 211s 169ms/step - loss: 2.7693 - accuracy: 0.3067 - val_loss: 2.6215 - val_accuracy: 0.3488
    Epoch 24/100
    1250/1250 [==============================] - 214s 171ms/step - loss: 2.7585 - accuracy: 0.3133 - val_loss: 2.6421 - val_accuracy: 0.3462
    Epoch 25/100
    1250/1250 [==============================] - 214s 171ms/step - loss: 2.7511 - accuracy: 0.3180 - val_loss: 2.6090 - val_accuracy: 0.3576
    Epoch 26/100
    1250/1250 [==============================] - 214s 171ms/step - loss: 2.7535 - accuracy: 0.3185 - val_loss: 2.7783 - val_accuracy: 0.3156
    Epoch 27/100
    1250/1250 [==============================] - 215s 172ms/step - loss: 2.7385 - accuracy: 0.3217 - val_loss: 2.5669 - val_accuracy: 0.3693
    Epoch 28/100
    1250/1250 [==============================] - 214s 172ms/step - loss: 2.7351 - accuracy: 0.3270 - val_loss: 2.5833 - val_accuracy: 0.3686
    Epoch 29/100
    1250/1250 [==============================] - 214s 171ms/step - loss: 2.7356 - accuracy: 0.3330 - val_loss: 2.6208 - val_accuracy: 0.3679
    Epoch 30/100
    1250/1250 [==============================] - 223s 178ms/step - loss: 2.7412 - accuracy: 0.3289 - val_loss: 2.6055 - val_accuracy: 0.3638
    Epoch 31/100
    1250/1250 [==============================] - 223s 178ms/step - loss: 2.7344 - accuracy: 0.3360 - val_loss: 2.5878 - val_accuracy: 0.3671
    Epoch 32/100
    1250/1250 [==============================] - 227s 182ms/step - loss: 2.7222 - accuracy: 0.3377 - val_loss: 2.5993 - val_accuracy: 0.3774
    Epoch 33/100
    1250/1250 [==============================] - 219s 176ms/step - loss: 2.7198 - accuracy: 0.3396 - val_loss: 2.6210 - val_accuracy: 0.3664
    Epoch 34/100
    1250/1250 [==============================] - 220s 176ms/step - loss: 2.7170 - accuracy: 0.3388 - val_loss: 2.7257 - val_accuracy: 0.3374
    Epoch 35/100
    1250/1250 [==============================] - 222s 178ms/step - loss: 2.7133 - accuracy: 0.3471 - val_loss: 2.5329 - val_accuracy: 0.3984
    Epoch 36/100
    1250/1250 [==============================] - 230s 184ms/step - loss: 2.7145 - accuracy: 0.3475 - val_loss: 2.7181 - val_accuracy: 0.3552
    Epoch 37/100
    1250/1250 [==============================] - 218s 174ms/step - loss: 2.7068 - accuracy: 0.3520 - val_loss: 2.5754 - val_accuracy: 0.3852
    Epoch 38/100
    1250/1250 [==============================] - 208s 166ms/step - loss: 2.7054 - accuracy: 0.3514 - val_loss: 2.5646 - val_accuracy: 0.3837
    Epoch 39/100
    1250/1250 [==============================] - 205s 164ms/step - loss: 2.7116 - accuracy: 0.3541 - val_loss: 2.5798 - val_accuracy: 0.3859
    Epoch 40/100
    1250/1250 [==============================] - 203s 162ms/step - loss: 2.7112 - accuracy: 0.3535 - val_loss: 2.5361 - val_accuracy: 0.3986
    Epoch 41/100
    1250/1250 [==============================] - 203s 163ms/step - loss: 2.7096 - accuracy: 0.3546 - val_loss: 2.5984 - val_accuracy: 0.3868
    Epoch 42/100
    1250/1250 [==============================] - 204s 163ms/step - loss: 2.7073 - accuracy: 0.3605 - val_loss: 2.5685 - val_accuracy: 0.4001
    Epoch 43/100
    1250/1250 [==============================] - 209s 167ms/step - loss: 2.7032 - accuracy: 0.3618 - val_loss: 2.5858 - val_accuracy: 0.3946
    Epoch 44/100
    1250/1250 [==============================] - 207s 166ms/step - loss: 2.7028 - accuracy: 0.3629 - val_loss: 2.5477 - val_accuracy: 0.4032
    Epoch 45/100
    1250/1250 [==============================] - 208s 167ms/step - loss: 2.6874 - accuracy: 0.3664 - val_loss: 2.5836 - val_accuracy: 0.3938
    Epoch 46/100
    1250/1250 [==============================] - 208s 166ms/step - loss: 2.6899 - accuracy: 0.3708 - val_loss: 2.6769 - val_accuracy: 0.3705
    Epoch 47/100
    1250/1250 [==============================] - 207s 166ms/step - loss: 2.6901 - accuracy: 0.3687 - val_loss: 2.6432 - val_accuracy: 0.3780
    Epoch 48/100
    1250/1250 [==============================] - 208s 167ms/step - loss: 2.6920 - accuracy: 0.3702 - val_loss: 2.5558 - val_accuracy: 0.4033
    Epoch 49/100
    1250/1250 [==============================] - 207s 165ms/step - loss: 2.6927 - accuracy: 0.3771 - val_loss: 2.5511 - val_accuracy: 0.4182
    Epoch 50/100
    1250/1250 [==============================] - 206s 165ms/step - loss: 2.6835 - accuracy: 0.3773 - val_loss: 2.5555 - val_accuracy: 0.4057
    Epoch 51/100
    1250/1250 [==============================] - 206s 165ms/step - loss: 2.6831 - accuracy: 0.3765 - val_loss: 2.6751 - val_accuracy: 0.3689
    Epoch 52/100
    1250/1250 [==============================] - 206s 165ms/step - loss: 2.6754 - accuracy: 0.3816 - val_loss: 2.5735 - val_accuracy: 0.4046
    Epoch 53/100
    1250/1250 [==============================] - 206s 164ms/step - loss: 2.6824 - accuracy: 0.3781 - val_loss: 2.5487 - val_accuracy: 0.4127
    Epoch 54/100
    1250/1250 [==============================] - 206s 165ms/step - loss: 2.6816 - accuracy: 0.3806 - val_loss: 2.6713 - val_accuracy: 0.3830
    Epoch 00054: early stopping
    Test loss: 2.6437888145446777
    Test accuracy: 0.38850000500679016
    
     
    
    


    
![png](output_230_1.png)
    



    
![png](output_230_2.png)
    


##### GCNN 2 - Model 6


```python
GCNN_model6 = Sequential()

# Create simple CNN model architecture with Pooling for dimensionality reduction 
# and Dropout to reduce overfitting
GCNN_model6.add(Conv2D(32, kernel_size=(3,3), activation = 'elu', input_shape = X_train[0].shape, kernel_regularizer=l2(0.0005))) 
GCNN_model6.add(MaxPooling2D(pool_size=(2, 2), padding='same'))

GCNN_model6.add(Conv2D(64, kernel_size=(3,3), activation = 'elu', padding='same', kernel_regularizer=l2(0.0005)))
GCNN_model6.add(Conv2D(128, kernel_size=(3,3), activation = 'elu', padding='same', kernel_regularizer=l2(0.0005)))
GCNN_model6.add(MaxPooling2D(pool_size=(2, 2), padding='same'))
GCNN_model6.add(Dropout(0.1))

GCNN_model6.add(Conv2D(128, kernel_size=(2,2), activation = 'elu', padding='same', kernel_regularizer=l2(0.0005)))
GCNN_model6.add(Conv2D(256, kernel_size=(2,2), activation = 'elu', padding='same', kernel_regularizer=l2(0.0005)))
GCNN_model6.add(MaxPooling2D(pool_size=(2, 2), padding='same'))
GCNN_model6.add(Dropout(0.2))

GCNN_model6.add(Conv2D(256, kernel_size=(1,1), activation = 'elu', padding='same', kernel_regularizer=l2(0.0005)))
GCNN_model6.add(Conv2D(512, kernel_size=(1,1), activation = 'elu', padding='same', kernel_regularizer=l2(0.0005)))
GCNN_model6.add(MaxPooling2D(pool_size=(2, 2), padding='same'))
GCNN_model6.add(Dropout(0.3))

# Flatten the output of our convolutional layers
GCNN_model6.add(Flatten())

# Add dense layers
GCNN_model6.add(Dense(512, activation = 'elu'))
GCNN_model6.add(Dense(256, activation = 'elu'))
GCNN_model6.add(Dense(len(np.unique(y_train)), activation='softmax'))

# Print out a summary of the network
GCNN_model6.summary()

# Compile the model with the desired loss function, optimizer, and metric(s) to track
GCNN_model6.compile(loss = 'sparse_categorical_crossentropy', #cross entropy is for multi-class classification
                  optimizer = 'Adam',
                  metrics = ['accuracy'])

# Fit the model on the training data, defining desired batch_size & number of epochs,
# running validation after each batch
GCNN6 = GCNN_model6.fit(X_train, y_train,
                          epochs = 100,
                          verbose = 1,
                          validation_split=0.2,
                            callbacks = ES)


test_loss_score(GCNN_model6)
accuracy_loss_plots(GCNN6)
confusion(GCNN_model6)

GCNN_model6.save('CNNmodels/GCNN_model6.h5')
```

    Model: "sequential_22"
    _________________________________________________________________
    Layer (type)                 Output Shape              Param #   
    =================================================================
    conv2d_87 (Conv2D)           (None, 30, 30, 32)        320       
    _________________________________________________________________
    max_pooling2d_65 (MaxPooling (None, 15, 15, 32)        0         
    _________________________________________________________________
    conv2d_88 (Conv2D)           (None, 15, 15, 64)        18496     
    _________________________________________________________________
    conv2d_89 (Conv2D)           (None, 15, 15, 128)       73856     
    _________________________________________________________________
    max_pooling2d_66 (MaxPooling (None, 8, 8, 128)         0         
    _________________________________________________________________
    dropout_57 (Dropout)         (None, 8, 8, 128)         0         
    _________________________________________________________________
    conv2d_90 (Conv2D)           (None, 8, 8, 128)         65664     
    _________________________________________________________________
    conv2d_91 (Conv2D)           (None, 8, 8, 256)         131328    
    _________________________________________________________________
    max_pooling2d_67 (MaxPooling (None, 4, 4, 256)         0         
    _________________________________________________________________
    dropout_58 (Dropout)         (None, 4, 4, 256)         0         
    _________________________________________________________________
    conv2d_92 (Conv2D)           (None, 4, 4, 256)         65792     
    _________________________________________________________________
    conv2d_93 (Conv2D)           (None, 4, 4, 512)         131584    
    _________________________________________________________________
    max_pooling2d_68 (MaxPooling (None, 2, 2, 512)         0         
    _________________________________________________________________
    dropout_59 (Dropout)         (None, 2, 2, 512)         0         
    _________________________________________________________________
    flatten_20 (Flatten)         (None, 2048)              0         
    _________________________________________________________________
    dense_67 (Dense)             (None, 512)               1049088   
    _________________________________________________________________
    dense_68 (Dense)             (None, 256)               131328    
    _________________________________________________________________
    dense_69 (Dense)             (None, 20)                5140      
    =================================================================
    Total params: 1,672,596
    Trainable params: 1,672,596
    Non-trainable params: 0
    _________________________________________________________________
    Epoch 1/100
    1250/1250 [==============================] - 79s 63ms/step - loss: 3.1718 - accuracy: 0.1620 - val_loss: 2.7570 - val_accuracy: 0.2479
    Epoch 2/100
    1250/1250 [==============================] - 81s 65ms/step - loss: 2.6500 - accuracy: 0.2673 - val_loss: 2.6145 - val_accuracy: 0.2655
    Epoch 3/100
    1250/1250 [==============================] - 80s 64ms/step - loss: 2.4335 - accuracy: 0.3221 - val_loss: 2.3289 - val_accuracy: 0.3523
    Epoch 4/100
    1250/1250 [==============================] - 80s 64ms/step - loss: 2.3249 - accuracy: 0.3586 - val_loss: 2.2297 - val_accuracy: 0.3873
    Epoch 5/100
    1250/1250 [==============================] - 81s 64ms/step - loss: 2.2512 - accuracy: 0.3913 - val_loss: 2.2238 - val_accuracy: 0.4045
    Epoch 6/100
    1250/1250 [==============================] - 80s 64ms/step - loss: 2.1872 - accuracy: 0.4171 - val_loss: 2.1690 - val_accuracy: 0.4320
    Epoch 7/100
    1250/1250 [==============================] - 80s 64ms/step - loss: 2.1435 - accuracy: 0.4386 - val_loss: 2.2055 - val_accuracy: 0.4380
    Epoch 8/100
    1250/1250 [==============================] - 80s 64ms/step - loss: 2.1125 - accuracy: 0.4551 - val_loss: 2.1647 - val_accuracy: 0.4466
    Epoch 9/100
    1250/1250 [==============================] - 81s 64ms/step - loss: 2.0923 - accuracy: 0.4677 - val_loss: 2.1347 - val_accuracy: 0.4562
    Epoch 10/100
    1250/1250 [==============================] - 81s 65ms/step - loss: 2.0633 - accuracy: 0.4794 - val_loss: 2.2313 - val_accuracy: 0.4366
    Epoch 11/100
    1250/1250 [==============================] - 81s 65ms/step - loss: 2.0498 - accuracy: 0.4902 - val_loss: 2.2323 - val_accuracy: 0.4513
    Epoch 12/100
    1250/1250 [==============================] - 80s 64ms/step - loss: 2.0255 - accuracy: 0.5038 - val_loss: 2.2446 - val_accuracy: 0.4494
    Epoch 13/100
    1250/1250 [==============================] - 81s 65ms/step - loss: 2.0129 - accuracy: 0.5082 - val_loss: 2.1112 - val_accuracy: 0.4926
    Epoch 14/100
    1250/1250 [==============================] - 81s 65ms/step - loss: 2.0049 - accuracy: 0.5138 - val_loss: 2.2055 - val_accuracy: 0.4677
    Epoch 15/100
    1250/1250 [==============================] - 81s 64ms/step - loss: 1.9856 - accuracy: 0.5239 - val_loss: 2.1489 - val_accuracy: 0.4913
    Epoch 16/100
    1250/1250 [==============================] - 81s 65ms/step - loss: 1.9838 - accuracy: 0.5256 - val_loss: 2.1912 - val_accuracy: 0.4859
    Epoch 17/100
    1250/1250 [==============================] - 81s 65ms/step - loss: 1.9787 - accuracy: 0.5309 - val_loss: 2.1531 - val_accuracy: 0.4869
    Epoch 18/100
    1250/1250 [==============================] - 81s 65ms/step - loss: 1.9532 - accuracy: 0.5429 - val_loss: 2.1553 - val_accuracy: 0.5002
    Epoch 19/100
    1250/1250 [==============================] - 81s 64ms/step - loss: 1.9499 - accuracy: 0.5441 - val_loss: 2.1181 - val_accuracy: 0.5062
    Epoch 20/100
    1250/1250 [==============================] - 87s 69ms/step - loss: 1.9473 - accuracy: 0.5494 - val_loss: 2.2089 - val_accuracy: 0.4921
    Epoch 21/100
    1250/1250 [==============================] - 84s 67ms/step - loss: 1.9338 - accuracy: 0.5542 - val_loss: 2.2257 - val_accuracy: 0.4901
    Epoch 22/100
    1250/1250 [==============================] - 83s 66ms/step - loss: 1.9510 - accuracy: 0.5528 - val_loss: 2.1990 - val_accuracy: 0.4863
    Epoch 23/100
    1250/1250 [==============================] - 82s 66ms/step - loss: 1.9619 - accuracy: 0.5530 - val_loss: 2.2437 - val_accuracy: 0.4777
    Epoch 24/100
    1250/1250 [==============================] - 84s 67ms/step - loss: 1.9406 - accuracy: 0.5603 - val_loss: 2.2419 - val_accuracy: 0.4778
    Epoch 00024: early stopping
    Test loss: 2.237199068069458
    Test accuracy: 0.47620001435279846
    
     
    
    


    
![png](output_232_1.png)
    



    
![png](output_232_2.png)
    



```python

```


```python

```


```python

```


```python

```


```python

```

# Model Evaluation


```python
CNNmodels/GCNN_model2.h5
```


```python
img = mpimg.imread('data/man.jpg')
img = cv2.resize(img, dsize=(32,32), interpolation=cv2.INTER_CUBIC)
imgplot = plt.imshow(img)
```


    
![png](output_240_0.png)
    



```python
pred_img = tf.keras.preprocessing.image.img_to_array(
    img, data_format=None, dtype=None)

GCNN_model2.predict(pred_img.reshape(1,32,32,1))

predict_probas = CNN_model6.predict(pred_img.reshape(1,32,32,1))
y_predict = np.argmax(predict_probas, axis=1)
Superclass_label.iloc[y_predict,0]
```


    ---------------------------------------------------------------------------

    ValueError                                Traceback (most recent call last)

    <ipython-input-90-5cc9e23a928f> in <module>
          2     img, data_format=None, dtype=None)
          3 
    ----> 4 GCNN_model2.predict(pred_img.reshape(1,32,32,1))
          5 
          6 predict_probas = CNN_model6.predict(pred_img.reshape(1,32,32,1))
    

    ValueError: cannot reshape array of size 3072 into shape (1,32,32,1)



```python

```
